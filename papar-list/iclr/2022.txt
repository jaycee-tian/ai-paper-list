	Sabri Eyuboglu, Maya Varma, Khaled Kamal Saab, Jean-Benoit Delbrouck, Christopher Lee-Messer, Jared Dunnmon, James Zou, Christopher Ré:
Domino: Discovering Systematic Errors with Cross-Modal Embeddings.
		Evan Hernandez, Sarah Schwettmann, David Bau, Teona Bagashvili, Antonio Torralba, Jacob Andreas:
Natural Language Descriptions of Deep Visual Features.
		Lixu Wang, Shichao Xu, Ruiqi Xu, Xiao Wang, Qi Zhu:
Non-Transferable Learning: A New Approach for Model Ownership Verification and Applicability Authorization.
		Meng Qu, Huiyu Cai, Jian Tang:
Neural Structured Prediction for Inductive Node Classification.
		Asiri Wijesinghe, Qing Wang:
A New Perspective on "How Graph Neural Networks Go Beyond Weisfeiler-Lehman?".
		Chulhee Yun, Shashank Rajput, Suvrit Sra:
Minibatch vs Local SGD with Shuffling: Tight Convergence Bounds and Beyond.
		Yifei Wang, Jonathan Lacotte, Mert Pilanci:
The Hidden Convex Optimization Landscape of Regularized Two-Layer ReLU Networks: an Exact Characterization of Optimal Solutions.
		Yonathan Efroni, Dipendra Misra, Akshay Krishnamurthy, Alekh Agarwal, John Langford:
Provably Filtering Exogenous Distractors using Multistep Inverse Dynamics.
		Sebastian Flennerhag, Yannick Schroecker, Tom Zahavy, Hado van Hasselt, David Silver, Satinder Singh:
Bootstrapped Meta-Learning.
		Anirudh Goyal, Aniket Rajiv Didolkar, Alex Lamb, Kartikeya Badola, Nan Rosemary Ke, Nasim Rahaman, Jonathan Binas, Charles Blundell, Michael Curtis Mozer, Yoshua Bengio:
Coordination Among Neural Modules Through a Shared Global Workspace.
		Minghao Guo, Veronika Thost, Beichen Li, Payel Das, Jie Chen, Wojciech Matusik:
Data-Efficient Graph Grammar Learning for Molecular Generation.
		Nicholas Carlini, Andreas Terzis:
Poisoning and Backdooring Contrastive Learning.
		X. Y. Han, Vardan Papyan, David L. Donoho:
Neural Collapse Under MSE Loss: Proximity to and Dynamics on the Central Path.
		Shuxiao Chen, Koby Crammer, Hangfeng He, Dan Roth, Weijie J. Su:
Weighted Training for Cross-Task Learning.
		Marine Schimel, Ta-Chu Kao, Kristopher T. Jensen, Guillaume Hennequin:
iLQR-VAE : control-based learning of input-driven dynamics with applications to neural data.
		Shiori Sagawa, Pang Wei Koh, Tony Lee, Irena Gao, Sang Michael Xie, Kendrick Shen, Ananya Kumar, Weihua Hu, Michihiro Yasunaga, Henrik Marklund, Sara Beery, Etienne David, Ian Stavness, Wei Guo, Jure Leskovec, Kate Saenko, Tatsunori Hashimoto, Sergey Levine, Chelsea Finn, Percy Liang:
Extending the WILDS Benchmark for Unsupervised Adaptation.
		S. Chandra Mouli, Bruno Ribeiro:
Asymmetry Learning for Counterfactually-invariant Classification in OOD Tasks.
		Shengjia Zhao, Abhishek Sinha, Yutong He, Aidan Perreault, Jiaming Song, Stefano Ermon:
Comparing Distributions by Measuring Differences that Affect Decision Making.
		Yusong Wu, Ethan Manilow, Yi Deng, Rigel Swavely, Kyle Kastner, Tim Cooijmans, Aaron C. Courville, Cheng-Zhi Anna Huang, Jesse H. Engel:
MIDI-DDSP: Detailed Control of Musical Performance via Hierarchical Modeling.
		Bo Wan, Wenjuan Han, Zilong Zheng, Tinne Tuytelaars:
Unsupervised Vision-Language Grammar Induction with Shared Structure Modeling.
		Haobo Wang, Ruixuan Xiao, Yixuan Li, Lei Feng, Gang Niu, Gang Chen, Junbo Zhao:
PiCO: Contrastive Label Disambiguation for Partial Label Learning.
		Shizhan Liu, Hang Yu, Cong Liao, Jianguo Li, Weiyao Lin, Alex X. Liu, Schahram Dustdar:
Pyraformer: Low-Complexity Pyramidal Attention for Long-Range Time Series Modeling and Forecasting.
		Floris Geerts, Juan L. Reutter:
Expressiveness and Approximation Properties of Graph Neural Networks.
		Steeven Janny, Fabien Baradel, Natalia Neverova, Madiha Nadri, Greg Mori, Christian Wolf:
Filtered-CoPhy: Unsupervised Learning of Counterfactual Physics in Pixel Space.
		Hangbo Bao, Li Dong, Songhao Piao, Furu Wei:
BEiT: BERT Pre-Training of Image Transformers.
		Ananya Kumar, Aditi Raghunathan, Robbie Matthew Jones, Tengyu Ma, Percy Liang:
Fine-Tuning can Distort Pretrained Features and Underperform Out-of-Distribution.
		Zongze Wu, Yotam Nitzan, Eli Shechtman, Dani Lischinski:
StyleAlign: Analysis and Applications of Aligned StyleGAN Models.
		Kohei Miyaguchi, Takayuki Katsuki, Akira Koseki, Toshiya Iwamori:
Variational Inference for Discriminative Learning with Generative Modeling of Feature Incompletion.
		Albert Gu, Karan Goel, Christopher Ré:
Efficiently Modeling Long Sequences with Structured State Spaces.
		Xuechen Li, Florian Tramèr, Percy Liang, Tatsunori Hashimoto:
Large Language Models Can Be Strong Differentially Private Learners.
		Minkai Xu, Lantao Yu, Yang Song, Chence Shi, Stefano Ermon, Jian Tang:
GeoDiff: A Geometric Diffusion Model for Molecular Conformation Generation.
		Omri Puny, Matan Atzmon, Edward J. Smith, Ishan Misra, Aditya Grover, Heli Ben-Hamu, Yaron Lipman:
Frame Averaging for Invariant and Equivariant Network Design.
		Alex Rogozhnikov:
Einops: Clear and Reliable Tensor Manipulations with Einstein-like Notation.
		Olivia Wiles, Sven Gowal, Florian Stimberg, Sylvestre-Alvise Rebuffi, Ira Ktena, Krishnamurthy Dvijotham, Ali Taylan Cemgil:
A Fine-Grained Analysis on Distribution Shift.
		Sagar Vaze, Kai Han, Andrea Vedaldi, Andrew Zisserman:
Open-Set Recognition: A Good Closed-Set Classifier is All You Need.
		Rachid Riad, Olivier Teboul, David Grangier, Neil Zeghidour:
Learning Strides in Convolutional Neural Networks.
		Jake Topping, Francesco Di Giovanni, Benjamin Paul Chamberlain, Xiaowen Dong, Michael M. Bronstein:
Understanding over-squashing and bottlenecks on graphs via curvature.
		Vadim Popov, Ivan Vovk, Vladimir Gogoryan, Tasnima Sadekova, Mikhail Sergeevich Kudinov, Jiansheng Wei:
Diffusion-Based Voice Conversion with Fast Maximum Likelihood Sampling Scheme.
		Shuming Kong, Yanyan Shen, Linpeng Huang:
Resolving Training Biases via Influence-based Data Relabeling.
		Divyam Madaan, Jaehong Yoon, Yuanchun Li, Yunxin Liu, Sung Ju Hwang:
Representational Continuity for Unsupervised Continual Learning.
		Kyle Hsu, Moo Jin Kim, Rafael Rafailov, Jiajun Wu, Chelsea Finn:
Vision-Based Manipulators Need to Also See from Their Hands.
		Huaxiu Yao, Linjun Zhang, Chelsea Finn:
Meta-Learning with Fewer Tasks through Task Interpolation.
		Huiqi Deng, Qihan Ren, Hao Zhang, Quanshi Zhang:
Discovering and Explaining the Representation Bottleneck of DNNS.
		António Farinhas, Wilker Aziz, Vlad Niculae, André F. T. Martins:
Sparse Communication via Mixed Distributions.
		Jason Wei, Maarten Bosma, Vincent Y. Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester, Nan Du, Andrew M. Dai, Quoc V. Le:
Finetuned Language Models are Zero-Shot Learners.
		Qing Jin, Jian Ren, Richard Zhuang, Sumant Hanumante, Zhengang Li, Zhiyu Chen, Yanzhi Wang, Kaiyuan Yang, Sergey Tulyakov:
F8Net: Fixed-Point 8-bit Only Multiplication for Network Quantization.
		Ye Yuan, Yuda Song, Zhengyi Luo, Wen Sun, Kris M. Kitani:
Transform2Act: Learning a Transform-and-Control Policy for Efficient Agent Design.
		Boris N. Oreshkin, Florent Bocquelet, Félix G. Harvey, Bay Raitt, Dominic Laflamme:
ProtoRes: Proto-Residual Network for Pose Authoring via Learned Inverse Kinematics.
		Nicolas Papernot, Thomas Steinke:
Hyperparameter Tuning with Renyi Differential Privacy.
		Mia Chiquier, Chengzhi Mao, Carl Vondrick:
Real-Time Neural Voice Camouflage.
		Shoufa Chen, Enze Xie, Chongjian Ge, Runjian Chen, Ding Liang, Ping Luo:
CycleMLP: A MLP-like Architecture for Dense Prediction.
		Fan Bao, Chongxuan Li, Jun Zhu, Bo Zhang:
Analytic-DPM: an Analytic Estimate of the Optimal Reverse Variance in Diffusion Probabilistic Models.
		Pingchuan Ma, Tao Du, Joshua B. Tenenbaum, Wojciech Matusik, Chuang Gan:
RISP: Rendering-Invariant State Predictor with Differentiable Simulation and Rendering for Cross-Domain Parameter Estimation.
		Benjamin Eysenbach, Ruslan Salakhutdinov, Sergey Levine:
The Information Geometry of Unsupervised Reinforcement Learning.
		Rose E. Wang, Esin Durmus, Noah D. Goodman, Tatsunori Hashimoto:
Language modeling via stochastic processes.
		Chen Jin, Ryutaro Tanno, Thomy Mertzanidou, Eleftheria Panagiotaki, Daniel C. Alexander:
Learning to Downsample for Segmentation of Ultra-High Resolution Images.
		Rasmus Berg Palm, Miguel González Duque, Shyam Sudhakaran, Sebastian Risi:
Variational Neural Cellular Automata.
		Todor Davchev, Oleg Olegovich Sushkov, Jean-Baptiste Regli, Stefan Schaal, Yusuf Aytar, Markus Wulfmeier, Jon Scholz:
Wish you were here: Hindsight Goal Selection for long-horizon dexterous manipulation.
		Ofir Lindenbaum, Moshe Salhov, Amir Averbuch, Yuval Kluger:
L0-Sparse Canonical Correlation Analysis.
		Sheikh Shams Azam, Seyyedali Hosseinalipour, Qiang Qiu, Christopher G. Brinton:
Recycling Model Updates in Federated Learning: Are Gradient Subspaces Low-Rank?
		Yao Ma, Xiaorui Liu, Neil Shah, Jiliang Tang:
Is Homophily a Necessity for Graph Neural Networks?
		Qizhang Feng, Ninghao Liu, Fan Yang, Ruixiang Tang, Mengnan Du, Xia Hu:
DEGREE: Decomposition Based Explanation for Graph Neural Networks.
		Rob Brekelmans, Sicong Huang, Marzyeh Ghassemi, Greg Ver Steeg, Roger Baker Grosse, Alireza Makhzani:
Improving Mutual Information Estimation with Annealed and Energy-Based Bounds.
		Xueyuan She, Saurabh Dash, Saibal Mukhopadhyay:
Sequence Approximation using Feedforward Spiking Neural Network for Spatiotemporal Learning: Theory and Optimization Methods.
		Ravikumar Balakrishnan, Tian Li, Tianyi Zhou, Nageen Himayat, Virginia Smith, Jeff A. Bilmes:
Diverse Client Selection for Federated Learning via Submodular Maximization.
		Da Xu, Yuting Ye, Chuanwei Ruan, Evren Körpeoglu, Sushant Kumar, Kannan Achan:
From Intervention to Domain Transportation: A Novel Perspective to Optimize Recommendation.
		Alexey Zakharov, Qinghai Guo, Zafeirios Fountas:
Variational Predictive Routing with Nested Subjective Timescales.
		Jia Guo, Jiankang Deng, Alexandros Lattas, Stefanos Zafeiriou:
Sample and Computation Redistribution for Efficient Face Detection.
		Yinfeng Yu, Wenbing Huang, Fuchun Sun, Changan Chen, Yikai Wang, Xiaohong Liu:
Sound Adversarial Audio-Visual Navigation.
		Aahlad Manas Puli, Lily H. Zhang, Eric Karl Oermann, Rajesh Ranganath:
Out-of-distribution Generalization in the Presence of Nuisance-Induced Spurious Correlations.
		Junfeng Guo, Ang Li, Cong Liu:
AEVA: Black-box Backdoor Detection Using Adversarial Extreme Value Analysis.
		Kirby Banman, Liam Peet-Pare, Nidhi Hegde, Alona Fyshe, Martha White:
Resonance in Weight Space: Covariate Shift Can Drive Divergence of SGD with Momentum.
		Chirag Gupta, Aaditya Ramdas:
Top-label calibration and multiclass-to-binary reductions.
		Gabriel Mel, Jeffrey Pennington:
Anisotropic Random Feature Regression in High Dimensions.
		Harshavardhan Kamarthi, Alexander Rodríguez, B. Aditya Prakash:
Back2Future: Leveraging Backfill Dynamics for Improving Real-time Predictions in Future.
		Alberto Bietti:
Approximation and Learning with Deep Convolutional Models: a Kernel Perspective.
		Dhruv Shah, Peng Xu, Yao Lu, Ted Xiao, Alexander Toshev, Sergey Levine, Brian Ichter:
Value Function Spaces: Skill-Centric State Abstractions for Long-Horizon Reasoning.
		Raphael A. Meyer, Cameron Musco, Christopher Musco, David P. Woodruff, Samson Zhou:
Fast Regression for Structured Inputs.
		Kensen Shi, Hanjun Dai, Kevin Ellis, Charles Sutton:
CrossBeam: Learning to Search in Bottom-Up Program Synthesis.
		Seng Pei Liew, Tsubasa Takahashi, Michihiko Ueno:
PEARL: Data Synthesis via Private Embeddings and Adversarial Reconstruction Learning.
		Michelle Miller, SueYeon Chung, Kenneth D. Miller:
Divisive Feature Normalization Improves Image Recognition Performance in AlexNet.
		Benjamin LeBrun, Alessandro Sordoni, Timothy J. O'Donnell:
Evaluating Distributional Distortion in Neural Language Modeling.
		Ahmed Imtiaz Humayun, Randall Balestriero, Richard G. Baraniuk:
MaGNET: Uniform Sampling from Deep Generative Network Manifolds Without Retraining.
		Pan Xu, Zheng Wen, Handong Zhao, Quanquan Gu:
Neural Contextual Bandits with Deep Representation and Shallow Exploration.
		Siyan Liu, Pei Zhang, Dan Lu, Guannan Zhang:
PI3NN: Out-of-distribution-aware Prediction Intervals from Three Neural Networks.
		Yingzhen Yang, Ping Li:
Discriminative Similarity for Data Clustering.
		Yuqing Du, Pieter Abbeel, Aditya Grover:
It Takes Four to Tango: Multiagent Self Play for Automatic Curriculum Generation.
		Fan Wu, Linyi Li, Zijian Huang, Yevgeniy Vorobeychik, Ding Zhao, Bo Li:
CROP: Certifying Robust Policies for Reinforcement Learning through Functional Smoothing.
		Liming Pan, Cheng Shi, Ivan Dokmanic:
Neural Link Prediction with Walk Pooling.
		Yihan Wang, Zhouxing Shi, Quanquan Gu, Cho-Jui Hsieh:
On the Convergence of Certified Robust Training with Interval Bound Propagation.
		Yu Meng, Chenyan Xiong, Payal Bajaj, Saurabh Tiwary, Paul N. Bennett, Jiawei Han, Xia Song:
Pretraining Text Encoders with Adversarial Mixture of Training Signal Generators.
		Anuroop Sriram, Abhishek Das, Brandon M. Wood, Siddharth Goyal, C. Lawrence Zitnick:
Towards Training Billion Parameter Graph Neural Networks for Atomic Simulations.
		Chenjun Xiao, Bo Dai, Jincheng Mei, Oscar A Ramirez, Ramki Gummadi, Chris Harris, Dale Schuurmans:
Understanding and Leveraging Overparameterization in Recursive Value Estimation.
		Khashayar Gatmiry, Stefanie Jegelka, Jonathan A. Kelner:
Optimization and Adaptive Generalization of Three layer Neural Networks.
		Ruibo Liu, Chongyang Gao, Chenyan Jia, Guangxuan Xu, Soroush Vosoughi:
Non-Parallel Text Style Transfer with Self-Parallel Supervision.
		Quanfu Fan, Chun-Fu Chen, Rameswar Panda:
Can an Image Classifier Suffice For Action Recognition?
		Wei Deng, Siqi Liang, Botao Hao, Guang Lin, Faming Liang:
Interacting Contour Stochastic Gradient Langevin Dynamics.
		Siqi Liu, Luke Marris, Daniel Hennes, Josh Merel, Nicolas Heess, Thore Graepel:
NeuPL: Neural Population Learning.
		Minghao Han, Jacob Euler-Rolle, Robert K. Katzschmann:
DeSKO: Stability-Assured Robust Control with a Deep Stochastic Koopman Operator.
		Panagiotis Misiakos, Georgios Smyrnis, George Retsinas, Petros Maragos:
Neural Network Approximation based on Hausdorff distance of Tropical Zonotopes.
		Xiong Zhou, Xianming Liu, Deming Zhai, Junjun Jiang, Xin Gao, Xiangyang Ji:
Learning Towards The Largest Margins.
		Yonggan Fu, Shunyao Zhang, Shang Wu, Cheng Wan, Yingyan Lin:
Patch-Fool: Are Vision Transformers Always Robust Against Adversarial Perturbations?
		David Berthelot, Rebecca Roelofs, Kihyuk Sohn, Nicholas Carlini, Alexey Kurakin:
AdaMatch: A Unified Approach to Semi-Supervised Learning and Domain Adaptation.
		Claudio Ferrari, Mark Niklas Müller, Nikola Jovanovic, Martin T. Vechev:
Complete Verification via Multi-Neuron Relaxation Guided Branch-and-Bound.
		Daniel Watson, William Chan, Jonathan Ho, Mohammad Norouzi:
Learning Fast Samplers for Diffusion Models by Differentiating Through Sample Quality.
		Abhishek Shetty, Raaz Dwivedi, Lester Mackey:
Distribution Compression in Near-Linear Time.
		Frank F. Xu, Junxian He, Graham Neubig, Vincent Josua Hellendoorn:
Capturing Structural Locality in Non-parametric Language Models.
		Shaojin Ding, Tianlong Chen, Zhangyang Wang:
Audio Lottery: Speech Recognition Made Ultra-Lightweight, Noise-Robust, and Transferable.
		Georgios Georgakis, Bernadette Bucher, Karl Schmeckpeper, Siddharth Singh, Kostas Daniilidis:
Learning to Map for Active Semantic Goal Navigation.
		Danijar Hafner:
Benchmarking the Spectrum of Agent Capabilities.
		Peihao Zhu, Rameen Abdal, John Femiani, Peter Wonka:
Mind the Gap: Domain Gap Control for Single Shot Domain Adaptation for Generative Adversarial Networks.
		Rylee Thompson, Boris Knyazev, Elahe Ghalebi, Jungtaek Kim, Graham W. Taylor:
On Evaluation Metrics for Graph Generative Models.
		Emily Black, Klas Leino, Matt Fredrikson:
Selective Ensembles for Consistent Predictions.
		Wei Jin, Lingxiao Zhao, Shichang Zhang, Yozen Liu, Jiliang Tang, Neil Shah:
Graph Condensation for Graph Neural Networks.
		Yonatan Dukler, Alessandro Achille, Giovanni Paolini, Avinash Ravichandran, Marzia Polito, Stefano Soatto:
DIVA: Dataset Derivative of a Learning Task.
		Baihe Huang, Jason D. Lee, Zhaoran Wang, Zhuoran Yang:
Towards General Function Approximation in Zero-Sum Markov Games.
		Kartik Goyal, Chris Dyer, Taylor Berg-Kirkpatrick:
Exposing the Implicit Energy Networks behind Masked Language Models via Metropolis--Hastings.
		Victor Schmidt, Alexandra Luccioni, Mélisande Teng, Tianyu Zhang, Alexia Reynaud, Sunand Raghupathi, Gautier Cosne, Adrien Juraver, Vahe Vardanyan, Alex Hernández-García, Yoshua Bengio:
ClimateGAN: Raising Climate Change Awareness by Generating Images of Floods.
		Tracy Ke, Longlin Wang:
A Comparison of Hamming Errors of Representative Variable Selection Methods.
		Gabriele Cesa, Leon Lang, Maurice Weiler:
A Program to Build E(N)-Equivariant Steerable CNNs.
		Tanner Fiez, Chi Jin, Praneeth Netrapalli, Lillian J. Ratliff:
Minimax Optimization with Smooth Algorithmic Adversaries.
		Xiaoyun Li, Belhal Karimi, Ping Li:
On Distributed Adaptive Optimization with Gradient Compression.
		Saurabh Garg, Sivaraman Balakrishnan, Zachary Chase Lipton, Behnam Neyshabur, Hanie Sedghi:
Leveraging unlabeled data to predict out-of-distribution performance.
		Yutong Wang, Clayton Scott:
VC dimension of partially quantized neural networks in the overparametrized regime.
		Yangjun Ruan, Yann Dubois, Chris J. Maddison:
Optimal Representations for Covariate Shift.
		Hattie Zhou, Ankit Vani, Hugo Larochelle, Aaron C. Courville:
Fortuitous Forgetting in Connectionist Networks.
		Ian Gemp, Brian McWilliams, Claire Vernade, Thore Graepel:
EigenGame Unloaded: When playing games is better than optimizing.
		Peifeng Wang, Jonathan Zamora, Junfeng Liu, Filip Ilievski, Muhao Chen, Xiang Ren:
Contextualized Scene Imagination for Generative Commonsense Reasoning.
		Jiquan Ngiam, Vijay Vasudevan, Benjamin Caine, Zhengdong Zhang, Hao-Tien Lewis Chiang, Jeffrey Ling, Rebecca Roelofs, Alex Bewley, Chenxi Liu, Ashish Venugopal, David J. Weiss, Ben Sapp, Zhifeng Chen, Jonathon Shlens:
Scene Transformer: A unified architecture for predicting future trajectories of multiple agents.
		Asma Ghandeharioun, Been Kim, Chun-Liang Li, Brendan Jou, Brian Eoff, Rosalind W. Picard:
DISSECT: Disentangled Simultaneous Explanations via Concept Traversals.
		Satya Narayan Shukla, Benjamin M. Marlin:
Heteroscedastic Temporal Variational Autoencoder For Irregularly Sampled Time Series.
		Ryuichi Kanoh, Mahito Sugiyama:
A Neural Tangent Kernel Perspective of Infinite Tree Ensembles.
		Ti-Rong Wu, Chung-Chin Shih, Ting-Han Wei, Meng-Yu Tsai, Wei-Yuan Hsu, I-Chen Wu:
AlphaZero-based Proof Cost Network to Aid Game Solving.
		Mislav Balunovic, Dimitar Iliev Dimitrov, Robin Staab, Martin T. Vechev:
Bayesian Framework for Gradient Leakage.
		Changho Shin, Winfred Li, Harit Vishwakarma, Nicholas Carl Roberts, Frederic Sala:
Universalizing Weak Supervision.
		Ge Liu, Alexander Dimitrakakis, Brandon Carter, David K. Gifford:
Maximum n-times Coverage for Vaccine Design.
		A. Tuan Nguyen, Toan Tran, Yarin Gal, Philip H. S. Torr, Atilim Gunes Baydin:
KL Guided Domain Adaptation.
		Lingxiao Zhao, Wei Jin, Leman Akoglu, Neil Shah:
From Stars to Subgraphs: Uplifting Any GNN with Local Structure Awareness.
		Julian Büchel, Fynn Firouz Faber, Dylan Richard Muir:
Network Insensitivity to Parameter Noise via Parameter Attack During Training.
		Qitong Gao, Dong Wang, Joshua David Amason, Siyang Yuan, Chenyang Tao, Ricardo Henao, Majda Hadziahmetovic, Lawrence Carin, Miroslav Pajic:
Gradient Importance Learning for Incomplete Observations.
		Leon Sixt, Martin Schuessler, Oana-Iuliana Popescu, Philipp Weiß, Tim Landgraf:
Do Users Benefit From Interpretable Vision? A User Study, Baseline, And Dataset.
		Jimmy Ba, Murat A. Erdogdu, Marzyeh Ghassemi, Shengyang Sun, Taiji Suzuki, Denny Wu, Tianzong Zhang:
Understanding the Variance Collapse of SVGD in High Dimensions.
		Geraud Nangue Tasse, Steven James, Benjamin Rosman:
Generalisation in Lifelong Reinforcement Learning through Logical Composition.
		Zhaoqi Leng, Mingxing Tan, Chenxi Liu, Ekin Dogus Cubuk, Jay Shi, Shuyang Cheng, Dragomir Anguelov:
PolyLoss: A Polynomial Expansion Perspective of Classification Loss Functions.
		Xiao Shi Huang, Felipe Pérez, Maksims Volkovs:
Improving Non-Autoregressive Translation Models Without Distillation.
		Arun Rajkumar, Vishnu Veerathu, Abdul Bakey Mir:
A Theory of Tournament Representations.
		Zhikang T. Wang, Masahito Ueda:
Convergent and Efficient Deep Q Learning Algorithm.
		Xiaoling Hu, Xiao Lin, Michael Cogswell, Yi Yao, Susmit Jha, Chao Chen:
Trigger Hunting with a Topological Prior for Trojan Detection.
		Yanchao Sun, Ruijie Zheng, Yongyuan Liang, Furong Huang:
Who Is the Strongest Enemy? Towards Optimal and Efficient Evasion Attacks in Deep RL.
		Max Morrison, Rithesh Kumar, Kundan Kumar, Prem Seetharaman, Aaron C. Courville, Yoshua Bengio:
Chunked Autoregressive GAN for Conditional Waveform Synthesis.
		Fan Wu, Linyi Li, Huan Zhang, Bhavya Kailkhura, Krishnaram Kenthapadi, Ding Zhao, Bo Li:
COPA: Certifying Robust Policies for Offline Reinforcement Learning against Poisoning Attacks.
		Vamsi Aribandi, Yi Tay, Tal Schuster, Jinfeng Rao, Huaixiu Steven Zheng, Sanket Vaibhav Mehta, Honglei Zhuang, Vinh Q. Tran, Dara Bahri, Jianmo Ni, Jai Prakash Gupta, Kai Hui, Sebastian Ruder, Donald Metzler:
ExT5: Towards Extreme Multi-Task Scaling for Transfer Learning.
		Zhili Feng, Shaobo Han, Simon Shaolei Du:
Provable Adaptation across Multiway Domains via Representation Learning.
		John Guibas, Morteza Mardani, Zongyi Li, Andrew Tao, Anima Anandkumar, Bryan Catanzaro:
Efficient Token Mixing for Transformers via Adaptive Fourier Neural Operators.
		Xiaobo Xia, Tongliang Liu, Bo Han, Mingming Gong, Jun Yu, Gang Niu, Masashi Sugiyama:
Sample Selection with Uncertainty of Losses for Learning with Noisy Labels.
		Aviral Kumar, Amir Yazdanbakhsh, Milad Hashemi, Kevin Swersky, Sergey Levine:
Data-Driven Offline Optimization for Architecting Hardware Accelerators.
		Elise van der Pol, Herke van Hoof, Frans A. Oliehoek, Max Welling:
Multi-Agent MDP Homomorphic Networks.
		Yifan Wang, Lukas Rahmann, Olga Sorkine-Hornung:
Geometry-Consistent Neural Shape Representation with Implicit Displacement Fields.
		Dhruvesh Patel, Pavitra Dangati, Jay-Yoon Lee, Michael Boratko, Andrew McCallum:
Modeling Label Space Interactions in Multi-label Classification using Box Embeddings.
		Shashanka Venkataramanan, Bill Psomas, Ewa Kijak, Laurent Amsaleg, Konstantinos Karantzalos, Yannis Avrithis:
It Takes Two to Tango: Mixup for Deep Metric Learning.
		Bichen Wu, Ruizhe Cheng, Peizhao Zhang, Tianren Gao, Joseph E. Gonzalez, Peter Vajda:
Data Efficient Language-Supervised Zero-Shot Recognition with Optimal Transport Distillation.
		Matan Haroush, Tzviel Frostig, Ruth Heller, Daniel Soudry:
A Statistical Framework for Efficient Out of Distribution Detection in Deep Neural Networks.
		Jaehoon Oh, Sangmook Kim, Se-Young Yun:
FedBABU: Toward Enhanced Representation for Federated Image Classification.
		Aviral Kumar, Joey Hong, Anikait Singh, Sergey Levine:
Should I Run Offline Reinforcement Learning or Behavioral Cloning?
		Changmin Yu, Dong Li, Jianye Hao, Jun Wang, Neil Burgess:
Learning State Representations via Retracing in Reinforcement Learning.
		Kaidi Cao, Maria Brbic, Jure Leskovec:
Open-World Semi-Supervised Learning.
		Oliver Bryniarski, Nabeel Hingun, Pedro Pachuca, Vincent Wang, Nicholas Carlini:
Evading Adversarial Example Detection Defenses with Orthogonal Projected Gradient Descent.
		Rahul Rade, Seyed-Mohsen Moosavi-Dezfooli:
Reducing Excessive Margin to Achieve a Better Accuracy vs. Robustness Trade-off.
		Shangmin Guo, Yi Ren, Kory Wallace Mathewson, Simon Kirby, Stefano V. Albrecht, Kenny Smith:
Expressivity of Emergent Languages is a Trade-off between Contextual Complexity and Unpredictability.
		Jieru Mei, Yucheng Han, Yutong Bai, Yixiao Zhang, Yingwei Li, Xianhang Li, Alan L. Yuille, Cihang Xie:
Fast AdvProp.
		Justin Y. Chen, Talya Eden, Piotr Indyk, Honghao Lin, Shyam Narayanan, Ronitt Rubinfeld, Sandeep Silwal, Tal Wagner, David P. Woodruff, Michael Zhang:
Triangle and Four Cycle Counting with Predictions in Graph Streams.
		Natalie Dullerud, Karsten Roth, Kimia Hamidieh, Nicolas Papernot, Marzyeh Ghassemi:
Is Fairness Only Metric Deep? Evaluating and Addressing Subgroup Gaps in Deep Metric Learning.
		Mikhail Galkin, Etienne G. Denis, Jiapeng Wu, William L. Hamilton:
NodePiece: Compositional and Parameter-Efficient Representations of Large Knowledge Graphs.
		Ting Chen, Saurabh Saxena, Lala Li, David J. Fleet, Geoffrey E. Hinton:
Pix2seq: A Language Modeling Framework for Object Detection.
		Kazusato Oko, Taiji Suzuki, Atsushi Nitanda, Denny Wu:
Particle Stochastic Dual Coordinate Ascent: Exponential convergent algorithm for mean field neural network optimization.
		Divyansh Pareek, Andrej Risteski:
The Effects of Invertibility on the Representational Complexity of Encoders in Variational Autoencoders.
		Aleksandr Podkopaev, Aaditya Ramdas:
Tracking the risk of a deployed model and detecting harmful distribution shifts.
		Hongyan Bao, Yufei Han, Yujun Zhou, Yun Shen, Xiangliang Zhang:
Towards Understanding the Robustness Against Evasion Attack on Categorical Data.
		Blake Bordelon, Cengiz Pehlevan:
Learning Curves for SGD on Structured Features.
		Chengyue Gong, Dilin Wang, Meng Li, Xinlei Chen, Zhicheng Yan, Yuandong Tian, Qiang Liu, Vikas Chandra:
NASViT: Neural Architecture Search for Efficient Vision Transformers with Gradient Conflict aware Supernet Training.
		Mahalakshmi Sabanayagam, Leena Chennuru Vankadara, Debarghya Ghoshdastidar:
Graphon based Clustering and Testing of Networks: Algorithms and Theory.
		Han Cai, Chuang Gan, Ji Lin, Song Han:
Network Augmentation for Tiny Deep Learning.
		Sarath Sreedharan, Utkarsh Soni, Mudit Verma, Siddharth Srivastava, Subbarao Kambhampati:
Bridging the Gap: Providing Post-Hoc Symbolic Explanations for Sequential Decision-Making Problems with Inscrutable Representations.
		Yudong Luo, Guiliang Liu, Haonan Duan, Oliver Schulte, Pascal Poupart:
Distributional Reinforcement Learning with Monotonic Splines.
		Seyed Omid Davoudi, Majid Komeili:
Toward Faithful Case-based Reasoning through Learning Prototypes in a Nearest Neighbor-friendly Space.
		Xiongjie Chen, Yongxin Yang, Yunpeng Li:
Augmented Sliced Wasserstein Distances.
		Kuang-Hung Liu:
Relational Learning with Variational Bayes.
		Dimitar Iliev Dimitrov, Gagandeep Singh, Timon Gehr, Martin T. Vechev:
Provably Robust Adversarial Examples.
		Chris Harris, Richard Pymar, Colin Rowat:
Joint Shapley values: a measure of joint feature importance.
		Rafid Mahmood, Sanja Fidler, Marc T. Law:
Low-Budget Active Learning via Wasserstein Distance: An Integer Programming Approach.
		Chunyuan Li, Jianwei Yang, Pengchuan Zhang, Mei Gao, Bin Xiao, Xiyang Dai, Lu Yuan, Jianfeng Gao:
Efficient Self-supervised Vision Transformers for Representation Learning.
		Lukas Schott, Julius von Kügelgen, Frederik Träuble, Peter Vincent Gehler, Chris Russell, Matthias Bethge, Bernhard Schölkopf, Francesco Locatello, Wieland Brendel:
Visual Representation Learning Does Not Generalize Strongly Within the Same Domain.
		Arda Sahiner, Tolga Ergen, Batu Ozturkler, Burak Bartan, John M. Pauly, Morteza Mardani, Mert Pilanci:
Hidden Convexity of Wasserstein GANs: Interpretable Generative Models with Closed-Form Solutions.
		Paul-Aymeric Martin McRae, Prasanna Parthasarathi, Mido Assran, Sarath Chandar:
Memory Augmented Optimizers for Deep Learning.
		Mehdi Fatemi, Arash Tavakoli:
Orchestrated Value Mapping for Reinforcement Learning.
		Zehao Xiao, Xiantong Zhen, Ling Shao, Cees G. M. Snoek:
Learning to Generalize across Domains on Single Test Samples.
		Tianqin Li, Zijie Li, Andrew Luo, Harold Rockwell, Amir Barati Farimani, Tai Sing Lee:
Prototype memory and attention mechanisms for few shot image generation.
		Zijie Li, Tianqin Li, Amir Barati Farimani:
TPU-GAN: Learning temporal coherence from dynamic point cloud sequences.
		Ted Moskovitz, Spencer R. Wilson, Maneesh Sahani:
A First-Occupancy Representation for Reinforcement Learning.
		Boris Hanin, Ryan S. Jeong, David Rolnick:
Deep ReLU Networks Preserve Expected Length.
		Sidak Pal Singh, Aurélien Lucchi, Thomas Hofmann, Bernhard Schölkopf:
Phenomenology of Double Descent in Finite-Width Neural Networks.
		Shaked Brody, Uri Alon, Eran Yahav:
How Attentive are Graph Attention Networks?
		Tingfeng Li, Shaobo Han, Martin Renqiang Min, Dimitris N. Metaxas:
Learning Transferable Reward for Query Object Localization with Policy Adaptation.
		David W. Romero, Anna Kuzina, Erik J. Bekkers, Jakub Mikolaj Tomczak, Mark Hoogendoorn:
CKConv: Continuous Kernel Convolution For Sequential Data.
		Yibo Yang, Stephan Mandt:
Towards Empirical Sandwich Bounds on the Rate-Distortion Function.
		Panagiotis Kyriakis, Jyotirmoy Deshmukh, Paul Bogdan:
Pareto Policy Adaptation.
		Mislav Balunovic, Anian Ruoss, Martin T. Vechev:
Fair Normalizing Flows.
		Yifei Wang, Mert Pilanci:
The Convex Geometry of Backpropagation: Neural Network Gradient Flows Converge to Extreme Points of the Dual Convex Program.
		Hao Huang, Yi Fang:
Adaptive Wavelet Transformer Network for 3D Shape Representation Learning.
		Ruinan Jin, Yu Xing, Xingkang He:
On the Convergence of mSGD and AdaGrad for Stochastic Optimization.
		Tianrong Chen, Guan-Horng Liu, Evangelos A. Theodorou:
Likelihood Training of Schrödinger Bridge using Forward-Backward SDEs Theory.
		Tanmay Gangwani, Yuan Zhou, Jian Peng:
Imitation Learning from Observations under Transition Model Disparity.
		Erik Nijkamp, Ruiqi Gao, Pavel Sountsov, Srinivas Vasudevan, Bo Pang, Song-Chun Zhu, Ying Nian Wu:
MCMC Should Mix: Learning Energy-Based Model with Neural Transport Latent Space MCMC.
		Steven James, Benjamin Rosman, George Konidaris:
Autonomous Learning of Object-Centric Abstractions for High-Level Planning.
		Vien V. Mai, Jacob Lindbäck, Mikael Johansson:
A fast and accurate splitting method for optimal transport: analysis and implementation.
		Benjamin Bowman, Guido Montúfar:
Implicit Bias of MSE Gradient Optimization in Underparameterized Neural Networks.
		Fahim Dalvi, Abdul Rafae Khan, Firoj Alam, Nadir Durrani, Jia Xu, Hassan Sajjad:
Discovering Latent Concepts Learned in BERT.
		Rahim Entezari, Hanie Sedghi, Olga Saukh, Behnam Neyshabur:
The Role of Permutation Invariance in Linear Mode Connectivity of Neural Networks.
		Evani Radiya-Dixit, Sanghyun Hong, Nicholas Carlini, Florian Tramèr:
Data Poisoning Won't Save You From Facial Recognition.
		Agrim Gupta, Linxi Fan, Surya Ganguli, Li Fei-Fei:
MetaMorph: Learning Universal Controllers with Transformers.
		Armen Aghajanyan, Dmytro Okhonko, Mike Lewis, Mandar Joshi, Hu Xu, Gargi Ghosh, Luke Zettlemoyer:
HTLM: Hyper-Text Pre-Training and Prompting of Language Models.
		Gautam Singh, Fei Deng, Sungjin Ahn:
Illiterate DALL-E Learns to Compose.
		Alexander Pan, Kush Bhatia, Jacob Steinhardt:
The Effects of Reward Misspecification: Mapping and Mitigating Misaligned Models.
		Li Ding, Lee Spector:
Optimizing Neural Networks with Gradient Lexicase Selection.
		Ilya Kostrikov, Ashvin Nair, Sergey Levine:
Offline Reinforcement Learning with Implicit Q-Learning.
		Farzin Haddadpour, Mohammad Mahdi Kamani, Mehrdad Mahdavi, Amin Karbasi:
Learning Distributionally Robust Models at Scale via Composite Optimization.
		Ngoc Bui, Duy Nguyen, Viet Anh Nguyen:
Counterfactual Plans under Distributional Ambiguity.
		Bryan A. Plummer, Nikoli Dryden, Julius Frost, Torsten Hoefler, Kate Saenko:
Neural Parameter Allocation Search.
		Gaurav Gupta, Xiongye Xiao, Radu Balan, Paul Bogdan:
Non-Linear Operator Approximations for Initial Value Problems.
		Safa Alver, Doina Precup:
Constructing a Good Behavior Basis for Transfer using Generalized Policy Updates.
		Mohamad Shahbazi, Martin Danelljan, Danda Pani Paudel, Luc Van Gool:
Collapse by Conditioning: Training Class-conditional GANs with Limited Data.
		Ali Kavis, Kfir Yehuda Levy, Volkan Cevher:
High Probability Bounds for a Class of Nonconvex Algorithms with AdaGrad Stepsize.
		Sugandha Sharma, Aidan Curtis, Marta Kryven, Joshua B. Tenenbaum, Ila R. Fiete:
Map Induction: Compositional spatial submap learning for efficient exploration in novel environments.
		Lingjiao Chen, Matei Zaharia, James Zou:
How Did the Model Change? Efficiently Assessing Machine Learning API Shifts.
		Jianwen Xie, Yaxuan Zhu, Jun Li, Ping Li:
A Tale of Two Flows: Cooperative Learning of Langevin Flow and Normalizing Flow Toward Energy-Based Model.
		Vikash Sehwag, Saeed Mahloujifar, Tinashe Handina, Sihui Dai, Chong Xiang, Mung Chiang, Prateek Mittal:
Robust Learning Meets Generative Models: Can Proxy Distributions Improve Adversarial Robustness?
		Yifei Wang, Qi Zhang, Yisen Wang, Jiansheng Yang, Zhouchen Lin:
Chaos is a Ladder: A New Theoretical Understanding of Contrastive Learning via Augmentation Overlap.
		Yoann Lemesle, Masataka Sawayama, Guillermo Valle Pérez, Maxime Adolphe, Hélène Sauzéon, Pierre-Yves Oudeyer:
Language-biased image classification: evaluation based on semantic representations.
		Liam H. Fowl, Jonas Geiping, Wojciech Czaja, Micah Goldblum, Tom Goldstein:
Robbing the Fed: Directly Obtaining Private Data in Federated Learning with Modified Models.
		Stratis Markou, James Requeima, Wessel P. Bruinsma, Anna Vaughan, Richard E. Turner:
Practical Conditional Neural Process Via Tractable Dependent Predictions.
		Xinran Liang, Katherine Shu, Kimin Lee, Pieter Abbeel:
Reward Uncertainty for Exploration in Preference-based Reinforcement Learning.
		Prashant Khanduri, Haibo Yang, Mingyi Hong, Jia Liu, Hoi-To Wai, Sijia Liu:
Decentralized Learning for Overparameterized Problems: A Multi-Agent Kernel Approximation Approach.
		Shashank Rajput, Kangwook Lee, Dimitris S. Papailiopoulos:
Permutation-Based SGD: Is Random Optimal?
		Shichang Zhang, Yozen Liu, Yizhou Sun, Neil Shah:
Graph-less Neural Networks: Teaching Old MLPs New Tricks Via Distillation.
		James C. R. Whittington, Joseph Warren, Tim E. J. Behrens:
Relating transformers to models and neural representations of the hippocampal formation.
		Brett W. Larsen, Stanislav Fort, Nic Becker, Surya Ganguli:
How many degrees of freedom do we need to train deep networks: a loss landscape perspective.
		Ke Alexander Wang, Niladri Shekhar Chatterji, Saminul Haque, Tatsunori Hashimoto:
Is Importance Weighting Incompatible with Interpolating Classifiers?
		Yatin Nandwani, Vidit Jain, Mausam, Parag Singla:
Neural Models for Output-Space Invariance in Combinatorial Problems.
		Jiatao Gu, Lingjie Liu, Peng Wang, Christian Theobalt:
StyleNeRF: A Style-based 3D Aware Generator for High-resolution Image Synthesis.
		Frederik Träuble, Andrea Dittadi, Manuel Wuthrich, Felix Widmaier, Peter Vincent Gehler, Ole Winther, Francesco Locatello, Olivier Bachem, Bernhard Schölkopf, Stefan Bauer:
The Role of Pretrained Representations for the OOD Generalization of RL Agents.
		Wang Ling, Wojciech Stokowiec, Domenic Donato, Chris Dyer, Lei Yu, Laurent Sartran, Austin Matthews:
Enabling Arbitrary Translation Objectives with Adaptive Tree Search.
		Jesse Michael Han, Jason Rute, Yuhuai Wu, Edward W. Ayers, Stanislas Polu:
Proof Artifact Co-Training for Theorem Proving with Language Models.
		Manan Tomar, Lior Shani, Yonathan Efroni, Mohammad Ghavamzadeh:
Mirror Descent Policy Optimization.
		Justin Gilmer, Behrooz Ghorbani, Ankush Garg, Sneha Kudugunta, Behnam Neyshabur, David Cardoze, George Edward Dahl, Zachary Nado, Orhan Firat:
A Loss Curvature Perspective on Training Instabilities of Deep Learning Models.
		Arnaud Fickinger, Samuel Cohen, Stuart Russell, Brandon Amos:
Cross-Domain Imitation Learning via Optimal Transport.
		Shantanu Thakoor, Corentin Tallec, Mohammad Gheshlaghi Azar, Mehdi Azabou, Eva L. Dyer, Rémi Munos, Petar Velickovic, Michal Valko:
Large-Scale Representation Learning on Graphs via Bootstrapping.
		Scott Alexander Cameron, Tyron Luke Cameron, Arnu Pretorius, Stephen J. Roberts:
Robust and Scalable SDE Learning: A Functional Perspective.
		Mingyu Kim, Kyeongryeol Go, Se-Young Yun:
Neural Processes with Stochastic Attention: Paying more attention to the context dataset.
		Raphaël Dang-Nhu:
Evaluating Disentanglement of Structured Representations.
		Alex Morehead, Chen Chen, Jianlin Cheng:
Geometric Transformers for Protein Interface Contact Prediction.
		Chen Zhu, Zheng Xu, Mingqing Chen, Jakub Konecný, Andrew Hard, Tom Goldstein:
Diurnal or Nocturnal? Federated Learning of Multi-branch Networks from Periodically Shifting Distributions.
		S. Deepak Narayanan, Aditya Sinha, Prateek Jain, Purushottam Kar, Sundararajan Sellamanickam:
IGLU: Efficient GCN Training via Lazy Updates.
		Ankesh Anand, Jacob C. Walker, Yazhe Li, Eszter Vértes, Julian Schrittwieser, Sherjil Ozair, Theophane Weber, Jessica B. Hamrick:
Procedural generalization by planning with self-supervised world models.
		Clément Vignac, Pascal Frossard:
Top-N: Equivariant Set and Graph Generation without Exchangeability.
		Moulik Choraria, Leello Tadesse Dadi, Grigorios Chrysos, Julien Mairal, Volkan Cevher:
The Spectral Bias of Polynomial Neural Networks.
		Chaochao Lu, Yuhuai Wu, José Miguel Hernández-Lobato, Bernhard Schölkopf:
Invariant Causal Representation Learning for Out-of-Distribution Generalization.
		Chengwei Qin, Shafiq R. Joty:
LFPT5: A Unified Framework for Lifelong Few-shot Language Learning Based on Prompt Tuning of T5.
		Xinting Hu, Yulei Niu, Chunyan Miao, Xian-Sheng Hua, Hanwang Zhang:
On Non-Random Missing Labels in Semi-Supervised Learning.
		Matthieu Kirchmeyer, Alain Rakotomamonjy, Emmanuel de Bézenac, Patrick Gallinari:
Mapping conditional distributions for domain adaptation under generalized target shift.
		Ziqiao Wang, Yongyi Mao:
On the Generalization of Models Trained with SGD: Information-Theoretic Bounds and Implications.
		Michael Arbel, Julien Mairal:
Amortized Implicit Differentiation for Stochastic Bilevel Optimization.
		Yiyang Zhao, Linnan Wang, Kevin Yang, Tianjun Zhang, Tian Guo, Yuandong Tian:
Multi-objective Optimization by Learning Space Partition.
		Roma Patel, Ellie Pavlick:
Mapping Language Models to Grounded Conceptual Spaces.
		Mostafa Dehghani, Yi Tay, Anurag Arnab, Lucas Beyer, Ashish Vaswani:
The Efficiency Misnomer.
		Tuan Anh Le, Katherine M. Collins, Luke Hewitt, Kevin Ellis, Siddharth Narayanaswamy, Samuel Gershman, Joshua B. Tenenbaum:
Hybrid Memoised Wake-Sleep: Approximate Inference at the Discrete-Continuous Interface.
		Hang Zhang, Yeyun Gong, Yelong Shen, Jiancheng Lv, Nan Duan, Weizhu Chen:
Adversarial Retriever-Ranker for Dense Text Retrieval.
		Alberto Gil Couto Pimentel Ramos, Abhinav Mehrotra, Nicholas Donald Lane, Sourav Bhattacharya:
Conditioning Sequence-to-sequence Networks with Learned Activations.
		Huan Liu, George Zhang, Jun Chen, Ashish J. Khisti:
Lossy Compression with Distribution Shift as Entropy Constrained Optimal Transport.
		Rumen Dangovski, Li Jing, Charlotte Loh, Seungwook Han, Akash Srivastava, Brian Cheung, Pulkit Agrawal, Marin Soljacic:
Equivariant Self-Supervised Learning: Encouraging Equivariance in Representations.
		Pierre-Alexandre Kamienny, Jean Tarbouriech, Sylvain Lamprier, Alessandro Lazaric, Ludovic Denoyer:
Direct then Diffuse: Incremental Unsupervised Skill Discovery for State Covering and Goal Reaching.
		Prince Osei Aboagye, Yan Zheng, Chin-Chia Michael Yeh, Junpeng Wang, Wei Zhang, Liang Wang, Hao Yang, Jeff M. Phillips:
Normalization of Language Embeddings for Cross-Lingual Alignment.
		Bohang Zhang, Du Jiang, Di He, Liwei Wang:
Boosting the Certified Robustness of L-infinity Distance Nets.
		Jonas Geiping, Micah Goldblum, Phillip Pope, Michael Moeller, Tom Goldstein:
Stochastic Training is Not Necessary for Generalization.
		Yanchao Sun, Ruijie Zheng, Xiyao Wang, Andrew E. Cohen, Furong Huang:
Transfer RL across Observation Feature Spaces via Model-Based Regularization.
		Poornima Ramesh, Jan-Matthis Lueckmann, Jan Boelts, Álvaro Tejero-Cantero, David S. Greenberg, Pedro J. Gonçalves, Jakob H. Macke:
GATSBI: Generative Adversarial Training for Simulation-Based Inference.
		David Acuna, Marc T. Law, Guojun Zhang, Sanja Fidler:
Domain Adversarial Training: A Game Perspective.
		Minyoung Kim:
Differentiable Expectation-Maximization for Set Representation Learning.
		Ge Yang, Anurag Ajay, Pulkit Agrawal:
Overcoming The Spectral Bias of Neural Value Approximation.
		Milad Alizadeh, Shyam A. Tailor, Luisa M. Zintgraf, Joost van Amersfoort, Sebastian Farquhar, Nicholas Donald Lane, Yarin Gal:
Prospect Pruning: Finding Trainable Weights at Initialization using Meta-Gradients.
		Glen Berseth, Zhiwei Zhang, Grace Zhang, Chelsea Finn, Sergey Levine:
CoMPS: Continual Meta Policy Search.
		Antoine Brochard, Sixin Zhang, Stéphane Mallat:
Generalized rectifier wavelet covariance models for texture synthesis.
		Jiefeng Chen, Xi Wu, Yang Guo, Yingyu Liang, Somesh Jha:
Towards Evaluating the Robustness of Neural Networks Learned by Transduction.
		Qu Tang, Xiangyu Zhu, Zhen Lei, Zhaoxiang Zhang:
Object Dynamics Distillation for Scene Decomposition and Representation.
		Christopher M. Bender, Patrick Emmanuel, Michael K. Reiter, Junier Oliva:
Practical Integration via Separable Bijective Networks.
		Navid Kardan, Mubarak Shah, Mitch Hill:
Self-Joint Supervised Learning.
		Yutong Feng, Jianwen Jiang, Mingqian Tang, Rong Jin, Yue Gao:
Rethinking Supervised Pre-Training for Better Downstream Transferring.
		Hengrui Jia, Hongyu Chen, Jonas Guan, Ali Shahin Shamsabadi, Nicolas Papernot:
A Zest of LIME: Towards Architecture-Independent Model Distances.
		Jiayi Li, Tao Lu, Xiaoge Cao, Yinghao Cai, Shuo Wang:
Meta-Imitation Learning by Watching Video Demonstrations.
		Xiao Zhang, David E. Evans:
Understanding Intrinsic Robustness Using Label Uncertainty.
		Junyuan Hong, Haotao Wang, Zhangyang Wang, Jiayu Zhou:
Efficient Split-Mix Federated Learning for On-Demand and In-Situ Customization.
		Jordan T. Ash, Cyril Zhang, Surbhi Goel, Akshay Krishnamurthy, Sham M. Kakade:
Anti-Concentrated Confidence Bonuses For Scalable Exploration.
		Ruilin Li, Hongyuan Zha, Molei Tao:
Sqrt(d) Dimension Dependence of Langevin Monte Carlo.
		Tao Huang, Zekang Li, Hua Lu, Yong Shan, Shusheng Yang, Yang Feng, Fei Wang, Shan You, Chang Xu:
Relational Surrogate Loss Learning.
		Sunghoon Hong, Deunsol Yoon, Kee-Eung Kim:
Structure-Aware Transformer Policy for Inhomogeneous Multi-Task Reinforcement Learning.
		Sunwoo Lee, Jeongwoo Park, Dongsuk Jeon:
Toward Efficient Low-Precision Training: Data Format Optimization and Hysteresis Quantization.
		Ruibo Liu, Guoqing Zheng, Shashank Gupta, Radhika Gaonkar, Chongyang Gao, Soroush Vosoughi, Milad Shokouhi, Ahmed Hassan Awadallah:
Knowledge Infused Decoding.
		Euhyun Moon, Eric C. Cyr:
Parallel Training of GRU Networks with a Multi-Grid Solver for Long Sequences.
		Viet Quoc Vo, Ehsan Abbasnejad, Damith Ranasinghe:
Query Efficient Decision Based Sparse Attacks Against Black-Box Deep Learning Models.
		Jinyuan Jia, Binghui Wang, Xiaoyu Cao, Hongbin Liu, Neil Zhenqiang Gong:
Almost Tight L0-norm Certified Robustness of Top-k Predictions against Adversarial Perturbations.
		Arthur C. W. da Cunha, Emanuele Natale, Laurent Viennot:
Proving the Lottery Ticket Hypothesis for Convolutional Neural Networks.
		Chengping Rao, Pu Ren, Yang Liu, Hao Sun:
Discovering Nonlinear PDEs from Scarce Data with Physics-encoded Learning.
		Rui Yang, Yiming Lu, Wenzhe Li, Hao Sun, Meng Fang, Yali Du, Xiu Li, Lei Han, Chongjie Zhang:
Rethinking Goal-Conditioned Supervised Learning and Its Connection to Offline RL.
		Robin Vandaele, Bo Kang, Jefrey Lijffijt, Tijl De Bie, Yvan Saeys:
Topologically Regularized Data Embeddings.
		Mohammed Haroon Dupty, Yanfei Dong, Wee Sun Lee:
PF-GNN: Differentiable particle filtering based approximation of universal graph representations.
		Xiaojiang Yang, Yi Wang, Jiacheng Sun, Xing Zhang, Shifeng Zhang, Zhenguo Li, Junchi Yan:
Nonlinear ICA Using Volume-Preserving Transformations.
		Pengjie Gu, Mengchen Zhao, Jianye Hao, Bo An:
Online Ad Hoc Teamwork under Partial Observability.
		Quang Pham, Chenghao Liu, Steven C. H. Hoi:
Continual Normalization: Rethinking Batch Normalization for Online Continual Learning.
		Wenbing Huang, Jiaqi Han, Yu Rong, Tingyang Xu, Fuchun Sun, Junzhou Huang:
Equivariant Graph Mechanics Networks with Constraints.
		Joel Jang, Seonghyeon Ye, Sohee Yang, Joongbo Shin, Janghoon Han, Gyeonghun Kim, Stanley Jungkyu Choi, Minjoon Seo:
Towards Continual Knowledge Learning of Language Models.
		Zhijian Yang, Junhao Wen, Christos Davatzikos:
Surreal-GAN: Semi-Supervised Representation Learning via GAN for uncovering heterogeneous disease-related imaging patterns.
		Jongjin Park, Younggyo Seo, Jinwoo Shin, Honglak Lee, Pieter Abbeel, Kimin Lee:
SURF: Semi-supervised Reward Learning with Data Augmentation for Feedback-efficient Preference-based Reinforcement Learning.
		Junyoung Park, Jinhyun Choo, Jinkyoo Park:
Convergent Graph Solvers.
		Jun Hyun Nam, Jaehyung Kim, Jaeho Lee, Jinwoo Shin:
Spread Spurious Attribute: Improving Worst-group Accuracy with Spurious Attribute Estimation.
		Yaoxin Wu, Wen Song, Zhiguang Cao, Jie Zhang:
Learning Scenario Representation for Solving Two-stage Stochastic Integer Programs.
		Gregor Bachmann, Thomas Hofmann, Aurélien Lucchi:
Generalization Through the Lens of Leave-One-Out Error.
		David Ruhe, Patrick Forré:
Self-Supervised Inference in State-Space Models.
		Tomer Galanti, András György, Marcus Hutter:
On the Role of Neural Collapse in Transfer Learning.
		Shengyang Sun, Daniele Calandriello, Huiyi Hu, Ang Li, Michalis K. Titsias:
Information-theoretic Online Memory Selection for Continual Learning.
		Wenhao Li, Xiangfeng Wang, Bo Jin, Junjie Sheng, Hongyuan Zha:
Dealing with Non-Stationarity in MARL via Trust-Region Decomposition.
		Stephan Sloth Lorenzen, Christian Igel, Mads Nielsen:
Information Bottleneck: Exact Analysis of (Quantized) Neural Networks.
		Xiyuan Wang, Muhan Zhang:
GLASS: GNN with Labeling Tricks for Subgraph Representation Learning.
		Arman Hasanzadeh, Ehsan Hajiramezanali, Nick Duffield, Xiaoning Qian:
MoReL: Multi-omics Relational Learning.
		Xinshi Chen, Haoran Sun, Le Song:
Provable Learning-based Algorithm For Sparse Recovery.
		Dan Andrei Calian, Florian Stimberg, Olivia Wiles, Sylvestre-Alvise Rebuffi, András György, Timothy A. Mann, Sven Gowal:
Defending Against Image Corruptions Through Adversarial Augmentations.
		Nicholas A. Lord, Romain Müller, Luca Bertinetto:
Attacking deep networks with surrogate-based adversarial black-box methods is easy.
		Emiel Hoogeboom, Alexey A. Gritsenko, Jasmijn Bastings, Ben Poole, Rianne van den Berg, Tim Salimans:
Autoregressive Diffusion Models.
		Wuyang Chen, Wei Huang, Xianzhi Du, Xiaodan Song, Zhangyang Wang, Denny Zhou:
Auto-scaling Vision Transformers without Training.
		Deshan Gong, Zhanxing Zhu, Andrew J. Bulpitt, He Wang:
Fine-grained Differentiable Physics: A Yarn-level Model for Fabrics.
		Dihong Jiang, Sun Sun, Yaoliang Yu:
Revisiting flow generative models for Out-of-distribution detection.
		Saachi Jain, Hadi Salman, Eric Wong, Pengchuan Zhang, Vibhav Vineet, Sai Vemprala, Aleksander Madry:
Missingness Bias in Model Debugging.
		Jeffrey Ryan Willette, Hae Beom Lee, Juho Lee, Sung Ju Hwang:
Meta Learning Low Rank Covariance Factors for Energy Based Deterministic Uncertainty.
		Thomas Kipf, Gamaleldin Fathy Elsayed, Aravindh Mahendran, Austin Stone, Sara Sabour, Georg Heigold, Rico Jonschkowski, Alexey Dosovitskiy, Klaus Greff:
Conditional Object-Centric Learning from Video.
		Yi Tay, Mostafa Dehghani, Jinfeng Rao, William Fedus, Samira Abnar, Hyung Won Chung, Sharan Narang, Dani Yogatama, Ashish Vaswani, Donald Metzler:
Scale Efficiently: Insights from Pretraining and Finetuning Transformers.
		Ari Seff, Wenda Zhou, Nick Richardson, Ryan P. Adams:
Vitruvion: A Generative Model of Parametric CAD Sketches.
		Samar Hadou, Charilaos I. Kanatsoulis, Alejandro Ribeiro:
Space-Time Graph Neural Networks.
		Jason D. McEwen, Christopher G. R. Wallis, Augustine N. Mavor-Parker:
Scattering Networks on the Sphere for Scalable and Rotationally Equivariant Spherical CNNs.
		Vincent Fortuin, Adrià Garriga-Alonso, Sebastian W. Ober, Florian Wenzel, Gunnar Rätsch, Richard E. Turner, Mark van der Wilk, Laurence Aitchison:
Bayesian Neural Network Priors Revisited.
		Lorenzo Moro, Amarildo Likmeta, Enrico Prati, Marcello Restelli:
Goal-Directed Planning via Hindsight Experience Replay.
		Krzysztof Marcin Choromanski, Han Lin, Haoxian Chen, Arijit Sehanobish, Yuanzhe Ma, Deepali Jain, Jake Varley, Andy Zeng, Michael S. Ryoo, Valerii Likhosherstov, Dmitry Kalashnikov, Vikas Sindhwani, Adrian Weller:
Hybrid Random Features.
		Tongtong Wu, Massimo Caccia, Zhuang Li, Yuan-Fang Li, Guilin Qi, Gholamreza Haffari:
Pretrained Language Model in Continual Learning: A Comparative Study.
		Sahil Singla, Soheil Feizi:
Salient ImageNet: How to discover spurious features in Deep Learning?
		Bertrand Charpentier, Simon Kibler, Stephan Günnemann:
Differentiable DAG Sampling.
		Arunkumar Byravan, Leonard Hasenclever, Piotr Trochim, Mehdi Mirza, Alessandro Davide Ialongo, Yuval Tassa, Jost Tobias Springenberg, Abbas Abdolmaleki, Nicolas Heess, Josh Merel, Martin A. Riedmiller:
Evaluating Model-Based Planning and Planner Amortization for Continuous Control.
		Kourosh Hakhamaneshi, Ruihan Zhao, Albert Zhan, Pieter Abbeel, Michael Laskin:
Hierarchical Few-Shot Imitation with Skill Transition Models.
		Daniel Zügner, Bertrand Charpentier, Morgane Ayle, Sascha Geringer, Stephan Günnemann:
End-to-End Learning of Probabilistic Hierarchies on Graphs.
		Arash Mehrjou, Ashkan Soleymani, Andrew Jesson, Pascal Notin, Yarin Gal, Stefan Bauer, Patrick Schwab:
GeneDisco: A Benchmark for Experimental Design in Drug Discovery.
		Joonhyung Park, Jaeyun Song, Eunho Yang:
GraphENS: Neighbor-Aware Ego Network Synthesis for Class-Imbalanced Node Classification.
		Zihan Zhou, Wei Fu, Bingliang Zhang, Yi Wu:
Continuously Discovering Novel Strategies via Reward-Switching Policy Optimization.
		Hyunwook Lee, Seungmin Jin, Hyeshin Chu, Hongkyu Lim, Sungahn Ko:
Learning to Remember Patterns: Pattern Matching Memory Networks for Traffic Forecasting.
		Yangkun Wang, Jiarui Jin, Weinan Zhang, Yongyi Yang, Jiuhai Chen, Quan Gan, Yong Yu, Zheng Zhang, Zengfeng Huang, David Wipf:
Why Propagate Alone? Parallel Use of Labels and Features on Graphs.
		David Silver, Anirudh Goyal, Ivo Danihelka, Matteo Hessel, Hado van Hasselt:
Learning by Directional Gradient Descent.
		Benjamin Eysenbach, Sergey Levine:
Maximum Entropy RL (Provably) Solves Some Robust RL Problems.
		Yifei Wang, Yisen Wang, Jiansheng Yang, Zhouchen Lin:
A Unified Contrastive Energy-based Model for Understanding the Generative Ability of Adversarial Training.
		Haorui Wang, Haoteng Yin, Muhan Zhang, Pan Li:
Equivariant and Stable Positional Encoding for More Powerful Graph Neural Networks.
		Kangjie Chen, Yuxian Meng, Xiaofei Sun, Shangwei Guo, Tianwei Zhang, Jiwei Li, Chun Fan:
BadPre: Task-agnostic Backdoor Attacks to Pre-trained NLP Foundation Models.
		Moïse Blanchard, Mohammed Amine Bennouna:
Shallow and Deep Networks are Near-Optimal Approximators of Korobov Functions.
		Jaehyung Kim, Dongyeop Kang, Sungsoo Ahn, Jinwoo Shin:
What Makes Better Augmentation Strategies? Augment Difficult but Not too Different.
		Kha Pham, Hung Le, Man Ngo, Truyen Tran, Bao Ho, Svetha Venkatesh:
Generative Pseudo-Inverse Memory.
		Laura Manduchi, Ricards Marcinkevics, Michela Carlotta Massi, Thomas J. Weikert, Alexander Sauter, Verena Gotta, Timothy Müller, Flavio Vasella, Marian C. Neidert, Marc Pfister, Bram Stieltjes, Julia E. Vogt:
A Deep Variational Approach to Clustering Survival Data.
		Youngsoo Jang, Jongmin Lee, Kee-Eung Kim:
GPT-Critic: Offline Reinforcement Learning for End-to-End Task-Oriented Dialogue Systems.
		Yi Tay, Vinh Q. Tran, Sebastian Ruder, Jai Prakash Gupta, Hyung Won Chung, Dara Bahri, Zhen Qin, Simon Baumgartner, Cong Yu, Donald Metzler:
Charformer: Fast Character Transformers via Gradient-based Subword Tokenization.
		Yonghyeon Lee, Sangwoong Yoon, Minjun Son, Frank Chongwoo Park:
Regularized Autoencoders for Isometric Representation Learning.
		Shaopeng Fu, Fengxiang He, Dacheng Tao:
Knowledge Removal in Sampling-based Bayesian Inference.
		Yuzheng Hu, Ziwei Ji, Matus Telgarsky:
Actor-critic is implicitly biased towards high entropy optimal policies.
		Eduardo Dadalto Câmara Gomes, Florence Alberge, Pierre Duhamel, Pablo Piantanida:
Igeood: An Information Geometry Approach to Out-of-Distribution Detection.
		Haohang Xu, Jiemin Fang, Xiaopeng Zhang, Lingxi Xie, Xinggang Wang, Wenrui Dai, Hongkai Xiong, Qi Tian:
Bag of Instances Aggregation Boosts Self-supervised Distillation.
		Adeel Pervez, Efstratios Gavves:
Stability Regularization for Discrete Representation Learning.
		Mohammad Fahes, Christophe Kervazo, Jérôme Bobin, Florence Tupin:
Unrolling PALM for Sparse Semi-Blind Source Separation.
		Tianjian Zhang, Feng Yin, Zhi-Quan Luo:
Fast Generic Interaction Detection for Model Interpretability and Compression.
		Taesung Kim, Jinhee Kim, Yunwon Tae, Cheonbok Park, Jang-Ho Choi, Jaegul Choo:
Reversible Instance Normalization for Accurate Time-Series Forecasting against Distribution Shift.
		Omer Antverg, Yonatan Belinkov:
On the Pitfalls of Analyzing Individual Neurons in Language Models.
		Dimitrios Alivanistos, Max Berrendorf, Michael Cochez, Mikhail Galkin:
Query Embedding on Hyper-Relational Knowledge Graphs.
		Federico Berto, Stefano Massaroli, Michael Poli, Jinkyoo Park:
Neural Solvers for Fast and Accurate Numerical Optimal Control.
		Paul Jeha, Michael Bohlke-Schneider, Pedro Mercado, Shubham Kapoor, Rajbir-Singh Nirwan, Valentin Flunkert, Jan Gasthaus, Tim Januschowski:
PSA-GAN: Progressive Self Attention GANs for Synthetic Time Series.
		Yuanfei Wang, Fangwei Zhong, Jing Xu, Yizhou Wang:
ToM2C: Target-oriented Multi-agent Communication and Cooperation with Theory of Mind.
		Yi Ren, Shangmin Guo, Danica J. Sutherland:
Better Supervisory Signals by Observing Learning Paths.
		Ziyuan Huang, Shiwei Zhang, Liang Pan, Zhiwu Qing, Mingqian Tang, Ziwei Liu, Marcelo H. Ang Jr.:
TAda! Temporally-Adaptive Convolutions for Video Understanding.
		Jean-Baptiste Gaya, Laure Soulier, Ludovic Denoyer:
Learning a subspace of policies for online adaptation in Reinforcement Learning.
		Xinchi Qiu, Javier Fernández-Marqués, Pedro P. B. de Gusmao, Yan Gao, Titouan Parcollet, Nicholas Donald Lane:
ZeroFL: Efficient On-Device Training for Federated Learning with Local Sparsity.
		Adam Celarek, Pedro Hermosilla, Bernhard Kerbl, Timo Ropinski, Michael Wimmer:
Gaussian Mixture Convolution Networks.
		Chaoning Zhang, Kang Zhang, Chenshuang Zhang, Trung X. Pham, Chang D. Yoo, In So Kweon:
How Does SimSiam Avoid Collapse Without Negative Samples? A Unified Understanding with Self-supervised Contrastive Learning.
		Mattia Rigotti, Christoph Miksovic, Ioana Giurgiu, Thomas Gschwind, Paolo Scotton:
Attention-based Interpretability with Concept Transformers.
		Jiarui Jin, Yangkun Wang, Kounianhua Du, Weinan Zhang, Zheng Zhang, David Wipf, Yong Yu, Quan Gan:
Inductive Relation Prediction Using Analogy Subgraph Embeddings.
		Hang Ren, Aivar Sootla, Taher Jafferjee, Junxiao Shen, Jun Wang, Haitham Bou-Ammar:
Reinforcement Learning in Presence of Discrete Markovian Context Evolution.
		Hanyu Peng, Mingming Sun, Ping Li:
Optimal Transport for Long-Tailed Recognition with Learnable Cost Matrix.
		Sang-gil Lee, Heeseung Kim, Chaehun Shin, Xu Tan, Chang Liu, Qi Meng, Tao Qin, Wei Chen, Sungroh Yoon, Tie-Yan Liu:
PriorGrad: Improving Conditional Denoising Diffusion Models with Data-Dependent Adaptive Prior.
		Shufang Xie, Ang Lv, Yingce Xia, Lijun Wu, Tao Qin, Tie-Yan Liu, Rui Yan:
Target-Side Input Augmentation for Sequence to Sequence Generation.
		Kunchang Li, Yali Wang, Peng Gao, Guanglu Song, Yu Liu, Hongsheng Li, Yu Qiao:
UniFormer: Unified Transformer for Efficient Spatial-Temporal Representation Learning.
		Alex J. Chan, Alicia Curth, Mihaela van der Schaar:
Inverse Online Learning: Understanding Non-Stationary and Reactionary Policies.
		Jicong Fan:
Multi-Mode Deep Matrix and Tensor Factorization.
		Jaehoon Lee, Jinsung Jeon, Sheo Yon Jhin, Jihyeon Hyeong, Jayoung Kim, Minju Jo, Seungji Kook, Noseong Park:
LORD: Lower-Dimensional Embedding of Log-Signature in Neural Rough Differential Equations.
		Andjela Mladenovic, Iosif Sakos, Gauthier Gidel, Georgios Piliouras:
Generalized Natural Gradient Flows in Hidden Convex-Concave Games and GANs.
		Thanh Nguyen-Tang, Sunil Gupta, A. Tuan Nguyen, Svetha Venkatesh:
Offline Neural Contextual Bandits: Pessimism, Optimization and Generalization.
		Thomas Gilles, Stefano Sabatini, Dzmitry Tsishkou, Bogdan Stanciulescu, Fabien Moutarde:
THOMAS: Trajectory Heatmap Output with learned Multi-Agent Sampling.
		Martin Mundt, Steven Lang, Quentin Delfosse, Kristian Kersting:
CLEVA-Compass: A Continual Learning Evaluation Assessment Compass to Promote Research Transparency and Comparability.
		Hanjun Dai, Yuan Xue, Zia Syed, Dale Schuurmans, Bo Dai:
Neural Stochastic Dual Dynamic Programming.
		Geon-Hyeong Kim, Seokin Seo, Jongmin Lee, Wonseok Jeon, HyeongJoo Hwang, Hongseok Yang, Kee-Eung Kim:
DemoDICE: Offline Imitation Learning with Supplementary Imperfect Demonstrations.
		Krzysztof Maziarz, Henry Richard Jackson-Flux, Pashmina Cameron, Finton Sirockin, Nadine Schneider, Nikolaus Stiefl, Marwin H. S. Segler, Marc Brockschmidt:
Learning to Extend Molecular Scaffolds with Structural Motifs.
		Antoine de Mathelin, François Deheeger, Mathilde Mougeot, Nicolas Vayatis:
Discrepancy-Based Active Learning for Domain Adaptation.
		Yuge Shi, Jeffrey Seely, Philip H. S. Torr, Siddharth Narayanaswamy, Awni Y. Hannun, Nicolas Usunier, Gabriel Synnaeve:
Gradient Matching for Domain Generalization.
		Shuo Yang, Peize Sun, Yi Jiang, Xiaobo Xia, Ruiheng Zhang, Zehuan Yuan, Changhu Wang, Ping Luo, Min Xu:
Objects in Semantic Topology.
		Vaisakh Shaj, Dieter Büchler, Rohit Sonker, Philipp Becker, Gerhard Neumann:
Hidden Parameter Recurrent State Space Models For Changing Dynamics Scenarios.
		Benjamin Hudson, Qingbiao Li, Matthew Malencia, Amanda Prorok:
Graph Neural Network Guided Local Search for the Traveling Salesperson Problem.
		Maximilian Seitzer, Arash Tavakoli, Dimitrije Antic, Georg Martius:
On the Pitfalls of Heteroscedastic Uncertainty Estimation with Probabilistic Neural Networks.
		Dmitry Baranchuk, Andrey Voynov, Ivan Rubachev, Valentin Khrulkov, Artem Babenko:
Label-Efficient Semantic Segmentation with Diffusion Models.
		Yen-Chang Hsu, Ting Hua, Sungen Chang, Qian Lou, Yilin Shen, Hongxia Jin:
Language model compression with weighted low-rank factorization.
		Xi Lin, Zhiyuan Yang, Qingfu Zhang:
Pareto Set Learning for Neural Multi-Objective Combinatorial Optimization.
		Kyungmin Lee:
Prototypical Contrastive Predictive Coding.
		Yonggang Zhang, Mingming Gong, Tongliang Liu, Gang Niu, Xinmei Tian, Bo Han, Bernhard Schölkopf, Kun Zhang:
Adversarial Robustness Through the Lens of Causality.
		Hieu Vu, Toan Tran, Man-Chung Yue, Viet Anh Nguyen:
Distributionally Robust Fair Principal Components via Geodesic Descents.
		Yongqiang Chen, Han Yang, Yonggang Zhang, Kaili Ma, Tongliang Liu, Bo Han, James Cheng:
Understanding and Improving Graph Injection Attack by Promoting Unnoticeability.
		Paul Barde, Tristan Karch, Derek Nowrouzezahrai, Clément Moulin-Frier, Christopher Pal, Pierre-Yves Oudeyer:
Learning to Guide and to be Guided in the Architect-Builder Problem.
		Florentin Guth, John Zarka, Stéphane Mallat:
Phase Collapse in Neural Networks.
		Wenyong Huang, Zhenhe Zhang, Yu Ting Yeung, Xin Jiang, Qun Liu:
SPIRAL: Self-supervised Perturbation-Invariant Representation Learning for Speech Pre-Training.
		Yuqi Liu, Bin Cao, Jing Fan:
Improving the Accuracy of Learning Example Weights for Imbalance Classification.
		Sihyun Yu, Jihoon Tack, Sangwoo Mo, Hyunsu Kim, Junho Kim, Jung-Woo Ha, Jinwoo Shin:
Generating Videos with Dynamics-aware Implicit Generative Adversarial Networks.
		Quanyi Li, Zhenghao Peng, Bolei Zhou:
Efficient Learning of Safe Driving Policy via Human-AI Copilot Optimization.
		Huiyun Yang, Huadong Chen, Hao Zhou, Lei Li:
Enhancing Cross-lingual Transfer by Manifold Mixup.
		Yutong Wang, Ke Xue, Chao Qian:
Evolutionary Diversity Optimization with Clustering-based Selection for Reinforcement Learning.
		Khang Truong Giang, Soohwan Song, Sungho Jo:
Curvature-Guided Dynamic Scale Networks for Multi-View Stereo.
		Ming Yin, Yaqi Duan, Mengdi Wang, Yu-Xiang Wang:
Near-optimal Offline Reinforcement Learning with Linear Representation: Leveraging Variance Information with Pessimism.
		Benyou Wang, Yuxin Ren, Lifeng Shang, Xin Jiang, Qun Liu:
Exploring extreme parameter compression for pre-trained language models.
		David Bertoin, Emmanuel Rachelson:
Local Feature Swapping for Generalization in Reinforcement Learning.
		Xiuye Gu, Tsung-Yi Lin, Weicheng Kuo, Yin Cui:
Open-vocabulary Object Detection via Vision and Language Knowledge Distillation.
		Sen Lin, Jialin Wan, Tengyu Xu, Yingbin Liang, Junshan Zhang:
Model-Based Offline Meta-Reinforcement Learning with Regularization.
		Hyungi Lee, Eunggu Yun, Hongseok Yang, Juho Lee:
Scale Mixtures of Neural Network Gaussian Processes.
		Ido Nachum, Jan Hazla, Michael Gastpar, Anatoly Khina:
A Johnson-Lindenstrauss Framework for Randomly Initialized CNNs.
		Ashwin Paranjape, Omar Khattab, Christopher Potts, Matei Zaharia, Christopher D. Manning:
Hindsight: Posterior-guided training of retrievers for improved open-ended generation.
		Siyi Tang, Jared Dunnmon, Khaled Kamal Saab, Xuan Zhang, Qianying Huang, Florian Dubost, Daniel L. Rubin, Christopher Lee-Messer:
Self-Supervised Graph Neural Networks for Improved Electroencephalographic Seizure Analysis.
		Pengcheng Yang, Xiaoming Zhang, Wenpeng Zhang, Ming Yang, Hong Wei:
Group-based Interleaved Pipeline Parallelism for Large-scale DNN Training.
		Sitan Chen, Jerry Li, Yuanzhi Li, Raghu Meka:
Minimax Optimality (Probably) Doesn't Imply Distribution Learning for GANs.
		Xiaoteng Ma, Yiqin Yang, Hao Hu, Jun Yang, Chongjie Zhang, Qianchuan Zhao, Bin Liang, Qihan Liu:
Offline Reinforcement Learning with Value-based Episodic Memory.
		Zhiyu Chong, Xinzhu Ma, Hong Zhang, Yuxin Yue, Haojie Li, Zhihui Wang, Wanli Ouyang:
MonoDistill: Learning Spatial Features for Monocular 3D Object Detection.
		Zirui Liu, Kaixiong Zhou, Fan Yang, Li Li, Rui Chen, Xia Hu:
EXACT: Scalable Graph Neural Networks Training via Extreme Activation Compression.
		Chao Ma, Lexing Ying:
Provably convergent quasistatic dynamics for mean-field two-player zero-sum games.
		Xingyu Cai, Jiahong Yuan, Yuchen Bian, Guangxu Xun, Jiaji Huang, Kenneth Church:
W-CTC: a Connectionist Temporal Classification Loss with Wild Cards.
		Tianchen Zhou, Jia Liu, Chaosheng Dong, Yi Sun:
Bandit Learning with Joint Effect of Incentivized Sampling, Delayed Sampling Feedback, and Self-Reinforcing User Preferences.
		Tsz-Him Cheung, Dit-Yan Yeung:
AdaAug: Learning Class- and Instance-adaptive Data Augmentation Policies.
		Mark Hamilton, Zhoutong Zhang, Bharath Hariharan, Noah Snavely, William T. Freeman:
Unsupervised Semantic Segmentation by Distilling Feature Correspondences.
		Mark Hamilton, Scott M. Lundberg, Stephanie Fu, Lei Zhang, William T. Freeman:
Axiomatic Explanations for Visual Search, Retrieval, and Similarity Learning.
		Zihao Xu, Hao He, Guang-He Lee, Bernie Wang, Hao Wang:
Graph-Relational Domain Adaptation.
		Shaochen Zhong, Guanqun Zhang, Ningjia Huang, Shuai Xu:
Revisit Kernel Pruning with Lottery Regulated Grouped Convolutions.
		Zhang-Wei Hong, Ge Yang, Pulkit Agrawal:
Bi-linear Value Networks for Multi-goal Reinforcement Learning.
		Raphael Gontijo Lopes, Yann N. Dauphin, Ekin Dogus Cubuk:
No One Representation to Rule Them All: Overlapping Features of Training Methods.
		Raaz Dwivedi, Lester Mackey:
Generalized Kernel Thinning.
		Sheng Shen, Liunian Harold Li, Hao Tan, Mohit Bansal, Anna Rohrbach, Kai-Wei Chang, Zhewei Yao, Kurt Keutzer:
How Much Can CLIP Benefit Vision-and-Language Tasks?
		Yuqing Wang, Minshuo Chen, Tuo Zhao, Molei Tao:
Large Learning Rate Tames Homogeneity: Convergence and Balancing Effect.
		Hadi Abdullah, Aditya Karlekar, Vincent Bindschaedler, Patrick Traynor:
Demystifying Limited Adversarial Transferability in Automatic Speech Recognition Systems.
		Cheng Wan, Youjie Li, Cameron R. Wolfe, Anastasios Kyrillidis, Nam Sung Kim, Yingyan Lin:
PipeGCN: Efficient Full-Graph Training of Graph Convolutional Networks with Pipelined Feature Communication.
		Yiling Jia, Weitong Zhang, Dongruo Zhou, Quanquan Gu, Hongning Wang:
Learning Neural Contextual Bandits through Perturbed Rewards.
		Yi Zeng, Si Chen, Won Park, Zhuoqing Mao, Ming Jin, Ruoxi Jia:
Adversarial Unlearning of Backdoors via Implicit Hypergradient.
		Hassam Sheikh, Mariano Phielipp, Ladislau Bölöni:
Maximizing Ensemble Diversity in Deep Reinforcement Learning.
		Vijay Prakash Dwivedi, Anh Tuan Luu, Thomas Laurent, Yoshua Bengio, Xavier Bresson:
Graph Neural Networks with Learnable Structural and Positional Representations.
		Burhaneddin Yaman, Seyed Amir Hossein Hosseini, Mehmet Akçakaya:
Zero-Shot Self-Supervised Learning for MRI Reconstruction.
		Aounon Kumar, Alexander Levine, Soheil Feizi:
Policy Smoothing for Provably Robust Reinforcement Learning.
		Renkun Ni, Manli Shu, Hossein Souri, Micah Goldblum, Tom Goldstein:
The Close Relationship Between Contrastive Learning and Meta-Learning.
		Jiaye Teng, Jianhao Ma, Yang Yuan:
Towards Understanding Generalization via Decomposing Excess Risk Dynamics.
		Mingyue Tang, Pan Li, Carl Yang:
Graph Auto-Encoder via Neighborhood Wasserstein Reconstruction.
		Tiago Salvador, Stephanie Cairns, Vikram Voleti, Noah Marshall, Adam M. Oberman:
FairCal: Fairness Calibration for Face Verification.
		Ruicheng Xian, Heng Ji, Han Zhao:
Cross-Lingual Transfer with Class-Weighted Language-Invariant Representations.
		Zhenfang Chen, Kexin Yi, Yunzhu Li, Mingyu Ding, Antonio Torralba, Joshua B. Tenenbaum, Chuang Gan:
ComPhy: Compositional Physical Reasoning of Objects and Events from Videos.
		Zhimeng Jiang, Kaixiong Zhou, Zirui Liu, Li Li, Rui Chen, Soo-Hyun Choi, Xia Hu:
An Information Fusion Approach to Learning with Instance-Dependent Label Noise.
		Xingchen Wan, Binxin Ru, Pedro M. Esperança, Zhenguo Li:
On Redundancy and Diversity in Cell-based Neural Architecture Search.
		Guodong Zhang, Aleksandar Botev, James Martens:
Deep Learning without Shortcuts: Shaping the Kernel with Tailored Rectifiers.
		Frederic Koehler, Viraj Mehta, Chenghui Zhou, Andrej Risteski:
Variational autoencoders in the presence of low-dimensional data: landscape and implicit bias.
		Chen Liang, Haoming Jiang, Simiao Zuo, Pengcheng He, Xiaodong Liu, Jianfeng Gao, Weizhu Chen, Tuo Zhao:
No Parameters Left Behind: Sensitivity Guided Adaptive Learning Rate for Training Large Transformer Models.
		Chenlin Meng, Yutong He, Yang Song, Jiaming Song, Jiajun Wu, Jun-Yan Zhu, Stefano Ermon:
SDEdit: Guided Image Synthesis and Editing with Stochastic Differential Equations.
		Julius Adebayo, Michael Muelly, Harold Abelson, Been Kim:
Post hoc Explanations may be Ineffective for Detecting Unknown Spurious Correlation.
		Shoukang Hu, Ruochen Wang, Lanqing Hong, Zhenguo Li, Cho-Jui Hsieh, Jiashi Feng:
Generalizing Few-Shot NAS with Gradient Matching.
		Shiwei Liu, Tianlong Chen, Xiaohan Chen, Li Shen, Decebal Constantin Mocanu, Zhangyang Wang, Mykola Pechenizkiy:
The Unreasonable Effectiveness of Random Pruning: Return of the Most Naive Baseline for Sparse Training.
		Zhenqiao Song, Hao Zhou, Lihua Qian, Jingjing Xu, Shanbo Cheng, Mingxuan Wang, Lei Li:
switch-GLAT: Multilingual Parallel Machine Translation Via Code-Switch Decoder.
		Qian Lou, Ting Hua, Yen-Chang Hsu, Yilin Shen, Hongxia Jin:
DictFormer: Tiny Transformer with Shared Dictionary.
		Ju-Seung Byun, Andrew Perrault:
Training Transition Policies via Distribution Matching for Complex Tasks.
		Huan He, Shifan Zhao, Yuanzhe Xi, Joyce C. Ho, Yousef Saad:
GDA-AM: On the Effectiveness of Solving Min-Imax Optimization via Anderson Mixing.
		Zhengdao Chen, Eric Vanden-Eijnden, Joan Bruna:
On feature learning in neural networks with global convergence guarantees.
		Nikhil Ghosh, Song Mei, Bin Yu:
The Three Stages of Learning Dynamics in High-dimensional Kernel Methods.
		Ziang Song, Song Mei, Yu Bai:
When Can We Learn General-Sum Markov Games with a Large Number of Players Sample-Efficiently?
		Alexander Atanasov, Blake Bordelon, Cengiz Pehlevan:
Neural Networks as Kernel Learners: The Silent Alignment Effect.
		Guiliang Liu, Ashutosh Adhikari, Amir-massoud Farahmand, Pascal Poupart:
Learning Object-Oriented Dynamics for Planning from Text.
		William T. Redman, Maria Fonoberova, Ryan Mohr, Yannis G. Kevrekidis, Igor Mezic:
An Operator Theoretic View On Pruning Deep Neural Networks.
		Matthew Farrell, Blake Bordelon, Shubhendu Trivedi, Cengiz Pehlevan:
Capacity of Group-invariant Linear Readouts from Equivariant Representations: How Many Objects can be Linearly Classified Under All Possible Views?
		Xiaoyu Liu, Jiahao Su, Furong Huang:
Tuformer: Data-driven Design of Transformers for Improved Generalization or Efficiency.
		Yao-Hung Hubert Tsai, Tianqin Li, Weixin Liu, Peiyuan Liao, Ruslan Salakhutdinov, Louis-Philippe Morency:
Learning Weakly-supervised Contrastive Representations.
		Baeseong Park, Se Jung Kwon, Daehwan Oh, Byeongwook Kim, Dongsoo Lee:
Encoding Weights of Irregular Sparsity for Fixed-to-Fixed Model Compression.
		Viraj Mehta, Biswajit Paria, Jeff Schneider, Stefano Ermon, Willie Neiswanger:
An Experimental Design Perspective on Model-Based Reinforcement Learning.
		Josue Nassar, Jennifer Rogers Brennan, Ben Evans, Kendall Lowrey:
BAM: Bayes with Adaptive Memory.
		Peng Jin, Xitong Zhang, Yinpeng Chen, Sharon Xiaolei Huang, Zicheng Liu, Youzuo Lin:
Unsupervised Learning of Full-Waveform Inversion: Connecting CNN and Partial Differential Equation in a Loop.
		Yao-Hung Hubert Tsai, Tianqin Li, Martin Q. Ma, Han Zhao, Kun Zhang, Louis-Philippe Morency, Ruslan Salakhutdinov:
Conditional Contrastive Learning with Kernel.
		Debasmit Das, Sungrack Yun, Fatih Porikli:
ConFeSS: A Framework for Single Source Cross-Domain Few-Shot Learning.
		Alexander P. Wu, Rohit Singh, Bonnie Berger:
Granger causal inference on DAGs identifies genomic loci regulating transcription.
		Jiaqi Guan, Wesley Wei Qian, Qiang Liu, Wei-Ying Ma, Jianzhu Ma, Jian Peng:
Energy-Inspired Molecular Conformation Optimization.
		Wei Huang, Yayong Li, Weitao Du, Richard Y. D. Xu, Jie Yin, Ling Chen, Miao Zhang:
Towards Deepening Graph Neural Networks: A GNTK-based Optimization Perspective.
		Lu Mi, Richard Xu, Sridhama Prakhya, Albert Lin, Nir Shavit, Aravinthan D. T. Samuel, Srinivas C. Turaga:
Connectome-constrained Latent Variable Model of Whole-Brain Neural Activity.
		Minhao Liu, Ailing Zeng, Qiuxia Lai, Ruiyuan Gao, Min Li, Jing Qin, Qiang Xu:
T-WaveNet: A Tree-Structured Wavelet Neural Network for Time Series Signal Analysis.
		Fangyu Liu, Yunlong Jiao, Jordan Massiah, Emine Yilmaz, Serhii Havrylov:
Trans-Encoder: Unsupervised sentence-pair modelling through self- and mutual-distillations.
		Qinsheng Zhang, Yongxin Chen:
Path Integral Sampler: A Stochastic Control Approach For Sampling.
		Rahul Ramesh, Pratik Chaudhari:
Model Zoo: A Growing Brain That Learns Continually.
		Xu Han, Han Gao, Tobias Pfaff, Jian-Xun Wang, Liping Liu:
Predicting Physics in Mesh-reduced Space with Temporal Attention.
		Shuai Zhang, Meng Wang, Sijia Liu, Pin-Yu Chen, Jinjun Xiong:
How unlabeled data improve generalization in self-training? A one-hidden-layer theoretical analysis.
		Shawn Tan, Chin-Wei Huang, Alessandro Sordoni, Aaron C. Courville:
Learning to Dequantise with Truncated Flows.
		Daniel R. Kepple, Rainer Engelken, Kanaka Rajan:
Curriculum learning as a tool to uncover learning principles in the brain.
		Tianshu Huang, Tianlong Chen, Sijia Liu, Shiyu Chang, Lisa Amini, Zhangyang Wang:
Optimizer Amalgamation.
		Zebang Shen, Juan Cerviño, Hamed Hassani, Alejandro Ribeiro:
An Agnostic Approach to Federated Learning with Class Imbalance.
		Samuel Sokota, Hengyuan Hu, David J. Wu, J. Zico Kolter, Jakob Nicolaus Foerster, Noam Brown:
A Fine-Tuning Approach to Belief State Modeling.
		Da Yu, Saurabh Naik, Arturs Backurs, Sivakanth Gopi, Huseyin A. Inan, Gautam Kamath, Janardhan Kulkarni, Yin Tat Lee, Andre Manoel, Lukas Wutschitz, Sergey Yekhanin, Huishuai Zhang:
Differentially Private Fine-tuning of Language Models.
		Benjamin Newman, Prafulla Kumar Choubey, Nazneen Rajani:
P-Adapters: Robustly Extracting Factual Information from Language Models with Diverse Prompts.
		Sachin G. Konan, Esmaeil Seraj, Matthew C. Gombolay:
Iterated Reasoning with Mutual Information in Cooperative and Byzantine Decentralized Teaming.
		Nikolay Savinov, Junyoung Chung, Mikolaj Binkowski, Erich Elsen, Aäron van den Oord:
Step-unrolled Denoising Autoencoders for Text Generation.
		Michael Wan, Jian Peng, Tanmay Gangwani:
Hindsight Foresight Relabeling for Meta-Reinforcement Learning.
		Edward J. Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, Weizhu Chen:
LoRA: Low-Rank Adaptation of Large Language Models.
		Luca Scimeca, Seong Joon Oh, Sanghyuk Chun, Michael Poli, Sangdoo Yun:
Which Shortcut Cues Will DNNs Choose? A Study from the Parameter-Space Perspective.
		Greg Yang, Michael Santacroce, Edward J. Hu:
Efficient Computation of Deep Nonlinear Infinite-Width Neural Networks that Learn Features.
		Mengjiao Yang, Sergey Levine, Ofir Nachum:
TRAIL: Near-Optimal Imitation Learning with Suboptimal Data.
		Pranjal Awasthi, Abhimanyu Das, Rajat Sen, Ananda Theertha Suresh:
On the benefits of maximum likelihood estimation for Regression and Forecasting.
		Vinay Venkatesh Ramasesh, Aitor Lewkowycz, Ethan Dyer:
Effect of scale on catastrophic forgetting in neural networks.
		Morteza Ramezani, Weilin Cong, Mehrdad Mahdavi, Mahmut T. Kandemir, Anand Sivasubramaniam:
Learn Locally, Correct Globally: A Distributed Algorithm for Training Graph Neural Networks.
		William Harvey, Saeid Naderiparizi, Frank Wood:
Conditional Image Generation by Conditioning Variational Auto-Encoders.
		Keir Adams, Lagnajit Pattanaik, Connor W. Coley:
Learning 3D Representations of Molecular Chirality with Invariance to Bond Rotations.
		Alfonso Amayuelas, Shuai Zhang, Susie Xi Rao, Ce Zhang:
Neural Methods for Logical Reasoning over Knowledge Graphs.
		Emily Black, Zifan Wang, Matt Fredrikson:
Consistent Counterfactuals for Deep Models.
		Shixing Yu, Tianlong Chen, Jiayi Shen, Huan Yuan, Jianchao Tan, Sen Yang, Ji Liu, Zhangyang Wang:
Unified Visual Transformer Compression.
		Yinhao Zhu, Yang Yang, Taco Cohen:
Transformer-based Transform Coding.
		Chuanyu Pan, Yanchao Yang, Kaichun Mo, Yueqi Duan, Leonidas J. Guibas:
Object Pursuit: Building a Space of Objects via Discriminative Weight Generation.
		Sangdon Park, Edgar Dobriban, Insup Lee, Osbert Bastani:
PAC Prediction Sets Under Covariate Shift.
		Simon Geisler, Johanna Sommer, Jan Schuchardt, Aleksandar Bojchevski, Stephan Günnemann:
Generalization of Neural Combinatorial Solvers Through the Lens of Adversarial Robustness.
		Nur Muhammad (Mahi) Shafiullah, Lerrel Pinto:
One After Another: Learning Incremental Skills for a Changing World.
		Xiang Zhang, Marko Zeman, Theodoros Tsiligkaridis, Marinka Zitnik:
Graph-Guided Network for Irregularly Sampled Multivariate Time Series.
		So Yeon Min, Devendra Singh Chaplot, Pradeep Kumar Ravikumar, Yonatan Bisk, Ruslan Salakhutdinov:
FILM: Following Instructions in Language with Modular Methods.
		Yun Kuen Cheung, Georgios Piliouras, Yixin Tao:
The Evolution of Uncertainty of Learning in Games.
		David Jaime Tena Cucala, Bernardo Cuenca Grau, Egor V. Kostylev, Boris Motik:
Explainable GNN-Based Models over Knowledge Graphs.
		Michiel de Jong, Yury Zemlyanskiy, Nicholas FitzGerald, Fei Sha, William W. Cohen:
Mention Memory: incorporating textual knowledge into Transformers through entity mention attention.
		Biao Zhang, Peter Wonka:
Training Data Generating Networks: Shape Reconstruction via Bi-level Optimization.
		Felix Petersen, Christian Borgelt, Hilde Kuehne, Oliver Deussen:
Monotonic Differentiable Sorting Networks.
		Matthias Gerstgrasser, Rakshit Trivedi, David C. Parkes:
CrowdPlay: Crowdsourcing Human Demonstrations for Offline Learning.
		Joseph Early, Christine Evers, Sarvapali D. Ramchurn:
Model Agnostic Interpretability for Multiple Instance Learning.
		Neil Jethani, Mukund Sudarshan, Ian Connick Covert, Su-In Lee, Rajesh Ranganath:
FastSHAP: Real-Time Shapley Value Estimation.
		Timofey Grigoryev, Andrey Voynov, Artem Babenko:
When, Why, and Which Pretrained GANs Are Useful?
		Tianxiang Gao, Hailiang Liu, Jia Liu, Hridesh Rajan, Hongyang Gao:
A global convergence theory for deep ReLU implicit networks via over-parameterization.
		Weiqi Peng, Jinghui Chen:
Learnability Lock: Authorized Learnability Control Through Adversarial Invertible Transformations.
		Nan Lu, Zhao Wang, Xiaoxiao Li, Gang Niu, Qi Dou, Masashi Sugiyama:
Federated Learning from Only Unlabeled Data with Class-conditional-sharing Clients.
		Hongyuan Mei, Chenghao Yang, Jason Eisner:
Transformer Embeddings of Irregularly Spaced Events and Their Participants.
		Eric Mitchell, Charles Lin, Antoine Bosselut, Chelsea Finn, Christopher D. Manning:
Fast Model Editing at Scale.
		Rui Pan, Haishan Ye, Tong Zhang:
Eigencurve: Optimal Learning Rate Schedule for SGD on Quadratic Objectives with Skewed Hessian Spectrums.
		Youzhi Luo, Shuiwang Ji:
An Autoregressive Flow Model for 3D Molecular Geometry Generation from Scratch.
		Ning Miao, Emile Mathieu, Siddharth N, Yee Whye Teh, Tom Rainforth:
On Incorporating Inductive Biases into VAEs.
		Xingyu Lin, Zhiao Huang, Yunzhu Li, Joshua B. Tenenbaum, David Held, Chuang Gan:
DiffSkill: Skill Abstraction from Differentiable Physics for Deformable Object Manipulations with Tools.
		Rebekka Burkholz, Nilanjana Laha, Rajarshi Mukherjee, Alkis Gotovos:
On the Existence of Universal Lottery Tickets.
		Shengchao Liu, Hanchen Wang, Weiyang Liu, Joan Lasenby, Hongyu Guo, Jian Tang:
Pre-training Molecular Graph Representation with 3D Geometry.
		Ziwei Guan, Tengyu Xu, Yingbin Liang:
PER-ETD: A Polynomially Efficient Emphatic Temporal Difference Learning Method.
		Simiao Zuo, Xiaodong Liu, Jian Jiao, Young Jin Kim, Hany Hassan, Ruofei Zhang, Jianfeng Gao, Tuo Zhao:
Taming Sparsely Activated Transformer with Stochastic Experts.
		Ying-Jun Du, Xiantong Zhen, Ling Shao, Cees G. M. Snoek:
Hierarchical Variational Memory for Few-shot Learning Across Domains.
		Bowen Shi, Wei-Ning Hsu, Kushal Lakhotia, Abdelrahman Mohamed:
Learning Audio-Visual Speech Representation by Masked Multimodal Cluster Prediction.
		Sang Michael Xie, Aditi Raghunathan, Percy Liang, Tengyu Ma:
An Explanation of In-context Learning as Implicit Bayesian Inference.
		Tianfan Fu, Wenhao Gao, Cao Xiao, Jacob Yasonik, Connor W. Coley, Jimeng Sun:
Differentiable Scaffolding Tree for Molecule Optimization.
		Xingyu Wang, Sewoong Oh, Chang-Han Rhee:
Eliminating Sharp Minima from SGD with Truncated Heavy-tailed Noise.
		Elahe Arani, Fahad Sarfraz, Bahram Zonooz:
Learning Fast, Learning Slow: A General Continual Learning Method based on Complementary Learning System.
		Charlie Hou, Kiran Koshy Thekumparampil, Giulia Fanti, Sewoong Oh:
FedChain: Chained Algorithms for Near-optimal Communication Cost in Federated Learning.
		Honglin Yuan, Warren Richard Morningstar, Lin Ning, Karan Singhal:
What Do We Mean by Generalization in Federated Learning?
		Yan Li, Dhruv Choudhary, Xiaohan Wei, Baichuan Yuan, Bhargav Bhushanam, Tuo Zhao, Guanghui Lan:
Frequency-aware SGD for Efficient Embedding Learning with Provable Benefits.
		Hui Jin, Pradeep Kr. Banerjee, Guido Montúfar:
Learning Curves for Gaussian Process Regression with Power-Law Priors and Targets.
		Tananun Songdechakraiwut, Bryan M. Krause, Matthew I. Banks, Kirill V. Nourski, Barry D. Van Veen:
Fast topological clustering with Wasserstein distance.
		Archit Sharma, Kelvin Xu, Nikhil Sardana, Abhishek Gupta, Karol Hausman, Sergey Levine, Chelsea Finn:
Autonomous Reinforcement Learning: Formalism and Benchmarking.
		Matthew Thorpe, Tan Minh Nguyen, Hedi Xia, Thomas Strohmer, Andrea L. Bertozzi, Stanley J. Osher, Bao Wang:
GRAND++: Graph Neural Diffusion with A Source Term.
		Mattia Atzeni, Shehzaad Zuzar Dhuliawala, Keerthiram Murugesan, Mrinmaya Sachan:
Case-based reasoning for better generalization in textual reinforcement learning.
		Shaojie Bai, Vladlen Koltun, J. Zico Kolter:
Neural Deep Equilibrium Solvers.
		Zhenmei Shi, Junyi Wei, Yingyu Liang:
A Theoretical Analysis on Feature Learning in Neural Networks: Emergence from Inputs and Advantage over Fixed Features.
		Cédric Rommel, Thomas Moreau, Joseph Paillard, Alexandre Gramfort:
CADDA: Class-wise Automatic Differentiable Data Augmentation for EEG Signals.
		Oscar Li, Jiankai Sun, Xin Yang, Weihao Gao, Hongyi Zhang, Junyuan Xie, Virginia Smith, Chong Wang:
Label Leakage and Protection in Two-party Split Learning.
		Cédric Vincent-Cuaz, Rémi Flamary, Marco Corneli, Titouan Vayer, Nicolas Courty:
Semi-relaxed Gromov-Wasserstein divergence and applications on graphs.
		Pardis Pashakhanloo, Aaditya Naik, Yuepeng Wang, Hanjun Dai, Petros Maniatis, Mayur Naik:
CodeTrek: Flexible Modeling of Code using an Extensible Relational Representation.
		Yifei Ma, Ge Liu, Anoop Deoras:
Bridging Recommendation and Marketing via Recurrent Intensity Modeling.
		Zhiqing Sun, Yiming Yang, Shinjae Yoo:
Sparse Attention with Learning to Hash.
		Zhenyu Zhu, Fabian Latorre, Grigorios Chrysos, Volkan Cevher:
Controlling the Complexity and Lipschitz Constant improves Polynomial Nets.
		Luke Melas-Kyriazi, Christian Rupprecht, Iro Laina, Andrea Vedaldi:
Finding an Unsupervised Image Segmenter in each of your Deep Generative Models.
		Yang Song, Liyue Shen, Lei Xing, Stefano Ermon:
Solving Inverse Problems in Medical Imaging with Score-Based Generative Models.
		Max W. Y. Lam, Jun Wang, Dan Su, Dong Yu:
BDDM: Bilateral Denoising Diffusion Models for Fast and High-Quality Speech Synthesis.
		Ziyi Chen, Shaocong Ma, Yi Zhou:
Sample Efficient Stochastic Policy Extragradient Algorithm for Zero-Sum Markov Game.
		Avi Schwarzschild, Arjun Gupta, Amin Ghiasi, Micah Goldblum, Tom Goldstein:
The Uncanny Similarity of Recurrence and Depth.
		Bochen Lv, Zhanxing Zhu:
Implicit Bias of Adversarial Training for Deep Neural Networks.
		Denis Yarats, Rob Fergus, Alessandro Lazaric, Lerrel Pinto:
Mastering Visual Continuous Control: Improved Data-Augmented Reinforcement Learning.
		Carl Hvarfner, Danny Stoll, Artur L. F. Souza, Marius Lindauer, Frank Hutter, Luigi Nardi:
$\pi$BO: Augmenting Acquisition Functions with User Beliefs for Bayesian Optimization.
		Kui Ren, Yunan Yang, Björn Engquist:
A Generalized Weighted Optimization Method for Computational Learning and Inversion.
		Cédric Allain, Alexandre Gramfort, Thomas Moreau:
DriPP: Driven Point Processes to Model Stimuli Induced Patterns in M/EEG Signals.
		Senwei Liang, Zhongzhan Huang, Hong Zhang:
Stiffness-aware neural network for learning Hamiltonian systems.
		Gerald Woo, Chenghao Liu, Doyen Sahoo, Akshat Kumar, Steven C. H. Hoi:
CoST: Contrastive Learning of Disentangled Seasonal-Trend Representations for Time Series Forecasting.
		Ruofan Liang, Hongyi Sun, Nandita Vijaykumar:
CoordX: Accelerating Implicit Neural Representation with a Split MLP Architecture.
		Jonas Fischer, Rebekka Burkholz:
Plant 'n' Seek: Can You Find the Winning Ticket?
		Yooju Shin, Susik Yoon, Sundong Kim, Hwanjun Song, Jae-Gil Lee, Byung Suk Lee:
Coherence-based Label Propagation over Time Series for Accelerated Active Learning.
		Fuchao Wei, Chenglong Bao, Yang Liu:
A Class of Short-term Recurrence Anderson Mixing Methods and Their Applications.
		Johannes Müller, Guido Montúfar:
The Geometry of Memoryless Stochastic Policy Optimization in Infinite-Horizon POMDPs.
		Jiawei Du, Hanshu Yan, Jiashi Feng, Joey Tianyi Zhou, Liangli Zhen, Rick Siow Mong Goh, Vincent Y. F. Tan:
Efficient Sharpness-aware Minimization for Improved Training of Neural Networks.
		Seohong Park, Jongwook Choi, Jaekyeom Kim, Honglak Lee, Gunhee Kim:
Lipschitz-constrained Unsupervised Skill Discovery.
		Jianda Chen, Sinno Jialin Pan:
Learning Generalizable Representations for Reinforcement Learning via Adaptive Meta-learner of Behavioral Similarities.
		Xiaolong Ma, Minghai Qin, Fei Sun, Zejiang Hou, Kun Yuan, Yi Xu, Yanzhi Wang, Yen-Kuang Chen, Rong Jin, Yuan Xie:
Effective Model Sparsification by Scheduled Grow-and-Prune Methods.
		Lewei Yao, Runhui Huang, Lu Hou, Guansong Lu, Minzhe Niu, Hang Xu, Xiaodan Liang, Zhenguo Li, Xin Jiang, Chunjing Xu:
FILIP: Fine-grained Interactive Language-Image Pre-Training.
		Homanga Bharadhwaj, Mohammad Babaeizadeh, Dumitru Erhan, Sergey Levine:
Information Prioritization through Empowerment in Visual Model-based RL.
		André Hottung, Yeong-Dae Kwon, Kevin Tierney:
Efficient Active Search for Combinatorial Optimization Problems.
		Lys Sanz Moreta, Ola Rønning, Ahmad Salim Al-Sibahi, Jotun Hein, Douglas L. Theobald, Thomas Hamelryck:
Ancestral protein sequence reconstruction using a tree-structured Ornstein-Uhlenbeck variational autoencoder.
		Zih-Syuan Huang, Ching-pei Lee:
Training Structured Neural Networks Through Manifold Identification and Variance Reduction.
		Róbert Csordás, Kazuki Irie, Jürgen Schmidhuber:
The Neural Data Router: Adaptive Control Flow in Transformers Improves Systematic Generalization.
		Imant Daunhawer, Thomas M. Sutter, Kieran Chin-Cheong, Emanuele Palumbo, Julia E. Vogt:
On the Limitations of Multimodal VAEs.
		Yixuan Chen, Yubin Shi, Dongsheng Li, Yujiang Wang, Mingzhi Dong, Yingying Zhao, Robert P. Dick, Qin Lv, Fan Yang, Li Shang:
Recursive Disentanglement Network.
		Louis Rouillard, Demian Wassermann:
ADAVI: Automatic Dual Amortized Variational Inference Applied To Pyramidal Bayesian Models.
		Paul Michel, Tatsunori Hashimoto, Graham Neubig:
Distributionally Robust Models with Parametric Likelihood Ratios.
		Jérémie Donà, Marie Déchelle, Patrick Gallinari, Marina Levy:
Constrained Physical-Statistics Models for Dynamical System Identification and Prediction.
		Majid Jahani, Sergey Rusakov, Zheng Shi, Peter Richtárik, Michael W. Mahoney, Martin Takác:
Doubly Adaptive Scaled Algorithm for Machine Learning Using Second-Order Information.
		Benoît Malézieux, Thomas Moreau, Matthieu Kowalski:
Understanding approximate and unrolled dictionary learning for pattern recovery.
		Sean Papay, Roman Klinger, Sebastian Padó:
Constraining Linear-chain CRFs to Regular Languages.
		Kerui Gu, Linlin Yang, Angela Yao:
Dive Deeper Into Integral Pose Regression.
		Melih Kandemir, Abdullah Akgül, Manuel Haußmann, Gozde Unal:
Evidential Turing Processes.
		Soon Hoe Lim, N. Benjamin Erichson, Francisco Utrera, Winnie Xu, Michael W. Mahoney:
Noisy Feature Mixup.
		Xiaohan Chen, Jason Zhang, Zhangyang Wang:
Peek-a-Boo: What (More) is Disguised in a Randomly Weighted Neural Network, and How to Find It Efficiently.
		Dapeng Hu, Shipeng Yan, Qizhengqiu Lu, Lanqing Hong, Hailin Hu, Yifan Zhang, Zhenguo Li, Xinchao Wang, Jiashi Feng:
How Well Does Self-Supervised Pre-Training Perform with Streaming Data?
		Afra Feyza Akyürek, Ekin Akyürek, Derry Wijaya, Jacob Andreas:
Subspace Regularizers for Few-Shot Class Incremental Learning.
		Simin Hong, Anthony G. Cohn, David Crossland Hogg:
Using Graph Representation Learning with Schema Encoders to Measure the Severity of Depressive Symptoms.
		Haobo Fu, Weiming Liu, Shuang Wu, Yijia Wang, Tao Yang, Kai Li, Junliang Xing, Bin Li, Bo Ma, Qiang Fu, Wei Yang:
Actor-Critic Policy Optimization in a Large-Scale Imperfect-Information Game.
		David Venuto, Elaine Lau, Doina Precup, Ofir Nachum:
Policy Gradients Incorporating the Future.
		Chongchong Li, Yue Wang, Wei Chen, Yuting Liu, Zhi-Ming Ma, Tie-Yan Liu:
Gradient Information Matters in Policy Optimization by Back-propagating through Model.
		Adrien Bardes, Jean Ponce, Yann LeCun:
VICReg: Variance-Invariance-Covariance Regularization for Self-Supervised Learning.
		Shaojie Li, Yong Liu:
High Probability Generalization Bounds with Fast Rates for Minimax Problems.
		Hyeonmin Ha, Ji-Hoon Kim, Semin Park, Byung-Gon Chun:
SUMNAS: Supernet with Unbiased Meta-Features for Neural Architecture Search.
		Shikuang Deng, Yuhang Li, Shanghang Zhang, Shi Gu:
Temporal Efficient Training of Spiking Neural Network via Gradient Re-weighting.
		Jianing Zhu, Jiangchao Yao, Bo Han, Jingfeng Zhang, Tongliang Liu, Gang Niu, Jingren Zhou, Jianliang Xu, Hongxia Yang:
Reliable Adversarial Distillation with Unreliable Teachers.
		Di Huang, Rui Zhang, Xing Hu, Xishan Zhang, Pengwei Jin, Nan Li, Zidong Du, Qi Guo, Yunji Chen:
Neural Program Synthesis with Query.
		Petra Poklukar, Vladislav Polianskii, Anastasiia Varava, Florian T. Pokorny, Danica Kragic:
Delaunay Component Analysis for Evaluation of Data Representations.
		Alexander Rivkind, Or Ram, Eldad Assa, Michael Kreiserman, Ehud Ahissar:
Visual hyperacuity with moving sensor and recurrent neural computations.
		Ziming Wang, Nan Xue, Ling Lei, Gui-Song Xia:
Partial Wasserstein Adversarial Network for Non-rigid Point Set Registration.
		Yang Zhao, Hao Zhang:
Quantitative Performance Assessment of CNN Units via Topological Entropy Calculation.
		Kamil Ciosek:
Imitation Learning by Reinforcement Learning.
		Lukas P. Fröhlich, Maksym Lefarov, Melanie N. Zeilinger, Felix Berkenkamp:
On-Policy Model Errors in Reinforcement Learning.
		Qian Liu, Bei Chen, Jiaqi Guo, Morteza Ziyadi, Zeqi Lin, Weizhu Chen, Jian-Guang Lou:
TAPEX: Table Pre-training via Learning a Neural SQL Executor.
		Jinxin Liu, Hongyin Zhang, Donglin Wang:
DARA: Dynamics-Aware Reward Augmentation in Offline Reinforcement Learning.
		Shuang Li, Mingquan Feng, Lu Wang, Abdelmajid Essofi, Yufeng Cao, Junchi Yan, Le Song:
Explaining Point Processes by Learning Interpretable Temporal Logic Rules.
		Zonghan Yang, Yang Liu:
On Robust Prefix-Tuning for Text Classification.
		Kai Cui, Heinz Koeppl:
Learning Graphon Mean Field Games and Approximate Nash Equilibria.
		Spyridon Mouselinos, Henryk Michalewski, Mateusz Malinowski:
Measuring CLEVRness: Black-box Testing of Visual Reasoning Models.
		Fei Zhang, Lei Feng, Bo Han, Tongliang Liu, Gang Niu, Tao Qin, Masashi Sugiyama:
Exploiting Class Activation Value for Partial-Label Learning.
		Yunjiang Jiang, Han Zhang, Yiming Qiu, Yun Xiao, Bo Long, Wen-Yun Yang:
Givens Coordinate Descent Methods for Rotation Matrix Learning in Trainable Embedding Indexes.
		Zhen Qin, Weixuan Sun, Hui Deng, Dongxu Li, Yunshen Wei, Baohong Lv, Junjie Yan, Lingpeng Kong, Yiran Zhong:
cosFormer: Rethinking Softmax In Attention.
		Lingjie Mei, Jiayuan Mao, Ziqi Wang, Chuang Gan, Joshua B. Tenenbaum:
FALCON: Fast Visual Concept Learning by Integrating Images, Linguistic descriptions, and Conceptual Relations.
		Boyan Li, Hongyao Tang, Yan Zheng, Jianye Hao, Pengyi Li, Zhen Wang, Zhaopeng Meng, Li Wang:
HyAR: Addressing Discrete-Continuous Action Reinforcement Learning via Hybrid Action Representation.
		Yi Huang, Adams Wai-Kin Kong:
Transferable Adversarial Attack based on Integrated Gradients.
		Niels Bruun Ipsen, Pierre-Alexandre Mattei, Jes Frellsen:
How to deal with missing data in supervised deep learning?
		Max Horn, Edward De Brouwer, Michael Moor, Yves Moreau, Bastian Rieck, Karsten M. Borgwardt:
Topological Graph Neural Networks.
		Matthew Chang, Arjun Gupta, Saurabh Gupta:
Learning Value Functions from Undirected State-only Experience.
		Cassidy Laidlaw, Anca D. Dragan:
The Boltzmann Policy Distribution: Accounting for Systematic Suboptimality in Human Models.
		Liang Peng, Senbo Yan, Boxi Wu, Zheng Yang, Xiaofei He, Deng Cai:
WeakM3D: Towards Weakly Supervised Monocular 3D Object Detection.
		Yinpeng Dong, Ke Xu, Xiao Yang, Tianyu Pang, Zhijie Deng, Hang Su, Jun Zhu:
Exploring Memorization in Adversarial Training.
		Seiya Tokui, Issei Sato:
Disentanglement Analysis with Partial Information Decomposition.
		Shizhan Zhu, Sayna Ebrahimi, Angjoo Kanazawa, Trevor Darrell:
Differentiable Gradient Sampling for Learning Implicit 3D Scene Reconstructions from a Single Image.
		Xueting Li, Shalini De Mello, Xiaolong Wang, Ming-Hsuan Yang, Jan Kautz, Sifei Liu:
Learning Continuous Environment Fields via Implicit Functions.
		Chandrasekar Subramanian, Balaraman Ravindran:
Causal Contextual Bandits with Targeted Interventions.
		Feisi Fu, Wenchao Li:
Sound and Complete Neural Network Repair with Minimality and Locality Guarantees.
		Juncheng Dong, Simiao Ren, Yang Deng, Omar Khatib, Jordan M. Malof, Mohammadreza Soltani, Willie Padilla, Vahid Tarokh:
Blaschke Product Neural Networks (BPNN): A Physics-Infused Neural Network for Phase Retrieval of Meromorphic Functions.
		Wei Jin, Xiaorui Liu, Xiangyu Zhao, Yao Ma, Neil Shah, Jiliang Tang:
Automated Self-Supervised Learning for Graphs.
		Jieyu Zhang, Bohan Wang, Xiangchen Song, Yujing Wang, Yaming Yang, Jing Bai, Alexander Ratner:
Creating Training Sets via Weak Indirect Supervision.
		Jaewoong Choi, Junho Lee, Changyeon Yoon, Jung Ho Park, Geonho Hwang, Myungjoo Kang:
Do Not Escape From the Manifold: Discovering the Local Coordinates on the Latent Space of GANs.
		Zhihao Zhang, Zhihao Jia:
GradSign: Model Performance Inference with Theoretical Insights.
		Eli Chien, Chao Pan, Jianhao Peng, Olgica Milenkovic:
You are AllSet: A Multiset Function Framework for Hypergraph Neural Networks.
		Gabriel Poesia, Alex Polozov, Vu Le, Ashish Tiwari, Gustavo Soares, Christopher Meek, Sumit Gulwani:
Synchromesh: Reliable Code Generation from Pre-trained Language Models.
		Ryo Karakida, Shotaro Akaho:
Learning curves for continual learning in neural networks: Self-knowledge transfer and forgetting.
		Yatao Bian, Yu Rong, Tingyang Xu, Jiaxiang Wu, Andreas Krause, Junzhou Huang:
Energy-Based Learning for Cooperative Games, with Applications to Valuation Problems in Machine Learning.
		Masatoshi Uehara, Wen Sun:
Pessimistic Model-based Offline Reinforcement Learning under Partial Coverage.
		Wenqing Zheng, Edward W. Huang, Nikhil Rao, Sumeet Katariya, Zhangyang Wang, Karthik Subbian:
Cold Brew: Distilling Graph Node Representations with Incomplete or Missing Neighborhoods.
		Yao Shu, Shaofeng Cai, Zhongxiang Dai, Beng Chin Ooi, Bryan Kian Hsiang Low:
NASI: Label- and Data-agnostic Neural Architecture Search at Initialization.
		Han-Jia Ye, Wei-Lun Chao:
How to Train Your MAML to Excel in Few-Shot Classification.
		Dingyang Chen, Yile Li, Qi Zhang:
Communication-Efficient Actor-Critic Methods for Homogeneous Markov Games.
		Sachin Mehta, Mohammad Rastegari:
MobileViT: Light-weight, General-purpose, and Mobile-friendly Vision Transformer.
		Yulun Wu, Nicholas Choma, Andrew Deru Chen, Mikaela Cashman, Érica Teixeira Prates, Verónica G. Melesse Vergara, Manesh Shah, Austin Clyde, Thomas S. Brettin, Wibe Albert de Jong, Neeraj Kumar, Martha S. Head, Rick L. Stevens, Peter Nugent, Daniel A. Jacobson, James B. Brown:
Spatial Graph Attention and Curiosity-driven Policy for Antiviral Drug Discovery.
		Arber Zela, Julien Niklas Siems, Lucas Zimmer, Jovita Lukasik, Margret Keuper, Frank Hutter:
Surrogate NAS Benchmarks: Going Beyond the Limited Search Spaces of Tabular NAS Benchmarks.
		Colin Wei, J. Zico Kolter:
Certified Robustness for Deep Equilibrium Models via Interval Bound Propagation.
		Tian Xie, Xiang Fu, Octavian-Eugen Ganea, Regina Barzilay, Tommi S. Jaakkola:
Crystal Diffusion Variational Autoencoder for Periodic Material Generation.
		Cat Phuoc Le, Juncheng Dong, Mohammadreza Soltani, Vahid Tarokh:
Task Affinity with Maximum Bipartite Matching in Few-Shot Learning.
		Yaohui Wang, Di Yang, François Brémond, Antitza Dantcheva:
Latent Image Animator: Learning to Animate Images via Latent Space Navigation.
		Edward S. Hu, Kun Huang, Oleh Rybkin, Dinesh Jayaraman:
Know Thyself: Transferable Visual Control Policies Through Robot-Awareness.
		Eli Chien, Wei-Cheng Chang, Cho-Jui Hsieh, Hsiang-Fu Yu, Jiong Zhang, Olgica Milenkovic, Inderjit S. Dhillon:
Node Feature Extraction by Self-Supervised Multi-scale Neighborhood Prediction.
		Yi Liu, Limei Wang, Meng Liu, Yuchao Lin, Xuan Zhang, Bora Oztekin, Shuiwang Ji:
Spherical Message Passing for 3D Molecular Graphs.
		Stephen Giguere, Blossom Metevier, Bruno Castro da Silva, Yuriy Brun, Philip S. Thomas, Scott Niekum:
Fairness Guarantees under Demographic Shift.
		Adam Ivankay, Ivan Girardi, Chiara Marchiori, Pascal Frossard:
Fooling Explanations in Text Classifiers.
		Tongzhou Wang, Phillip Isola:
On the Learning and Learnability of Quasimetrics.
		Dandan Guo, Long Tian, Minghe Zhang, Mingyuan Zhou, Hongyuan Zha:
Learning Prototype-oriented Set Representations for Meta-Learning.
		Gianluigi Silvestri, Emily Fertig, Dave Moore, Luca Ambrogioni:
Embedded-model flows: Combining the inductive biases of model-free deep learning and explicit probabilistic modeling.
		Jiaxian Guo, Mingming Gong, Dacheng Tao:
A Relational Intervention Approach for Unsupervised Dynamics Generalization in Model-Based Reinforcement Learning.
		Eric Ricardo Anschütz:
Critical Points in Quantum Generative Models.
		Xuefeng Du, Zhaoning Wang, Mu Cai, Yixuan Li:
VOS: Learning What You Don't Know by Virtual Outlier Synthesis.
		Jakub Grudzien Kuba, Ruiqing Chen, Muning Wen, Ying Wen, Fanglei Sun, Jun Wang, Yaodong Yang:
Trust Region Policy Optimisation in Multi-Agent Reinforcement Learning.
		Michael Rotman, Amit Dekel, Shir Gur, Yaron Oz, Lior Wolf:
Unsupervised Disentanglement with Tensor Product Representations on the Torus.
		Tom Shenkar, Lior Wolf:
Anomaly Detection for Tabular Data with Internal Contrastive Learning.
		David Henry Mguni, Taher Jafferjee, Jianhong Wang, Nicolas Perez Nieves, Oliver Slumbers, Feifei Tong, Yang Li, Jiangcheng Zhu, Yaodong Yang, Jun Wang:
LIGS: Learnable Intrinsic-Reward Generation Selection for Multi-Agent Learning.
		Yuning You, Yue Cao, Tianlong Chen, Zhangyang Wang, Yang Shen:
Bayesian Modeling and Uncertainty Quantification for Learning to Optimize: What, Why, and How.
		Shiwei Liu, Tianlong Chen, Zahra Atashgahi, Xiaohan Chen, Ghada Sokar, Elena Mocanu, Mykola Pechenizkiy, Zhangyang Wang, Decebal Constantin Mocanu:
Deep Ensembling with No Overhead for either Training or Testing: The All-Round Blessings of Dynamic Sparsity.
		Ziniu Li, Yingru Li, Yushun Zhang, Tong Zhang, Zhi-Quan Luo:
HyperDQN: A Randomized Exploration Method for Deep Reinforcement Learning.
		Yingtian Zou, Fusheng Liu, Qianxiao Li:
Unraveling Model-Agnostic Meta-Learning via The Adaptation Learning Rate.
		Yuexiang Xie, Zhen Wang, Yaliang Li, Ce Zhang, Jingren Zhou, Bolin Ding:
iFlood: A Stable and Effective Regularizer.
		David W. Romero, Robert-Jan Bruintjes, Jakub Mikolaj Tomczak, Erik J. Bekkers, Mark Hoogendoorn, Jan van Gemert:
FlexConv: Continuous Kernel Convolutions With Differentiable Kernel Sizes.
		Edoardo Mello Rella, Ajad Chhatkuli, Yun Liu, Ender Konukoglu, Luc Van Gool:
Zero Pixel Directional Boundary by Vector Transform.
		Zhaoyang Lyu, Zhifeng Kong, Xudong Xu, Liang Pan, Dahua Lin:
A Conditional Point Diffusion-Refinement Paradigm for 3D Point Cloud Completion.
		Keerthiram Murugesan, Vijay Sadashivaiah, Ronny Luss, Karthikeyan Shanmugam, Pin-Yu Chen, Amit Dhurandhar:
Auto-Transfer: Learning to Route Transferable Representations.
		Chao-Hong Tan, Qian Chen, Wen Wang, Qinglin Zhang, Siqi Zheng, Zhen-Hua Ling:
PoNet: Pooling Network for Efficient Token Mixing in Long Sequences.
		Yingjie Wang, Xianrui Zhong, Fengxiang He, Hong Chen, Dacheng Tao:
Huber Additive Models for Non-stationary Time Series Analysis.
		Youngmin Oh, Jinwoo Shin, Eunho Yang, Sung Ju Hwang:
Model-augmented Prioritized Experience Replay.
		Zhen Xiang, David J. Miller, George Kesidis:
Post-Training Detection of Backdoor Attacks for Two-Class and Multi-Attack Scenarios.
		Donggyun Kim, Seongwoong Cho, Wonkwang Lee, Seunghoon Hong:
Multi-Task Processes.
		Wenqi Shao, Yixiao Ge, Zhaoyang Zhang, Xuyuan Xu, Xiaogang Wang, Ying Shan, Ping Luo:
Dynamic Token Normalization improves Vision Transformers.
		Wenqing Zheng, Tianlong Chen, Ting-Kuei Hu, Zhangyang Wang:
Symbolic Learning to Optimize: Towards Interpretability and Scalability.
		Seanie Lee, Haebeom Lee, Juho Lee, Sung Ju Hwang:
Sequential Reptile: Inter-Task Gradient Alignment for Multilingual Learning.
		Luping Liu, Yi Ren, Zhijie Lin, Zhou Zhao:
Pseudo Numerical Methods for Diffusion Models on Manifolds.
		Yangguang Li, Feng Liang, Lichen Zhao, Yufeng Cui, Wanli Ouyang, Jing Shao, Fengwei Yu, Junjie Yan:
Supervision Exists Everywhere: A Data Efficient Contrastive Language-Image Pre-training Paradigm.
		Santhosh Kumar Ramakrishnan, Tushar Nagarajan, Ziad Al-Halah, Kristen Grauman:
Environment Predictive Coding for Visual Navigation.
		Zhang-Wei Hong, Tao Chen, Yen-Chen Lin, Joni Pajarinen, Pulkit Agrawal:
Topological Experience Replay.
		Tianlong Chen, Zhenyu Zhang, Pengjun Wang, Santosh Balachandra, Haoyu Ma, Zehao Wang, Zhangyang Wang:
Sparsity Winning Twice: Better Robust Generalization from More Efficient Training.
		Ronghang Zhu, Sheng Li:
CrossMatch: Cross-Classifier Consistency Regularization for Open-Set Single Domain Generalization.
		Shaopeng Fu, Fengxiang He, Yang Liu, Li Shen, Dacheng Tao:
Robust Unlearnable Examples: Protecting Data Privacy Against Adversarial Learning.
		Namjoon Suh, Hyunouk Ko, Xiaoming Huo:
A Non-Parametric Regression Viewpoint : Generalization of Overparametrized Deep RELU Network Under Noisy Observations.
		Siyuan Li, Jin Zhang, Jianhao Wang, Yang Yu, Chongjie Zhang:
Active Hierarchical Exploration with Stable Subgoal Representation Learning.
		Yu Zheng, Zhi Zhang, Shen Yan, Mi Zhang:
Deep AutoAugment.
		Bing Su, Ji-Rong Wen:
Temporal Alignment Prediction for Supervised Representation Learning and Few-Shot Sequence Classification.
		Peihao Wang, Wenqing Zheng, Tianlong Chen, Zhangyang Wang:
Anti-Oversmoothing in Deep Vision Transformers via the Fourier Domain Analysis: From Theory to Practice.
		Hongjun Wang, Yisen Wang:
Self-ensemble Adversarial Training for Improved Robustness.
		Allan Zhou, Fahim Tajwar, Alexander Robey, Tom Knowles, George J. Pappas, Hamed Hassani, Chelsea Finn:
Do deep networks transfer invariances across classes?
		Bogdan Mazoure, Ahmed M. Ahmed, R. Devon Hjelm, Andrey Kolobov, Patrick MacAlpine:
Cross-Trajectory Representation Learning for Zero-Shot Generalization in RL.
		Guy Tennenholtz, Assaf Hallak, Gal Dalal, Shie Mannor, Gal Chechik, Uri Shalit:
On Covariate Shift of Latent Confounders in Imitation and Reinforcement Learning.
		Scott Emmons, Benjamin Eysenbach, Ilya Kostrikov, Sergey Levine:
RvS: What is Essential for Offline RL via Supervised Learning?
		Wei Lu:
Learning Guarantees for Graph Convolutional Networks on the Stochastic Block Model.
		Mingyu Ding, Yuqi Huo, Haoyu Lu, Linjie Yang, Zhe Wang, Zhiwu Lu, Jingdong Wang, Ping Luo:
Learning Versatile Neural Architectures by Propagating Network Codes.
		Jun Yamada, Karl Pertsch, Anisha Gunjal, Joseph J. Lim:
Task-Induced Representation Learning.
		Liudmila Prokhorenkova, Dmitry Baranchuk, Nikolay Bogachev, Yury Demidovich, Alexander Kolpakov:
Graph-based Nearest Neighbor Search in Hyperbolic Spaces.
		Ali Jahanian, Xavier Puig, Yonglong Tian, Phillip Isola:
Generative Models as a Data Source for Multiview Representation Learning.
		Yiqi Jiang, Zhiyu Tan, Junyan Wang, Xiuyu Sun, Ming C. Lin, Hao Li:
GiraffeDet: A Heavy-Neck Paradigm for Object Detection.
		Anh Tuan Bui, Trung Le, Quan Hung Tran, He Zhao, Dinh Q. Phung:
A Unified Wasserstein Distributional Robustness Framework for Adversarial Training.
		Kunhao Zheng, Jesse Michael Han, Stanislas Polu:
miniF2F: a cross-system benchmark for formal Olympiad-level mathematics.
		Andrei Afonin, Sai Praneeth Karimireddy:
Towards Model Agnostic Federated Learning Using Knowledge Distillation.
		Chencheng Xu, Zhiwei Hong, Minlie Huang, Tao Jiang:
Acceleration of Federated Learning with Alleviated Forgetting in Local Training.
		Yingxin Wu, Xiang Wang, An Zhang, Xiangnan He, Tat-Seng Chua:
Discovering Invariant Rationales for Graph Neural Networks.
		Dongsheng Wang, Dandan Guo, He Zhao, Huangjie Zheng, Korawat Tanwisuth, Bo Chen, Mingyuan Zhou:
Representing Mixtures of Word Embeddings with Mixtures of Topic Embeddings.
		Litu Rout, Alexander Korotin, Evgeny Burnaev:
Generative Modeling with Optimal Transport Maps.
		Vihari Piratla, Praneeth Netrapalli, Sunita Sarawagi:
Focus on the Common Good: Group Distributional Robustness Follows.
		Wensi Tang, Guodong Long, Lu Liu, Tianyi Zhou, Michael Blumenstein, Jing Jiang:
Omni-Scale CNNs: a simple and effective kernel size configuration for time series classification.
		Yaohua Wang, Yaobin Zhang, Fangyi Zhang, Senzhang Wang, Ming Lin, YuQi Zhang, Xiuyu Sun:
Ada-NETS: Face Clustering via Adaptive Neighbour Discovery in the Structure Space.
		Junguang Jiang, Baixu Chen, Jianmin Wang, Mingsheng Long:
Decoupled Adaptation for Cross-Domain Object Detection.
		Xu Ma, Can Qin, Haoxuan You, Haoxi Ran, Yun Fu:
Rethinking Network Design and Local Geometry in Point Cloud: A Simple Residual MLP Framework.
		Lucas Caccia, Rahaf Aljundi, Nader Asadi, Tinne Tuytelaars, Joelle Pineau, Eugene Belilovsky:
New Insights on Reducing Abrupt Representation Change in Online Continual Learning.
		Tolga Ergen, Arda Sahiner, Batu Ozturkler, John M. Pauly, Morteza Mardani, Mert Pilanci:
Demystifying Batch Normalization in ReLU Networks: Equivalent Convex Optimization Models and Implicit Regularization.
		Dennis Y. H. Wu, Dinan Lin, Vincent Chen, Hung-Hsuan Chen:
Associated Learning: an Alternative to End-to-End Backpropagation that Works on CNN, RNN, and Transformer.
		Weixin Liang, James Zou:
MetaShift: A Dataset of Datasets for Evaluating Contextual Distribution Shifts and Training Conflicts.
		Wen Wang, Yang Cao, Jing Zhang, Dacheng Tao:
FP-DETR: Detection Transformer Advanced by Fully Pre-training.
		Yu Bai, Song Mei, Huan Wang, Yingbo Zhou, Caiming Xiong:
Efficient and Differentiable Conformal Prediction with General Function Classes.
		Chenxi Yang, Swarat Chaudhuri:
Safe Neurosymbolic Learning with Differentiable Symbolic Execution.
		Zirui Wang, Jiahui Yu, Adams Wei Yu, Zihang Dai, Yulia Tsvetkov, Yuan Cao:
SimVLM: Simple Visual Language Model Pretraining with Weak Supervision.
		Nico Courts, Henry Kvinge:
Bundle Networks: Fiber Bundles, Local Trivializations, and a Generative Approach to Exploring Many-to-one Maps.
		Casey Meehan, Amrita Roy Chowdhury, Kamalika Chaudhuri, Somesh Jha:
Privacy Implications of Shuffling.
		Mathieu Rita, Florian Strub, Jean-Bastien Grill, Olivier Pietquin, Emmanuel Dupoux:
On the role of population heterogeneity in emergent communication.
		Yurong You, Katie Z. Luo, Xiangyu Chen, Junan Chen, Wei-Lun Chao, Wen Sun, Bharath Hariharan, Mark E. Campbell, Kilian Q. Weinberger:
Hindsight is 20/20: Leveraging Past Traversals to Aid 3D Perception.
		Boyi Li, Kilian Q. Weinberger, Serge J. Belongie, Vladlen Koltun, René Ranftl:
Language-driven Semantic Segmentation.
		Jinghao Zhou, Chen Wei, Huiyu Wang, Wei Shen, Cihang Xie, Alan L. Yuille, Tao Kong:
Image BERT Pre-training with Online Tokenizer.
		Jie Xu, Viktor Makoviychuk, Yashraj S. Narang, Fabio Ramos, Wojciech Matusik, Animesh Garg, Miles Macklin:
Accelerated Policy Learning with Parallel Differentiable Simulation.
		Shyam A. Tailor, Felix L. Opolka, Pietro Liò, Nicholas Donald Lane:
Do We Need Anisotropic Graph Neural Networks?
		Johan Bjorck, Carla P. Gomes, Kilian Q. Weinberger:
Is High Variance Unavoidable in RL? A Case Study in Continuous Control.
		Jonathan Godwin, Michael Schaarschmidt, Alexander L. Gaunt, Alvaro Sanchez-Gonzalez, Yulia Rubanova, Petar Velickovic, James Kirkpatrick, Peter W. Battaglia:
Simple GNN Regularisation for 3D Molecular Property Prediction and Beyond.
		Lucio M. Dery, Paul Michel, Ameet Talwalkar, Graham Neubig:
Should We Be Pre-training? An Argument for End-task Aware Training as an Alternative.
		Philippe Weinzaepfel, Thomas Lucas, Diane Larlus, Yannis Kalantidis:
Learning Super-Features for Image Retrieval.
		Shaofeng H.-C. Jiang, Erzhi Liu, You Lyu, Zhihao Gavin Tang, Yubo Zhang:
Online Facility Location with Predictions.
		Yiming Li, Haoxiang Zhong, Xingjun Ma, Yong Jiang, Shu-Tao Xia:
Few-Shot Backdoor Attacks on Visual Object Tracking.
		Kunzhe Huang, Yiming Li, Baoyuan Wu, Zhan Qin, Kui Ren:
Backdoor Defense via Decoupling the Training Process.
		Daya Guo, Alexey Svyatkovskiy, Jian Yin, Nan Duan, Marc Brockschmidt, Miltiadis Allamanis:
Learning to Complete Code with Sketches.
		Yifan Gong, Yuguang Yao, Yize Li, Yimeng Zhang, Xiaoming Liu, Xue Lin, Sijia Liu:
Reverse Engineering of Imperceptible Adversarial Image Perturbations.
		Shilong Liu, Feng Li, Hao Zhang, Xiao Yang, Xianbiao Qi, Hang Su, Jun Zhu, Lei Zhang:
DAB-DETR: Dynamic Anchor Boxes are Better Queries for DETR.
		Zhuolin Yang, Linyi Li, Xiaojun Xu, Bhavya Kailkhura, Tao Xie, Bo Li:
On the Certified Robustness for Ensemble Models and Beyond.
		Phillip Lippe, Taco Cohen, Efstratios Gavves:
Efficient Neural Causal Discovery without Acyclicity Constraints.
		Can Wang, Sheng Jin, Yingda Guan, Wentao Liu, Chen Qian, Ping Luo, Wanli Ouyang:
Pseudo-Labeled Auto-Curriculum Learning for Semi-Supervised Keypoint Localization.
		Nils Koster, Oliver Grothe, Achim Rettinger:
Signing the Supermask: Keep, Hide, Invert.
		Shikun Liu, Shuaifeng Zhi, Edward Johns, Andrew J. Davison:
Bootstrapping Semantic Segmentation with Regional Contrast.
		Zhaoqiang Liu, Jiulong Liu, Subhroshekhar Ghosh, Jun Han, Jonathan Scarlett:
Generative Principal Component Analysis.
		Yijun Yang, Jing Jiang, Tianyi Zhou, Jie Ma, Yuhui Shi:
Pareto Policy Pool for Model-based Offline Reinforcement Learning.
		Andrea Cini, Ivan Marisca, Cesare Alippi:
Filling the G_ap_s: Multivariate Time Series Imputation by Graph Neural Networks.
		Wenlong Ji, Yiping Lu, Yiliang Zhang, Zhun Deng, Weijie J. Su:
An Unconstrained Layer-Peeled Perspective on Neural Collapse.
		Xuan-Phi Nguyen, Hongyu Gong, Yun Tang, Changhan Wang, Philipp Koehn, Shafiq R. Joty:
Contrastive Clustering to Mine Pseudo Parallel Data for Unsupervised Translation.
		Saeed Saremi, Rupesh Kumar Srivastava:
Multimeasurement Generative Models.
		Wentao Zhang, Yexin Wang, Zhenbang You, Meng Cao, Ping Huang, Jiulong Shan, Zhi Yang, Bin Cui:
Information Gain Propagation: a New Way to Graph Active Learning with Soft Labels.
		Tan Yu, Jun Li, Yunfeng Cai, Ping Li:
Constructing Orthogonal Convolutions in an Explicit Manner.
		Ximei Wang, Xinyang Chen, Jianmin Wang, Mingsheng Long:
X-model: Improving Data Efficiency in Deep Learning with A Minimax Model.
		Uiwon Hwang, Heeseung Kim, Dahuin Jung, Hyemi Jang, Hyungyu Lee, Sungroh Yoon:
Stein Latent Optimization for Generative Adversarial Networks.
		Byungseok Roh, Jaewoong Shin, Wuhyun Shin, Saehoon Kim:
Sparse DETR: Efficient End-to-End Object Detection with Learnable Sparsity.
		Naman Agarwal, Syomantak Chaudhuri, Prateek Jain, Dheeraj Mysore Nagaraj, Praneeth Netrapalli:
Online Target Q-learning with Reverse Experience Replay: Efficiently finding the Optimal Policy for Linear MDPs.
		Lun Wang, Iosif Pinelis, Dawn Song:
Differentially Private Fractional Frequency Moments Estimation with Polylogarithmic Space.
		Chengrun Yang, Ziyang Wu, Jerry Chee, Christopher De Sa, Madeleine Udell:
How Low Can We Go: Trading Memory for Error in Low-Precision Training.
		Borja G. León, Murray Shanahan, Francesco Belardinelli:
In a Nutshell, the Human Asked for This: Latent Goals for Following Temporal Specifications.
		Chengzhi Mao, Lu Jiang, Mostafa Dehghani, Carl Vondrick, Rahul Sukthankar, Irfan Essa:
Discrete Representations Strengthen Vision Transformer Robustness.
		Che Wang, Shuhan Yuan, Kai Shao, Keith W. Ross:
On the Convergence of the Monte Carlo Exploring Starts Algorithm for Reinforcement Learning.
		Yong Liu, Xiangning Chen, Minhao Cheng, Cho-Jui Hsieh, Yang You:
Concurrent Adversarial Learning for Large-Batch Training.
		Yan Zhang, David W. Zhang, Simon Lacoste-Julien, Gertjan J. Burghouts, Cees G. M. Snoek:
Multiset-Equivariant Set Prediction with Approximate Implicit Differentiation.
		Kimberly L. Stachenfeld, Drummond Buschman Fielding, Dmitrii Kochkov, Miles D. Cranmer, Tobias Pfaff, Jonathan Godwin, Can Cui, Shirley Ho, Peter W. Battaglia, Alvaro Sanchez-Gonzalez:
Learned Simulators for Turbulence.
		Jorge A. Mendez, Harm van Seijen, Eric Eaton:
Modular Lifelong Reinforcement Learning via Neural Composition.
		Tong Bu, Wei Fang, Jianhao Ding, Penglin Dai, Zhaofei Yu, Tiejun Huang:
Optimal ANN-SNN Conversion for High-accuracy and Ultra-low-latency Spiking Neural Networks.
		Dongze Lian, Zehao Yu, Xing Sun, Shenghua Gao:
AS-MLP: An Axial Shifted MLP Architecture for Vision.
		Hyunseo Koh, Dahyun Kim, Jung-Woo Ha, Jonghyun Choi:
Online Continual Learning on Class Incremental Blurry Task Configuration with Anytime Inference.
		Jiaheng Wei, Zhaowei Zhu, Hao Cheng, Tongliang Liu, Gang Niu, Yang Liu:
Learning with Noisy Labels Revisited: A Study Using Real-World Human Annotations.
		Mingjie Li, Yisen Wang, Xingyu Xie, Zhouchen Lin:
Optimization inspired Multi-Branch Equilibrium Models.
		Yu Yang, Xiaotian Cheng, Hakan Bilen, Xiangyang Ji:
Learning to Annotate Part Segmentation with Gradient Matching.
		Jiahui Yu, Xin Li, Jing Yu Koh, Han Zhang, Ruoming Pang, James Qin, Alexander Ku, Yuanzhong Xu, Jason Baldridge, Yonghui Wu:
Vector-quantized Image Modeling with Improved VQGAN.
		Ofir Press, Noah A. Smith, Mike Lewis:
Train Short, Test Long: Attention with Linear Biases Enables Input Length Extrapolation.
		Ruixiang Zhang, Shuangfei Zhai, Etai Littwin, Joshua M. Susskind:
Learning Representation from Neural Fisher Kernel with Low-rank Approximation.
		Weiran Yao, Yuewen Sun, Alex Ho, Changyin Sun, Kun Zhang:
Learning Temporally Causal Latent Processes from General Temporal Data.
		Zhaowei Zhu, Tianyi Luo, Yang Liu:
The Rich Get Richer: Disparate Impact of Semi-Supervised Learning.
		Ershad Banijamali:
Neural Relational Inference with Node-Specific Information.
		Feihu Huang, Shangqian Gao, Heng Huang:
Bregman Gradient Policy Optimization.
		Nicolas Boullé, Alex Townsend:
A generalization of the randomized singular value decomposition.
		Takuya Hiraoka, Takahisa Imagawa, Taisei Hashimoto, Takashi Onishi, Yoshimasa Tsuruoka:
Dropout Q-Functions for Doubly Efficient Reinforcement Learning.
		Xiuying Wei, Ruihao Gong, Yuhang Li, Xianglong Liu, Fengwei Yu:
QDrop: Randomly Dropping Quantization for Extremely Low-bit Post-Training Quantization.
		Osama Makansi, Julius von Kügelgen, Francesco Locatello, Peter Vincent Gehler, Dominik Janzing, Thomas Brox, Bernhard Schölkopf:
You Mostly Walk Alone: Analyzing Feature Attribution in Trajectory Prediction.
		Yu Yao, Tongliang Liu, Bo Han, Mingming Gong, Gang Niu, Masashi Sugiyama, Dacheng Tao:
Rethinking Class-Prior Estimation for Positive-Unlabeled Learning.
		Hang Zhao, Yang Yu, Kai Xu:
Learning Efficient Online 3D Bin Packing on Packing Configuration Trees.
		Xiaotong Li, Yongxing Dai, Yixiao Ge, Jun Liu, Ying Shan, Lingyu Duan:
Uncertainty Modeling for Out-of-Distribution Generalization.
		Andjela Mladenovic, Avishek Joey Bose, Hugo Berard, William L. Hamilton, Simon Lacoste-Julien, Pascal Vincent, Gauthier Gidel:
Online Adversarial Attacks.
		Zhuang Liu, Zhiqiu Xu, Hung-Ju Wang, Trevor Darrell, Evan Shelhamer:
Anytime Dense Prediction with Confidence Adaptivity.
		Russell Tsuchida, Suk Yee Yong, Mohammad Ali Armin, Lars Petersson, Cheng Soon Ong:
Declarative nets that are equilibrium models.
		Yunchang Yang, Tianhao Wu, Han Zhong, Evrard Garcelon, Matteo Pirotta, Alessandro Lazaric, Liwei Wang, Simon Shaolei Du:
A Reduction-Based Framework for Conservative Bandits and Reinforcement Learning.
		Xiaofang Wang, Dan Kondratyuk, Eric Christiansen, Kris M. Kitani, Yair Movshovitz-Attias, Elad Eban:
Wisdom of Committees: An Overlooked Approach To Faster and More Accurate Models.
		Hong-Xing Yu, Leonidas J. Guibas, Jiajun Wu:
Unsupervised Discovery of Object Radiance Fields.
		Samuel Hurault, Arthur Leclaire, Nicolas Papadakis:
Gradient Step Denoiser for convergent Plug-and-Play.
		Juntang Zhuang, Boqing Gong, Liangzhe Yuan, Yin Cui, Hartwig Adam, Nicha C. Dvornek, Sekhar Tatikonda, James S. Duncan, Ting Liu:
Surrogate Gap Minimization Improves Sharpness-Aware Training.
		Yingwei Li, Tiffany Chen, Maya Kabkab, Ruichi Yu, Longlong Jing, Yurong You, Hang Zhao:
R4D: Utilizing Reference Objects for Long-Range Distance Estimation.
		Li Jing, Pascal Vincent, Yann LeCun, Yuandong Tian:
Understanding Dimensional Collapse in Contrastive Self-supervised Learning.
		Nam Hyeon-Woo, Moon Ye-Bin, Tae-Hyun Oh:
FedPara: Low-rank Hadamard Product for Communication-Efficient Federated Learning.
		Chun-Fu Chen, Rameswar Panda, Quanfu Fan:
RegionViT: Regional-to-Local Attention for Vision Transformers.
		Shitao Tang, Jiahui Zhang, Siyu Zhu, Ping Tan:
Quadtree Attention for Vision Transformers.
		Hugo Germain, Vincent Lepetit, Guillaume Bourmaud:
Visual Correspondence Hallucination.
		Maximilian Böther, Otto Kißig, Martin Taraz, Sarel Cohen, Karen Seidel, Tobias Friedrich:
What's Wrong with Deep Learning in Tree Search for Combinatorial Optimization.
		Ifigeneia Apostolopoulou, Ian Char, Elan Rosenfeld, Artur Dubrawski:
Deep Attentive Variational Inference.
		Ginger Delmas, Rafael Sampaio de Rezende, Gabriela Csurka, Diane Larlus:
ARTEMIS: Attention-based Retrieval with Text-Explicit Matching and Implicit Similarity.
		Kristof Meding, Luca M. Schulze Buschoff, Robert Geirhos, Felix A. Wichmann:
Trivial or Impossible --- dichotomous data difficulty masks model differences (on ImageNet and beyond).
		Maximilian Dax, Stephen R. Green, Jonathan Gair, Michael Deistler, Bernhard Schölkopf, Jakob H. Macke:
Group equivariant neural posterior estimation.
		Yue Song, Nicu Sebe, Wei Wang:
Fast Differentiable Matrix Square Root.
		Cong Guo, Yuxian Qiu, Jingwen Leng, Xiaotian Gao, Chen Zhang, Yunxin Liu, Fan Yang, Yuhao Zhu, Minyi Guo:
SQuant: On-the-Fly Data-Free Quantization via Diagonal Hessian Approximation.
		Insu Jeon, Youngjin Park, Gunhee Kim:
Neural Variational Dropout Processes.
		Jiawei Yang, Hanbo Chen, Jiangpeng Yan, Xiaoyu Chen, Jianhua Yao:
Towards Better Understanding and Better Generalization of Low-shot Classification in Histology Images with Contrastive Learning.
		Yaxing Wang, Joost van de Weijer, Lu Yu, Shangling Jui:
Distilling GANs with Style-Mixed Triplets for X2I Translation with Limited Data.
		Qitian Wu, Hengrui Zhang, Junchi Yan, David Wipf:
Handling Distribution Shifts on Graphs: An Invariance Perspective.
		Boshi Wang, Jialin Yi, Hang Dong, Bo Qiao, Chuan Luo, Qingwei Lin:
Automatic Loss Function Search for Predict-Then-Optimize Problems with Strong Ranking Property.
		Zhimeng Jiang, Xiaotian Han, Chao Fan, Fan Yang, Ali Mostafavi, Xia Hu:
Generalized Demographic Parity for Group Fairness.
		Samet Çetin, Orhun Bugra Baran, Ramazan Gokberk Cinbis:
Closed-form Sample Probing for Learning Generative Models in Zero-shot Learning.
		Minsik Cho, Keivan Alizadeh-Vahid, Saurabh Adya, Mohammad Rastegari:
DKM: Differentiable k-Means Clustering Layer for Neural Network Compression.
		Varsha Kishore, Xiangyu Chen, Yan Wang, Boyi Li, Kilian Q. Weinberger:
Fixed Neural Network Steganography: Train the images, not the network.
		Erik Jenner, Maurice Weiler:
Steerable Partial Differential Operators for Equivariant Neural Networks.
		Weiming Zhuang, Yonggang Wen, Shuai Zhang:
Divergence-aware Federated Self-Supervised Learning.
		Shixiang Zhu, Haoyun Wang, Zheng Dong, Xiuyuan Cheng, Yao Xie:
Neural Spectral Marked Point Processes.
		Zhiyuan Zhang, Lingjuan Lyu, Weiqiang Wang, Lichao Sun, Xu Sun:
How to Inject Backdoors with Better Consistency: Logit Anchoring on Clean Data.
		Sayan Ghosal, Qiang Chen, Giulio Pergola, Aaron L. Goldman, William Ulrich, Daniel R. Weinberger, Archana Venkataraman:
A Biologically Interpretable Graph Convolutional Network to Link Genetic Risk Pathways and Imaging Phenotypes of Disease.
		Ningyu Zhang, Luoqiu Li, Xiang Chen, Shumin Deng, Zhen Bi, Chuanqi Tan, Fei Huang, Huajun Chen:
Differentiable Prompt Makes Pre-trained Language Models Better Few-shot Learners.
		Ningyu Zhang, Zhen Bi, Xiaozhuan Liang, Siyuan Cheng, Haosen Hong, Shumin Deng, Qiang Zhang, Jiazhang Lian, Huajun Chen:
OntoProtein: Protein Pretraining With Gene Ontology Embedding.
		Rafal Szlendak, Alexander Tyurin, Peter Richtárik:
Permutation Compressors for Provably Faster Distributed Nonconvex Optimization.
		Chunwei Ma, Ziyun Huang, Mingchen Gao, Jinhui Xu:
Few-shot Learning via Dirichlet Tessellation Ensemble.
		Jaesung Choe, Byeongin Joung, François Rameau, Jaesik Park, In So Kweon:
Deep Point Cloud Reconstruction.
		Pengzhou Abel Wu, Kenji Fukumizu:
$\beta$-Intact-VAE: Identifying and Estimating Causal Effects under Limited Overlap.
		Wei Ji, Jingjing Li, Qi Bi, Chuan Guo, Jie Liu, Li Cheng:
Promoting Saliency From Depth: Deep Unsupervised RGB-D Saliency Detection.
		Dacheng Yin, Xuanchi Ren, Chong Luo, Yuwang Wang, Zhiwei Xiong, Wenjun Zeng:
Retriever: Learning Content-Style Representation as a Token-Level Bipartite Graph.
		Sung Woo Park, Kyungjae Lee, Junseok Kwon:
Neural Markov Controlled SDE: Stochastic Optimization for Continuous-Time Data.
		Wenxiao Wang, Lu Yao, Long Chen, Binbin Lin, Deng Cai, Xiaofei He, Wei Liu:
CrossFormer: A Versatile Vision Transformer Hinging on Cross-scale Attention.
		Asaf Gendler, Tsui-Wei Weng, Luca Daniel, Yaniv Romano:
Adversarially Robust Conformal Prediction.
		Binjie Zhang, Yixiao Ge, Yantao Shen, Yu Li, Chun Yuan, Xuyuan Xu, Yexin Wang, Ying Shan:
Hot-Refresh Model Upgrades with Regression-Free Compatible Training in Image Retrieval.
		Lucas Deecke, Timothy M. Hospedales, Hakan Bilen:
Visual Representation Learning over Latent Domains.
		Hongwei Wang, Weijiang Li, Xiaomeng Jin, Kyunghyun Cho, Heng Ji, Jiawei Han, Martin D. Burke:
Chemical-Reaction-Aware Molecule Representation Learning.
		Taewook Nam, Shao-Hua Sun, Karl Pertsch, Sung Ju Hwang, Joseph J. Lim:
Skill-based Meta-Reinforcement Learning.
		Chieh Hubert Lin, Hsin-Ying Lee, Yen-Chi Cheng, Sergey Tulyakov, Ming-Hsuan Yang:
InfinityGAN: Towards Infinite-Pixel Image Synthesis.
		Albert Cheu, Matthew Joseph, Jieming Mao, Binghui Peng:
Shuffle Private Stochastic Convex Optimization.
		Ayush Jain, Norio Kosaka, Kyung-Min Kim, Joseph J. Lim:
Know Your Action Set: Learning Action Relations for Reinforcement Learning.
		Lauren Watson, Chuan Guo, Graham Cormode, Alexandre Sablayrolles:
On the Importance of Difficulty Calibration in Membership Inference Attacks.
		Yichen Qian, Xiuyu Sun, Ming Lin, Zhiyu Tan, Rong Jin:
Entroformer: A Transformer-based Entropy Model for Learned Image Compression.
		Yue Bai, Huan Wang, Zhiqiang Tao, Kunpeng Li, Yun Fu:
Dual Lottery Ticket Hypothesis.
		Kuan Wang, Yuyu Zhang, Diyi Yang, Le Song, Tao Qin:
GNN is a Counter? Revisiting GNN for Question Answering.
		Qi Li, Kaichun Mo, Yanchao Yang, Hang Zhao, Leonidas J. Guibas:
IFR-Explore: Learning Inter-object Functional Relationships in 3D Indoor Scenes.
		Ruihai Wu, Yan Zhao, Kaichun Mo, Zizheng Guo, Yian Wang, Tianhao Wu, Qingnan Fan, Xuelin Chen, Leonidas J. Guibas, Hao Dong:
VAT-Mart: Learning Visual Action Trajectory Proposals for Manipulating 3D ARTiculated Objects.
		Alexis Bellot, Kim Branson, Mihaela van der Schaar:
Neural graphical modelling in continuous-time: consistency guarantees and algorithms.
		Tianjun Zhang, Benjamin Eysenbach, Ruslan Salakhutdinov, Sergey Levine, Joseph E. Gonzalez:
C-Planning: An Automatic Curriculum for Learning Goal-Reaching Tasks.
		Yash Mehta, Colin White, Arber Zela, Arjun Krishnakumar, Guri Zabergja, Shakiba Moradian, Mahmoud Safari, Kaicheng Yu, Frank Hutter:
NAS-Bench-Suite: NAS Evaluation is (Now) Surprisingly Easy.
		Yiping Lu, Haoxuan Chen, Jianfeng Lu, Lexing Ying, Jose H. Blanchet:
Machine Learning For Elliptic PDEs: Fast Rate Generalization Bound, Neural Scaling Law and Minimax Optimality.
		Dongqi Han, Tadashi Kozuno, Xufang Luo, Zhao-Yun Chen, Kenji Doya, Yuqing Yang, Dongsheng Li:
Variational oracle guiding for reinforcement learning.
		Tongkun Xu, Weihua Chen, Pichao Wang, Fan Wang, Hao Li, Rong Jin:
CDTrans: Cross-domain Transformer for Unsupervised Domain Adaptation.
		Qilong Zhang, Xiaodan Li, Yuefeng Chen, Jingkuan Song, Lianli Gao, Yuan He, Hui Xue:
Beyond ImageNet Attack: Towards Crafting Adversarial Examples for Black-box Domains.
		Yuanhao Xiong, Li-Cheng Lan, Xiangning Chen, Ruochen Wang, Cho-Jui Hsieh:
Learning to Schedule Learning rate with Graph Neural Networks.
		Ayan Das, Yongxin Yang, Timothy M. Hospedales, Tao Xiang, Yi-Zhe Song:
SketchODE: Learning neural sketch representation in continuous time.
		Iro Laina, Yuki M. Asano, Andrea Vedaldi:
Measuring the Interpretability of Unsupervised Representations via Quantized Reversed Probing.
		Utku Evci, Bart van Merrienboer, Thomas Unterthiner, Fabian Pedregosa, Max Vladymyrov:
GradMax: Growing Neural Networks using Gradient Information.
		Jaehong Yoon, Divyam Madaan, Eunho Yang, Sung Ju Hwang:
Online Coreset Selection for Rehearsal-based Continual Learning.
		Zhengdong Hu, Yifan Sun, Yi Yang:
Switch to Generalize: Domain-Switch Learning for Cross-Domain Few-Shot Classification.
		Shaofeng Zhang, Feng Zhu, Junchi Yan, Rui Zhao, Xiaokang Yang:
Zero-CL: Instance and Feature decorrelation for negative-free symmetric contrastive learning.
		Hafiz Tiomoko Ali, Zhenyu Liao, Romain Couillet:
Random matrices in service of ML footprint: ternary random features with no performance loss.
		Stefanos Leonardos, Will Overman, Ioannis Panageas, Georgios Piliouras:
Global Convergence of Multi-Agent Policy Gradient in Markov Potential Games.
		Yao Zhu, Jiacheng Sun, Zhenguo Li:
Rethinking Adversarial Transferability from a Data Distribution Perspective.
		Samuel Müller, Noah Hollmann, Sebastian Pineda-Arango, Josif Grabocka, Frank Hutter:
Transformers Can Do Bayesian Inference.
		Alon Berliner, Guy Rotman, Yossi Adi, Roi Reichart, Tamir Hazan:
Learning Discrete Structured Variational Auto-Encoder using Natural Evolution Strategies.
		Dongyoon Han, Young Joon Yoo, Beomyoung Kim, Byeongho Heo:
Learning Features with Parameter-Free Layers.
		Chen-Hao Chao, Wei-Fang Sun, Bo-Wun Cheng, Yi-Chen Lo, Chia-Che Chang, Yu-Lun Liu, Yu-Lin Chang, Chia-Ping Chen, Chun-Yi Lee:
Denoising Likelihood Score Matching for Conditional Score-based Data Generation.
		Liyuan Wang, Xingxing Zhang, Kuo Yang, Longhui Yu, Chongxuan Li, Lanqing Hong, Shifeng Zhang, Zhenguo Li, Yi Zhong, Jun Zhu:
Memory Replay with Data Compression for Continual Learning.
		Chia-Hsiang Kao, Wei-Chen Chiu, Pin-Yu Chen:
MAML is a Noisy Contrastive Learner in Classification.
		Xiaojian Ma, Weili Nie, Zhiding Yu, Huaizu Jiang, Chaowei Xiao, Yuke Zhu, Song-Chun Zhu, Anima Anandkumar:
RelViT: Concept-guided Vision Transformer for Visual Relational Reasoning.
		Pascal Klink, Carlo D'Eramo, Jan Peters, Joni Pajarinen:
Boosted Curriculum Reinforcement Learning.
		Hwanjun Song, Deqing Sun, Sanghyuk Chun, Varun Jampani, Dongyoon Han, Byeongho Heo, Wonjae Kim, Ming-Hsuan Yang:
ViDT: An Efficient and Effective Fully Transformer-based Object Detector.
		Haotong Qin, Yifu Ding, Mingyuan Zhang, Qinghua Yan, Aishan Liu, Qingqing Dang, Ziwei Liu, Xianglong Liu:
BiBERT: Accurate Fully Binarized BERT.
		Bobby He, Mete Ozay:
Feature Kernel Distillation.
		Xiaoyang Huang, Jiancheng Yang, Yanjun Wang, Ziyu Chen, Linguo Li, Teng Li, Bingbing Ni, Wenjun Zhang:
Representation-Agnostic Shape Fields.
		Fabio Ferreira, Thomas Nierhoff, Andreas Sälinger, Frank Hutter:
Learning Synthetic Environments and Reward Networks for Reinforcement Learning.
		Changchun Li, Ximing Li, Lei Feng, Jihong Ouyang:
Who Is Your Right Mixup Partner in Positive and Unlabeled Learning.
		Tsai-Shien Chen, Wei-Chih Hung, Hung-Yu Tseng, Shao-Yi Chien, Ming-Hsuan Yang:
Incremental False Negative Detection for Contrastive Learning.
		Siddharth Mysore, George Cheng, Yunqi Zhao, Kate Saenko, Meng Wu:
Multi-Critic Actor Learning: Teaching RL Policies to Act with Style.
		Seungjun Nah, Sanghyun Son, Jaerin Lee, Kyoung Mu Lee:
Clean Images are Hard to Reblur: Exploiting the Ill-Posed Inverse Task for Dynamic Scene Deblurring.
		Xuanchi Ren, Tao Yang, Yuwang Wang, Wenjun Zeng:
Learning Disentangled Representation by Exploiting Pretrained Generative Models: A Contrastive Learning View.
		Tao Yang, Xuanchi Ren, Yuwang Wang, Wenjun Zeng, Nanning Zheng:
Towards Building A Group-based Unsupervised Representation Disentanglement Framework.
		Yulun Zhang, Huan Wang, Can Qin, Yun Fu:
Learning Efficient Image Super-Resolution Networks via Structure-Regularized Pruning.
		Franziska Geiger, Martin Schrimpf, Tiago Marques, James J. DiCarlo:
Wiring Up Vision: Minimizing Supervised Synaptic Updates Needed to Produce a Primate Ventral Stream.
		Blake Wulfe, Logan Michael Ellis, Jean Mercat, Rowan Thomas McAllister, Adrien Gaidon:
Dynamics-Aware Comparison of Learned Reward Functions.
		Brian DuSell, David Chiang:
Learning Hierarchical Structures with Differentiable Nondeterministic Stacks.
		Jiaxin Shi, Chang Liu, Lester Mackey:
Sampling with Mirrored Stein Operators.
		Ioannis Antonoglou, Julian Schrittwieser, Sherjil Ozair, Thomas K. Hubert, David Silver:
Planning in Stochastic Environments with a Learned Model.
		Adrián Javaloy, Isabel Valera:
RotoGrad: Gradient Homogenization in Multitask Learning.
		Muzammal Naseer, Kanchana Ranasinghe, Salman Khan, Fahad Shahbaz Khan, Fatih Porikli:
On Improving Adversarial Transferability of Vision Transformers.
		Yi Zhang, Arushi Gupta, Nikunj Saunshi, Sanjeev Arora:
On Predicting Generalization using GANs.
		Qi Han, Zejia Fan, Qi Dai, Lei Sun, Ming-Ming Cheng, Jiaying Liu, Jingdong Wang:
On the Connection between Local Attention and Dynamic Depth-wise Convolution.
		Ziyin Liu, Kangqiao Liu, Takashi Mori, Masahito Ueda:
Strength of Minibatch Noise in SGD.
		DJ Strouse, Kate Baumli, David Warde-Farley, Volodymyr Mnih, Steven Stenberg Hansen:
Learning more skills through optimistic exploration.
		Zhi Zhang, Zhuoran Yang, Han Liu, Pratap Tokekar, Furong Huang:
Reinforcement Learning under a Multi-agent Predictive State Representation Model: Method and Theory.
		Shangyuan Tong, Timur Garipov, Yang Zhang, Shiyu Chang, Tommi S. Jaakkola:
Adversarial Support Alignment.
		Xikun Zhang, Antoine Bosselut, Michihiro Yasunaga, Hongyu Ren, Percy Liang, Christopher D. Manning, Jure Leskovec:
GreaseLM: Graph REASoning Enhanced Language Models.
		Herilalaina Rakotoarison, Louisot Milijaona, Andry Rasoanaivo, Michèle Sebag, Marc Schoenauer:
Learning meta-features for AutoML.
		Roger Girgis, Florian Golemo, Felipe Codevilla, Martin Weiss, Jim Aldon D'Souza, Samira Ebrahimi Kahou, Felix Heide, Christopher Pal:
Latent Variable Sequential Set Transformers for Joint Multi-Agent Motion Prediction.
		Qi Lyu, Xiao Fu, Weiran Wang, Songtao Lu:
Understanding Latent Correlation-Based Multiview Learning and Self-Supervision: An Identifiability Perspective.
		Nate Gruver, Marc Anton Finzi, Samuel Don Stanton, Andrew Gordon Wilson:
Deconstructing the Inductive Biases of Hamiltonian Neural Networks.
		Yuhuai Wu, Markus Norman Rabe, DeLesley Hutchins, Christian Szegedy:
Memorizing Transformers.
		Jon C. Ergun, Zhili Feng, Sandeep Silwal, David P. Woodruff, Samson Zhou:
Learning-Augmented $k$-means Clustering.
		Chu-Cheng Lin, Arya D. McCarthy:
On the Uncomputability of Partition Functions in Energy-Based Sequence Models.
		Andrew Jaegle, Sebastian Borgeaud, Jean-Baptiste Alayrac, Carl Doersch, Catalin Ionescu, David Ding, Skanda Koppula, Daniel Zoran, Andrew Brock, Evan Shelhamer, Olivier J. Hénaff, Matthew M. Botvinick, Andrew Zisserman, Oriol Vinyals, João Carreira:
Perceiver IO: A General Architecture for Structured Inputs & Outputs.
		Aviral Kumar, Rishabh Agarwal, Tengyu Ma, Aaron C. Courville, George Tucker, Sergey Levine:
DR3: Value-Based Deep Reinforcement Learning Requires Explicit Regularization.
		Josh Gardner, Ian Simon, Ethan Manilow, Curtis Hawthorne, Jesse H. Engel:
MT3: Multi-Task Multitrack Music Transcription.
		Jiuhai Chen, Jonas Mueller, Vassilis N. Ioannidis, Soji Adeshina, Yangkun Wang, Tom Goldstein, David Wipf:
Does your graph need a confidence boost? Convergent boosted smoothing on graphs with tabular node features.
		Johannes Brandstetter, Rob Hesselink, Elise van der Pol, Erik J. Bekkers, Max Welling:
Geometric and Physical Quantities improve E(3) Equivariant Message Passing.
		Yandong Wen, Weiyang Liu, Adrian Weller, Bhiksha Raj, Rita Singh:
SphereFace2: Binary Classification is All You Need for Deep Face Recognition.
		Miklós Z. Horváth, Mark Niklas Müller, Marc Fischer, Martin T. Vechev:
Boosting Randomized Smoothing with Variance Reduced Classifiers.
		Manuel Nonnenmacher, Thomas Pfeil, Ingo Steinwart, David Reeb:
SOSP: Efficiently Capturing Global Correlations by Second-Order Structured Pruning.
		Kaidi Cao, Jiaxuan You, Jure Leskovec:
Relational Multi-Task Learning: Modeling Relations between Data and Tasks.
		Andrea Banino, Adrià Puigdomènech Badia, Jacob C. Walker, Tim Scholtes, Jovana Mitrovic, Charles Blundell:
CoBERL: Contrastive BERT for Reinforcement Learning.
		Ruibo Tu, Kun Zhang, Hedvig Kjellström, Cheng Zhang:
Optimal Transport for Causal Discovery.
		Hong-You Chen, Wei-Lun Chao:
On Bridging Generic and Personalized Federated Learning for Image Classification.
		Claas Voelcker, Victor Liao, Animesh Garg, Amir-massoud Farahmand:
Value Gradient weighted Model-Based Reinforcement Learning.
		Ada Wan:
Fairness in Representation for Multilingual NLP: Insights from Controlled Experiments on Conditional Language Modeling.
		Desik Rengarajan, Gargi Vaidya, Akshay Sarvesh, Dileep M. Kalathil, Srinivas Shakkottai:
Reinforcement Learning with Sparse Rewards using Guidance from Offline Demonstration.
		Shunyu Yao, Mo Yu, Yang Zhang, Karthik R. Narasimhan, Joshua B. Tenenbaum, Chuang Gan:
Linking Emergent and Natural Languages via Corpus Transfer.
		Yuzhou Chen, Ignacio Segovia-Dominguez, Baris Coskunuzer, Yulia R. Gel:
TAMP-S2GCNets: Coupling Time-Aware Multipersistence Knowledge Representation with Spatio-Supra Graph Convolutional Networks for Time-Series Forecasting.
		Thibault Sellam, Steve Yadlowsky, Ian Tenney, Jason Wei, Naomi Saphra, Alexander D'Amour, Tal Linzen, Jasmijn Bastings, Iulia Raluca Turc, Jacob Eisenstein, Dipanjan Das, Ellie Pavlick:
The MultiBERTs: BERT Reproductions for Robustness Analysis.
		Johannes Brandstetter, Daniel E. Worrall, Max Welling:
Message Passing Neural PDE Solvers.
		Jens Tuyls, Shunyu Yao, Sham M. Kakade, Karthik Narasimhan:
Multi-Stage Episodic Control for Strategic Exploration in Text Games.
		Samira Abnar, Mostafa Dehghani, Behnam Neyshabur, Hanie Sedghi:
Exploring the Limits of Large Scale Pre-training.
		Anastasis Kratsios, Behnoosh Zamanlooy, Tianlin Liu, Ivan Dokmanic:
Universal Approximation Under Constraints is Possible with Transformers.
		Behrooz Ghorbani, Orhan Firat, Markus Freitag, Ankur Bapna, Maxim Krikun, Xavier Garcia, Ciprian Chelba, Colin Cherry:
Scaling Laws for Neural Machine Translation.
		Biwei Huang, Fan Feng, Chaochao Lu, Sara Magliacane, Kun Zhang:
AdaRL: What, Where, and How to Adapt in Transfer Reinforcement Learning.
		Octavian-Eugen Ganea, Xinyuan Huang, Charlotte Bunne, Yatao Bian, Regina Barzilay, Tommi S. Jaakkola, Andreas Krause:
Independent SE(3)-Equivariant Models for End-to-End Rigid Protein Docking.
		Junxian He, Chunting Zhou, Xuezhe Ma, Taylor Berg-Kirkpatrick, Graham Neubig:
Towards a Unified View of Parameter-Efficient Transfer Learning.
		Yuxian Meng, Shi Zong, Xiaoya Li, Xiaofei Sun, Tianwei Zhang, Fei Wu, Jiwei Li:
GNN-LM: Language Modeling based on Global Contexts via GNN.
		Zichen Miao, Ze Wang, Wei Chen, Qiang Qiu:
Continual Learning with Filter Atom Swapping.
		Hao Liu, Huaping Liu:
Continual Learning with Recursive Gradient Optimization.
		Chun-Hao Chang, Rich Caruana, Anna Goldenberg:
NODE-GAM: Neural Generalized Additive Model for Interpretable Deep Learning.
		Sho Okumoto, Taiji Suzuki:
Learnability of convolutional neural networks for infinite dimensional input via mixed and anisotropic smoothness.
		Sahil Singla, Surbhi Singla, Soheil Feizi:
Improved deterministic l2 robustness on CIFAR-10 and CIFAR-100.
		Chaoyue Liu, Libin Zhu, Misha Belkin:
Transition to Linearity of Wide Neural Networks is an Emerging Property of Assembling Weak Models.
		Mozhgan PourKeshavarz, Guoying Zhao, Mohammad Sabokrou:
Looking Back on Learned Experiences For Class/task Incremental Learning.
		Wenzheng Zhang, Wenyue Hua, Karl Stratos:
EntQA: Entity Linking as Question Answering.
		Thomas Pethick, Puya Latafat, Panos Patrinos, Olivier Fercoq, Volkan Cevher:
Escaping limit cycles: Global convergence for constrained nonconvex-nonconcave minimax problems.
		Sarthak Mittal, Sharath Chandra Raparthy, Irina Rish, Yoshua Bengio, Guillaume Lajoie:
Compositional Attention: Disentangling Search and Retrieval.
		Yunji Kim, Jung-Woo Ha:
Contrastive Fine-grained Class Clustering via Generative Adversarial Networks.
		Tom Joy, Yuge Shi, Philip H. S. Torr, Tom Rainforth, Sebastian M. Schmon, Siddharth Narayanaswamy:
Learning Multimodal VAEs through Mutual Supervision.
		Miruna Pislar, David Szepesvari, Georg Ostrovski, Diana L. Borsa, Tom Schaul:
When should agents explore?
		Cong Lu, Philip J. Ball, Jack Parker-Holder, Michael A. Osborne, Stephen J. Roberts:
Revisiting Design Choices in Offline Model Based Reinforcement Learning.
		Xiaoxuan Lou, Shangwei Guo, Jiwei Li, Yaoxin Wu, Tianwei Zhang:
NASPY: Automated Extraction of Automated Machine Learning Models.
		Jongmin Lee, Cosmin Paduraru, Daniel J. Mankowitz, Nicolas Heess, Doina Precup, Kee-Eung Kim, Arthur Guez:
COptiDICE: Offline Constrained Reinforcement Learning via Stationary Distribution Correction Estimation.
		Ruihan Yang, Minghao Zhang, Nicklas Hansen, Huazhe Xu, Xiaolong Wang:
Learning Vision-Guided Quadrupedal Locomotion End-to-End with Cross-Modal Transformers.
		Kwonjoon Lee, Huiwen Chang, Lu Jiang, Han Zhang, Zhuowen Tu, Ce Liu:
ViTGAN: Training GANs with Vision Transformers.
		Alizée Pace, Alex J. Chan, Mihaela van der Schaar:
POETREE: Interpretable Policy Learning with Adaptive Decision Trees.
		Sen Lin, Li Yang, Deliang Fan, Junshan Zhang:
TRGP: Trust Region Gradient Projection for Continual Learning.
		Kartik Ahuja, Jason S. Hartford, Yoshua Bengio:
Properties from mechanisms: an equivariance perspective on identifiable representation learning.
		Han Shi, Jiahui Gao, Hang Xu, Xiaodan Liang, Zhenguo Li, Lingpeng Kong, Stephen M. S. Lee, James T. Kwok:
Revisiting Over-smoothing in BERT from the Perspective of Graph.
		Thien Le, Stefanie Jegelka:
Training invariances and the low-rank phenomenon: beyond linear networks.
		Zhizhou Ren, Ruihan Guo, Yuan Zhou, Jian Peng:
Learning Long-Term Reward Redistribution via Randomized Return Decomposition.
		Zhiyuan Li, Tianhao Wang, Sanjeev Arora:
What Happens after SGD Reaches Zero Loss? --A Mathematical Framework.
		Enyan Dai, Jie Chen:
Graph-Augmented Normalizing Flows for Anomaly Detection of Multiple Time Series.
		Phillip Si, Allan Bishop, Volodymyr Kuleshov:
Autoregressive Quantile Flows for Predictive Uncertainty Estimation.
		Saba Ghaffari, Ehsan Saleh, David A. Forsyth, Yu-Xiong Wang:
On the Importance of Firth Bias Reduction in Few-Shot Classification.
		Hairi, Jia Liu, Songtao Lu:
Finite-Time Convergence and Sample Complexity of Multi-Agent Actor-Critic Reinforcement Learning with Average Reward.
		Muthu Chidambaram, Xiang Wang, Yuzheng Hu, Chenwei Wu, Rong Ge:
Towards Understanding the Data Dependency of Mixup-style Training.
		Changhee Lee, Fergus Imrie, Mihaela van der Schaar:
Self-Supervision Enhanced Feature Selection with Correlated Gates.
		Tim Dockhorn, Arash Vahdat, Karsten Kreis:
Score-Based Generative Modeling with Critically-Damped Langevin Diffusion.
		Yilun Xu, Hao He, Tianxiao Shen, Tommi S. Jaakkola:
Controlling Directions Orthogonal to a Classifier.
		Shengyao Lu, Bang Liu, Keith G. Mills, Shangling Jui, Di Niu:
R5: Rule Discovery with Reinforced and Recurrent Relational Reasoning.
		Masatoshi Uehara, Xuezhou Zhang, Wen Sun:
Representation Learning for Online and Offline RL in Low-rank MDPs.
		Anji Liu, Stephan Mandt, Guy Van den Broeck:
Lossless Compression with Probabilistic Circuits.
		Xiaoyu Chen, Jiachen Hu, Chi Jin, Lihong Li, Liwei Wang:
Understanding Domain Randomization for Sim-to-real Transfer.
		Dian Wang, Robin Walters, Robert Platt:
$\mathrm{SO}(2)$-Equivariant Reinforcement Learning.
		Dara Bahri, Heinrich Jiang, Yi Tay, Donald Metzler:
Scarf: Self-Supervised Contrastive Learning using Random Feature Corruption.
		Ning Yu, Vladislav Skripniuk, Dingfan Chen, Larry S. Davis, Mario Fritz:
Responsible Disclosure of Generative Models Using Scalable Fingerprinting.
		Haoran Sun, Hanjun Dai, Wei Xia, Arun Ramamurthy:
Path Auxiliary Proposal for MCMC in Discrete Space.
		Robby Costales, Shariq Iqbal, Fei Sha:
Possibility Before Utility: Learning And Using Hierarchical Affordances.
		Mangal Prakash, Mauricio Delbracio, Peyman Milanfar, Florian Jug:
Interpretable Unsupervised Diversity Denoising and Artefact Removal.
		Patrick Schnell, Philipp Holl, Nils Thuerey:
Half-Inverse Gradients for Physical Deep Learning.
		Yikun Ban, Yuchen Yan, Arindam Banerjee, Jingrui He:
EE-Net: Exploitation-Exploration Neural Networks in Contextual Bandits.
		Alan Jeffares, Qinghai Guo, Pontus Stenetorp, Timoleon Moraitis:
Spike-inspired rank coding for fast and accurate recurrent neural networks.
		Yimeng Zhang, Yuguang Yao, Jinghan Jia, Jinfeng Yi, Mingyi Hong, Shiyu Chang, Sijia Liu:
How to Robustify Black-Box ML Models? A Zeroth-Order Optimization Perspective.
		Dingfan Chen, Ning Yu, Mario Fritz:
RelaxLoss: Defending Membership Inference Attacks without Losing Utility.
		Bingbin Liu, Elan Rosenfeld, Pradeep Kumar Ravikumar, Andrej Risteski:
Analyzing and Improving the Optimization Landscape of Noise-Contrastive Estimation.
		Sizhe Li, Zhiao Huang, Tao Du, Hao Su, Joshua B. Tenenbaum, Chuang Gan:
Contact Points Discovery for Soft-Body Manipulations with Differentiable Physics.
		Baptiste Rozière, Jie Zhang, François Charton, Mark Harman, Gabriel Synnaeve, Guillaume Lample:
Leveraging Automated Unit Tests for Unsupervised Code Translation.
		Insu Han, Mike Gartrell, Jennifer Gillenwater, Elvis Dohmatob, Amin Karbasi:
Scalable Sampling for Nonsymmetric Determinantal Point Processes.
		Wenhao Gao, Rocío Mercado, Connor W. Coley:
Amortized Tree Generation for Bottom-up Synthesis Planning and Synthesizable Molecular Design.
		Wengong Jin, Jeremy Wohlwend, Regina Barzilay, Tommi S. Jaakkola:
Iterative Refinement Graph Neural Network for Antibody Sequence-Structure Co-design.
		Heinrich Jiang, Harikrishna Narasimhan, Dara Bahri, Andrew Cotter, Afshin Rostamizadeh:
Churn Reduction via Distillation.
		Masahiro Kato, Masaaki Imaizumi, Kenichiro McAlinn, Shota Yasui, Haruo Kakehi:
Learning Causal Models from Conditional Moment Restrictions by Importance Weighting.
		Ross M. Clarke, Elre Talea Oldewage, José Miguel Hernández-Lobato:
Scalable One-Pass Optimisation of High-Dimensional Weight-Update Hyperparameters by Implicit Differentiation.
		Vincent Mai, Kaustubh Mani, Liam Paull:
Sample Efficient Deep Reinforcement Learning via Uncertainty Estimation.
		Lu Miao, Xiaolong Luo, Tianlong Chen, Wuyang Chen, Dong Liu, Zhangyang Wang:
Learning Pruning-Friendly Networks via Frank-Wolfe: One-Shot, Any-Sparsity, And No Retraining.
		Dushyant Rao, Fereshteh Sadeghi, Leonard Hasenclever, Markus Wulfmeier, Martina Zambelli, Giulia Vezzani, Dhruva Tirumala, Yusuf Aytar, Josh Merel, Nicolas Heess, Raia Hadsell:
Learning transferable motor skills with hierarchical latent mixture policies.
		Zhuoning Yuan, Zhishuai Guo, Nitesh V. Chawla, Tianbao Yang:
Compositional Training for End-to-End Deep AUC Maximization.
		Aria Masoomi, Davin Hill, Zhonghui Xu, Craig P. Hersh, Edwin K. Silverman, Peter J. Castaldi, Stratis Ioannidis, Jennifer G. Dy:
Explanations of Black-Box Models based on Directional Feature Interactions.
		Marc Aurel Vischer, Robert Tjarko Lange, Henning Sprekeler:
On Lottery Tickets and Minimal Task Representations in Deep Reinforcement Learning.
		Hong Liu, Jeff Z. HaoChen, Adrien Gaidon, Tengyu Ma:
Self-supervised Learning is More Robust to Dataset Imbalance.
		Nicholas Gao, Stephan Günnemann:
Ab-Initio Potential Energy Surfaces by Pairing GNNs with Neural Wave Functions.
		Xiaoyu Chen, Jiachen Hu, Lin Yang, Liwei Wang:
Near-Optimal Reward-Free Exploration for Linear Mixture MDPs with Plug-in Solver.
		Haoang Chi, Feng Liu, Wenjing Yang, Long Lan, Tongliang Liu, Bo Han, Gang Niu, Mingyuan Zhou, Masashi Sugiyama:
Meta Discovery: Learning to Discover Novel Classes given Very Limited Data.
		Yarden As, Ilnura Usmanova, Sebastian Curi, Andreas Krause:
Constrained Policy Optimization via Bayesian World Models.
		Alexander Shekhovtsov, Dmitrij Schlesinger, Boris Flach:
VAE Approximation Error: ELBO and Exponential Families.
		Hiroki Furuta, Yutaka Matsuo, Shixiang Shane Gu:
Generalized Decision Transformer for Offline Hindsight Information Matching.
		Dinghuai Zhang, Jie Fu, Yoshua Bengio, Aaron C. Courville:
Unifying Likelihood-free Inference with Black-box Optimization and Beyond.
		Wei Fan, Shun Zheng, Xiaohan Yi, Wei Cao, Yanjie Fu, Jiang Bian, Tie-Yan Liu:
DEPTS: Deep Expansion Learning for Periodic Time Series Forecasting.
		Leslie O'Bray, Max Horn, Bastian Rieck, Karsten M. Borgwardt:
Evaluation Metrics for Graph Generative Models: Problems, Pitfalls, and Practical Solutions.
		Bertrand Charpentier, Oliver Borchert, Daniel Zügner, Simon Geisler, Stephan Günnemann:
Natural Posterior Network: Deep Bayesian Predictive Uncertainty for Exponential Family Distributions.
		Tim Franzmeyer, Mateusz Malinowski, João F. Henriques:
Learning Altruistic Behaviours in Reinforcement Learning without External Rewards.
		Tonghan Wang, Liang Zeng, Weijun Dong, Qianlan Yang, Yang Yu, Chongjie Zhang:
Context-Aware Sparse Deep Coordination Graphs.
		Zhong Li, Haotian Jiang, Qianxiao Li:
On the approximation properties of recurrent encoder-decoder architectures.
		Beidi Chen, Tri Dao, Kaizhao Liang, Jiaming Yang, Zhao Song, Atri Rudra, Christopher Ré:
Pixelated Butterfly: Simple and Efficient Sparse training for Neural Network Models.
		Tim Dettmers, Mike Lewis, Sam Shleifer, Luke Zettlemoyer:
8-bit Optimizers via Block-wise Quantization.
		Anne Harrington, Arturo Deza:
Finding Biological Plausibility for Adversarially Robust Features via Metameric Tasks.
		Chao Li, Aojun Zhou, Anbang Yao:
Omni-Dimensional Dynamic Convolution.
		Youwei Liang, Chongjian Ge, Zhan Tong, Yibing Song, Jue Wang, Pengtao Xie:
EViT: Expediting Vision Transformers via Token Reorganizations.
		Zhaozhi Qian, Krzysztof Kacprzyk, Mihaela van der Schaar:
D-CODE: Discovering Closed-form ODEs from Observed Trajectories.
		Sungsoo Ahn, Binghong Chen, Tianzhe Wang, Le Song:
Spanning Tree-based Graph Generation for Molecules.
		Ivo Danihelka, Arthur Guez, Julian Schrittwieser, David Silver:
Policy improvement by planning with Gumbel.
		David Stutz, Krishnamurthy Dvijotham, Ali Taylan Cemgil, Arnaud Doucet:
Learning Optimal Conformal Classifiers.
		Victor Sanh, Albert Webson, Colin Raffel, Stephen H. Bach, Lintang Sutawika, Zaid Alyafeai, Antoine Chaffin, Arnaud Stiegler, Arun Raja, Manan Dey, M Saiful Bari, Canwen Xu, Urmish Thakker, Shanya Sharma Sharma, Eliza Szczechla, Taewoon Kim, Gunjan Chhablani, Nihal V. Nayak, Debajyoti Datta, Jonathan Chang, Mike Tian-Jian Jiang, Han Wang, Matteo Manica, Sheng Shen, Zheng Xin Yong, Harshit Pandey, Rachel Bawden, Thomas Wang, Trishala Neeraj, Jos Rozen, Abheesht Sharma, Andrea Santilli, Thibault Févry, Jason Alan Fries, Ryan Teehan, Teven Le Scao, Stella Biderman, Leo Gao, Thomas Wolf, Alexander M. Rush:
Multitask Prompted Training Enables Zero-Shot Task Generalization.
		Tristan Deleu, David Kanaa, Leo Feng, Giancarlo Kerg, Yoshua Bengio, Guillaume Lajoie, Pierre-Luc Bacon:
Continuous-Time Meta-Learning with Forward Mode Differentiation.
		Alexander Hepburn, Valero Laparra, Raúl Santos-Rodríguez, Johannes Ballé, Jesus Malo:
On the relation between statistical learning and perceptual distances.
		Paris Giampouras, Benjamin David Haeffele, René Vidal:
Implicit Bias of Projected Subgradient Method Gives Provable Robust Recovery of Subspaces of Unknown Codimension.
		Gal Vardi, Gilad Yehudai, Ohad Shamir:
On the Optimal Memorization Power of ReLU Neural Networks.
		Wenjie Qiu, He Zhu:
Programmatic Reinforcement Learning without Oracles.
		Xiangning Chen, Cho-Jui Hsieh, Boqing Gong:
When Vision Transformers Outperform ResNets without Pre-training or Strong Data Augmentations.
		Haebeom Lee, Hayeon Lee, Jaewoong Shin, Eunho Yang, Timothy M. Hospedales, Sung Ju Hwang:
Online Hyperparameter Meta-Learning with Hypergradient Distillation.
		Carles Domingo-Enrich, Youssef Mroueh:
Tighter Sparse Approximation Bounds for ReLU Neural Networks.
		T. Konstantin Rusch, Siddhartha Mishra, N. Benjamin Erichson, Michael W. Mahoney:
Long Expressive Memory for Sequence Modeling.
		Jiehui Xu, Haixu Wu, Jianmin Wang, Mingsheng Long:
Anomaly Transformer: Time Series Anomaly Detection with Association Discrepancy.
		Tim Salimans, Jonathan Ho:
Progressive Distillation for Fast Sampling of Diffusion Models.
		Yucheng Lu, Si Yi Meng, Christopher De Sa:
A General Analysis of Example-Selection for Stochastic Gradient Descent.
		Yiding Jiang, Vaishnavh Nagarajan, Christina Baek, J. Zico Kolter:
Assessing Generalization of SGD via Disagreement.
		Haichao Zhang, Wei Xu, Haonan Yu:
Generative Planning for Temporally Coordinated Exploration in Reinforcement Learning.
		Chenjia Bai, Lingxiao Wang, Zhuoran Yang, Zhi-Hong Deng, Animesh Garg, Peng Liu, Zhaoran Wang:
Pessimistic Bootstrapping for Uncertainty-Driven Offline Reinforcement Learning.
		Beatrice Bevilacqua, Fabrizio Frasca, Derek Lim, Balasubramaniam Srinivasan, Chen Cai, Gopinath Balamurugan, Michael M. Bronstein, Haggai Maron:
Equivariant Subgraph Aggregation Networks.
		Namuk Park, Songkuk Kim:
How Do Vision Transformers Work?
		Manuel Glöckler, Michael Deistler, Jakob H. Macke:
Variational methods for simulation-based inference.
		Zhisheng Xiao, Karsten Kreis, Arash Vahdat:
Tackling the Generative Learning Trilemma with Denoising Diffusion GANs.
		Andrew Corbett, Dmitry Kangin:
Imbedding Deep Neural Networks.
		Clare Lyle, Mark Rowland, Will Dabney:
Understanding and Preventing Capacity Loss in Reinforcement Learning.
		Cian Eastwood, Ian Mason, Christopher K. I. Williams, Bernhard Schölkopf:
Source-Free Adaptation to Measurement Shift via Bottom-Up Feature Restoration.
		Yoav Levine, Noam Wies, Daniel Jannai, Dan Navon, Yedid Hoshen, Amnon Shashua:
The Inductive Bias of In-Context Learning: Rethinking Pretraining Example Design.
		Rahma Chaabouni, Florian Strub, Florent Altché, Eugene Tarassov, Corentin Tallec, Elnaz Davoodi, Kory Wallace Mathewson, Olivier Tieleman, Angeliki Lazaridou, Bilal Piot:
Emergent Communication at Scale.
		Jingchao Ni, Wei Cheng, Zhengzhang Chen, Takayoshi Asakura, Tomoya Soma, Sho Kato, Haifeng Chen:
Superclass-Conditional Gaussian Mixture Model For Learning Fine-Grained Embeddings.
		Zaccharie Ramzi, Florian Mannel, Shaojie Bai, Jean-Luc Starck, Philippe Ciuciu, Thomas Moreau:
SHINE: SHaring the INverse Estimate from the forward pass for bi-level optimization and implicit models.
		Jiawei Huang, Jinglin Chen, Li Zhao, Tao Qin, Nan Jiang, Tie-Yan Liu:
Towards Deployment-Efficient Reinforcement Learning: Lower Bound and Optimality.
		Jiechao Guan, Zhiwu Lu:
Task Relatedness-Based Generalization Bounds for Meta Learning.
		Konstantin Mishchenko, Bokun Wang, Dmitry Kovalev, Peter Richtárik:
IntSGD: Adaptive Floatless Compression of Stochastic Gradients.
		Zifeng Wang, Shao-Lun Huang, Ercan Engin Kuruoglu, Jimeng Sun, Xi Chen, Yefeng Zheng:
PAC-Bayes Information Bottleneck.
		Sai Praneeth Karimireddy, Lie He, Martin Jaggi:
Byzantine-Robust Learning on Heterogeneous Datasets via Bucketing.
		Kyuhong Shim, Jungwook Choi, Wonyong Sung:
Understanding the Role of Self Attention for Efficient Speech Recognition.
		Deval Shah, Zi Yu Xue, Tor M. Aamodt:
Label Encoding for Regression Networks.
		Philipp Thölke, Gianni De Fabritiis:
Equivariant Transformers for Neural Network based Molecular Potentials.
		Ziyin Liu, Botao Li, James B. Simon, Masahito Ueda:
SGD Can Converge to Local Maxima.
		Yuanxiong Guo, Ying Sun, Rui Hu, Yanmin Gong:
Hybrid Local SGD for Federated Learning with Heterogeneous Communications.
		Adam Dziedzic, Muhammad Ahmad Kaleem, Yu Shen Lu, Nicolas Papernot:
Increasing the Cost of Model Extraction with Calibrated Proof of Work.
		Marten Lienen, Stephan Günnemann:
Learning the Dynamics of Physical Systems from Sparse Observations with Finite Element Networks.
		Dongsu Zhang, Changwoon Choi, Inbum Park, Young Min Kim:
Probabilistic Implicit Scene Completion.
		Qiang Meng, Feng Zhou, Hainan Ren, Tianshu Feng, Guochao Liu, Yuanqing Lin:
Improving Federated Learning Face Recognition via Privacy-Agnostic Clusters.