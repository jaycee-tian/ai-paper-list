	Feiqing Huang, Kexin Lu, Yuxi Cai, Zhen Qin, Yanwen Fang, Guangjian Tian, Guodong Li:
Encoding Recurrence into Transformers.
		Jiri Hron, Karl Krauth, Michael I. Jordan, Niki Kilbertus, Sarah Dean:
Modeling content creator incentives on algorithm-curated platforms.
		Gresa Shala, Thomas Elsken, Frank Hutter, Josif Grabocka:
Transfer NAS with Meta-learned Bayesian Surrogates.
		Anji Liu, Honghua Zhang, Guy Van den Broeck:
Scaling Up Probabilistic Circuits by Latent Variable Distillation.
		Daniel Barzilai, Amnon Geifman, Meirav Galun, Ronen Basri:
A Kernel Perspective of Skip Connections in Convolutional Networks.
		Matthew Ho, Aditya Sharma, Justin Chang, Michael Saxon, Sharon Levy, Yujie Lu, William Yang Wang:
WikiWhy: Answering and Explaining Cause-and-Effect Questions.
		Samuel K. Ainsworth, Jonathan Hayase, Siddhartha S. Srinivasa:
Git Re-Basin: Merging Models modulo Permutation Symmetries.
		Tengyang Xie, Dylan J. Foster, Yu Bai, Nan Jiang, Sham M. Kakade:
The Role of Coverage in Online Reinforcement Learning.
		Takashi Ishida, Ikko Yamane, Nontawat Charoenphakdee, Gang Niu, Masashi Sugiyama:
Is the Performance of My Deep Network Too Good to Be True? A Direct Approach to Estimating the Bayes Error in Binary Classification.
		Aviral Kumar, Rishabh Agarwal, Xinyang Geng, George Tucker, Sergey Levine:
Offline Q-learning on Diverse Multi-Task Data Both Scales And Generalizes.
		Ekin Akyürek, Dale Schuurmans, Jacob Andreas, Tengyu Ma, Denny Zhou:
What learning algorithm is in-context learning? Investigations with linear models.
		Zeyuan Allen-Zhu, Yuanzhi Li:
Towards Understanding Ensemble, Knowledge Distillation and Self-Distillation in Deep Learning.
		Mert Yüksekgönül, Federico Bianchi, Pratyusha Kalluri, Dan Jurafsky, James Zou:
When and Why Vision-Language Models Behave like Bags-Of-Words, and What to Do About It?
		Joey Hong, Aviral Kumar, Sergey Levine:
Confidence-Conditioned Value Functions for Offline Reinforcement Learning.
		Joey Hong, Kush Bhatia, Anca D. Dragan:
On the Sensitivity of Reward Inference to Misspecified Human Models.
		Jinhyung Park, Chenfeng Xu, Shijia Yang, Kurt Keutzer, Kris M. Kitani, Masayoshi Tomizuka, Wei Zhan:
Time Will Tell: New Outlooks and A Baseline for Temporal Multi-View 3D Object Detection.
		Sherry Yang, Dale Schuurmans, Pieter Abbeel, Ofir Nachum:
Dichotomy of Control: Separating What You Can Control from What You Cannot.
		Cristina Cornelio, Jan Stuehmer, Shell Xu Hu, Timothy M. Hospedales:
Learning where and when to reason in neuro-symbolic inference.
		Quentin Garrido, Yubei Chen, Adrien Bardes, Laurent Najman, Yann LeCun:
On the duality between contrastive and non-contrastive self-supervised learning.
		Ben Poole, Ajay Jain, Jonathan T. Barron, Ben Mildenhall:
DreamFusion: Text-to-3D using 2D Diffusion.
		Sitan Chen, Sinho Chewi, Jerry Li, Yuanzhi Li, Adil Salim, Anru Zhang:
Sampling is as easy as learning the score: theory for diffusion models with minimal data assumptions.
		Donggyun Kim, Jinwoo Kim, Seongwoong Cho, Chong Luo, Seunghoon Hong:
Universal Few-shot Learning of Dense Prediction Tasks with Visual Token Matching.
		Heshan Devaka Fernando, Han Shen, Miao Liu, Subhajit Chaudhury, Keerthiram Murugesan, Tianyi Chen:
Mitigating Gradient Bias in Multi-objective Learning: A Provably Convergent Approach.
		Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik R. Narasimhan, Yuan Cao:
ReAct: Synergizing Reasoning and Acting in Language Models.
		Weilin Cong, Si Zhang, Jian Kang, Baichuan Yuan, Hao Wu, Xin Zhou, Hanghang Tong, Mehrdad Mahdavi:
Do We Really Need Complicated Model Architectures For Temporal Networks?
		Anurag Ajay, Yilun Du, Abhi Gupta, Joshua B. Tenenbaum, Tommi S. Jaakkola, Pulkit Agrawal:
Is Conditional Generative Modeling all you need for Decision Making?
		Nate Gruver, Marc Anton Finzi, Micah Goldblum, Andrew Gordon Wilson:
The Lie Derivative for Measuring Learned Equivariance.
		Matteo Pagliardini, Martin Jaggi, François Fleuret, Sai Praneeth Karimireddy:
Agree to Disagree: Diversity through Disagreement for Better Transferability.
		Roman Pogodin, Namrata Deka, Yazhe Li, Danica J. Sutherland, Victor Veitch, Arthur Gretton:
Efficient Conditionally Invariant Representation Learning.
		Joel Dapello, Kohitij Kar, Martin Schrimpf, Robert Baldwin Geary, Michael Ferguson, David Daniel Cox, James J. DiCarlo:
Aligning Model and Macaque Inferior Temporal Cortex Representations Improves Model-to-Human Behavioral Alignment and Adversarial Robustness.
		Bingbin Liu, Jordan T. Ash, Surbhi Goel, Akshay Krishnamurthy, Cyril Zhang:
Transformers Learn Shortcuts to Automata.
		Michael Laskin, Luyu Wang, Junhyuk Oh, Emilio Parisotto, Stephen Spencer, Richie Steigerwald, DJ Strouse, Steven Stenberg Hansen, Angelos Filos, Ethan A. Brooks, Maxime Gazeau, Himanshu Sahni, Satinder Singh, Volodymyr Mnih:
In-context Reinforcement Learning with Algorithm Distillation.
		Antonia Creswell, Murray Shanahan, Irina Higgins:
Selection-Inference: Exploiting Large Language Models for Interpretable Logical Reasoning.
		Langwen Huang, Torsten Hoefler:
Compressing multidimensional weather and climate data into neural networks.
		Ali Shahin Shamsabadi, Sierra Calanda Wyllie, Nicholas Franzese, Natalie Dullerud, Sébastien Gambs, Nicolas Papernot, Xiao Wang, Adrian Weller:
Confidential-PROFITT: Confidential PROof of FaIr Training of Trees.
		Lingxiao Huang, Shaofeng H.-C. Jiang, Jianing Lou, Xuan Wu:
Near-optimal Coresets for Robust Clustering.
		Shaokun Zhang, Feiran Jia, Chi Wang, Qingyun Wu:
Targeted Hyperparameter Optimization with Lexicographic Preferences Over Multiple Objectives.
		Anton Bakhtin, David J. Wu, Adam Lerer, Jonathan Gray, Athul Paul Jacob, Gabriele Farina, Alexander H. Miller, Noam Brown:
Mastering the Game of No-Press Diplomacy via Human-Regularized Reinforcement Learning and Planning.
		Lin Zheng, Jianbo Yuan, Chong Wang, Lingpeng Kong:
Efficient Attention via Control Variates.
		Thomas Möllenhoff, Mohammad Emtiyaz Khan:
SAM as an Optimal Relaxation of Bayes.
		Jianan Zhao, Meng Qu, Chaozhuo Li, Hao Yan, Qian Liu, Rui Li, Xing Xie, Jian Tang:
Learning on Large-scale Text-attributed Graphs via Variational Inference.
		Divyansh Garg, Joey Hejna, Matthieu Geist, Stefano Ermon:
Extreme Q-Learning: MaxEnt RL without Entropy.
		Fivos Kalogiannis, Ioannis Anagnostides, Ioannis Panageas, Emmanouil-Vasileios Vlatakis-Gkaragkounis, Vaggos Chatziafratis, Stelios Andrew Stavroulakis:
Efficiently Computing Nash Equilibria in Adversarial Team Markov Games.
		Jimmy T. H. Smith, Andrew Warrington, Scott W. Linderman:
Simplified State Space Layers for Sequence Modeling.
		Kuo-Hao Zeng, Luca Weihs, Roozbeh Mottaghi, Ali Farhadi:
Moving Forward by Moving Backward: Embedding Action Impact over Action Semantics.
		Yuzhe Yang, Xin Liu, Jiang Wu, Silviu Borac, Dina Katabi, Ming-Zher Poh, Daniel McDuff:
SimPer: Simple Self-Supervised Learning of Periodic Targets.
		Xi Chen, Xiao Wang, Soravit Changpinyo, A. J. Piergiovanni, Piotr Padlewski, Daniel Salz, Sebastian Goodman, Adam Grycner, Basil Mustafa, Lucas Beyer, Alexander Kolesnikov, Joan Puigcerver, Nan Ding, Keran Rong, Hassan Akbari, Gaurav Mishra, Linting Xue, Ashish V. Thapliyal, James Bradbury, Weicheng Kuo:
PaLI: A Jointly-Scaled Multilingual Language-Image Model.
		Pierluca D'Oro, Max Schwarzer, Evgenii Nikishin, Pierre-Luc Bacon, Marc G. Bellemare, Aaron C. Courville:
Sample-Efficient Reinforcement Learning by Breaking the Replay Ratio Barrier.
		Shuaichen Chang, Jun Wang, Mingwen Dong, Lin Pan, Henghui Zhu, Alexander Hanbo Li, Wuwei Lan, Sheng Zhang, Jiarong Jiang, Joseph Lilien, Steve Ash, William Yang Wang, Zhiguo Wang, Vittorio Castelli, Patrick Ng, Bing Xiang:
Dr.Spider: A Diagnostic Evaluation Benchmark towards Text-to-SQL Robustness.
		Guangji Bai, Chen Ling, Liang Zhao:
Temporal Domain Generalization with Drift-Aware Dynamic Neural Networks.
		Albert Qiaochu Jiang, Sean Welleck, Jin Peng Zhou, Timothée Lacroix, Jiacheng Liu, Wenda Li, Mateja Jamnik, Guillaume Lample, Yuhuai Wu:
Draft, Sketch, and Prove: Guiding Formal Theorem Provers with Informal Proofs.
		Duc N. M. Hoang, Shiwei Liu, Radu Marculescu, Zhangyang Wang:
Revisiting Pruning at Initialization Through the Lens of Ramanujan Graph.
		Chongyi Li, Chun-Le Guo, Man Zhou, Zhexin Liang, Shangchen Zhou, Ruicheng Feng, Chen Change Loy:
Embedding Fourier for Ultra-High-Definition Low-Light Image Enhancement.
		Paul F. Jaeger, Carsten T. Lüth, Lukas Klein, Till J. Bungert:
A Call to Reflect on Evaluation Practices for Failure Detection in Image Classification.
		Michal Zawalski, Michal Tyrolski, Konrad Czechowski, Tomasz Odrzygózdz, Damian Stachura, Piotr Piekos, Yuhuai Wu, Lukasz Kucinski, Piotr Milos:
Fast and Precise: Adjusting Planning Horizon with Adaptive Subgoal Search.
		Kaituo Feng, Changsheng Li, Xiaolu Zhang, Jun Zhou:
Towards Open Temporal Graph Neural Networks.
		Luca Moschella, Valentino Maiorca, Marco Fumero, Antonio Norelli, Francesco Locatello, Emanuele Rodolà:
Relative representations enable zero-shot latent space communication.
		Phillip Rust, Jonas F. Lotz, Emanuele Bugliarello, Elizabeth Salesky, Miryam de Lhoneux, Desmond Elliott:
Language Modelling with Pixels.
		Marius-Constantin Dinu, Markus Holzleitner, Maximilian Beck, Hoan Duc Nguyen, Andrea Huber, Hamid Eghbal-zadeh, Bernhard Alois Moser, Sergei V. Pereverzyev, Sepp Hochreiter, Werner Zellinger:
Addressing Parameter Choice Issues in Unsupervised Domain Adaptation by Aggregation.
		Fangzheng Sun, Yang Liu, Jian-Xun Wang, Hao Sun:
Symbolic Physics Learner: Discovering governing equations via Monte Carlo tree search.
		Kangjie Chen, Xiaoxuan Lou, Guowen Xu, Jiwei Li, Tianwei Zhang:
Clean-image Backdoor: Attacking Multi-label Models with Poisoned Labels Only.
		Benjamin Paul Chamberlain, Sergey Shirobokov, Emanuele Rossi, Fabrizio Frasca, Thomas Markovich, Nils Yannick Hammerla, Michael M. Bronstein, Max Hansmire:
Graph Neural Networks for Link Prediction with Subgraph Sketching.
		David Klee, Ondrej Biza, Robert Platt, Robin Walters:
Image to Sphere: Learning Equivariant Features for Efficient Pose Prediction.
		Huiqiang Wang, Jian Peng, Feihu Huang, Jince Wang, Junhui Chen, Yifei Xiao:
MICN: Multi-scale Local and Global Context Modeling for Long-term Series Forecasting.
		Jian Xu, Xinyi Tong, Shao-Lun Huang:
Personalized Federated Learning with Feature Alignment and Classifier Collaboration.
		Zichen Jeff Cui, Yibin Wang, Nur Muhammad (Mahi) Shafiullah, Lerrel Pinto:
From Play to Policy: Conditional Behavior Generation from Uncurated Robot Data.
		Sachit Menon, Carl Vondrick:
Visual Classification via Description from Large Language Models.
		Zihui Xue, Zhengqi Gao, Sucheng Ren, Hang Zhao:
The Modality Focusing Hypothesis: Towards Understanding Crossmodal Knowledge Distillation.
		Juhan Bae, Michael R. Zhang, Michael Ruan, Eric Wang, So Hasegawa, Jimmy Ba, Roger Baker Grosse:
Multi-Rate VAE: Train Once, Get the Full Rate-Distortion Curve.
		Xiang Li, Viraj Mehta, Johannes Kirschner, Ian Char, Willie Neiswanger, Jeff Schneider, Andreas Krause, Ilija Bogunovic:
Near-optimal Policy Identification in Active Reinforcement Learning.
		Xiangzhe Kong, Wenbing Huang, Yang Liu:
Conditional Antibody Design as 3D Equivariant Graph Translation.
		Kenneth Li, Aspen K. Hopkins, David Bau, Fernanda B. Viégas, Hanspeter Pfister, Martin Wattenberg:
Emergent World Representations: Exploring a Sequence Model Trained on a Synthetic Task.
		Haozhe Ji, Pei Ke, Zhipeng Hu, Rongsheng Zhang, Minlie Huang:
Tailoring Language Generation Models under Total Variation Distance.
		Vincent Micheli, Eloi Alonso, François Fleuret:
Transformers are Sample-Efficient World Models.
		Frederic Koehler, Alexander Heckett, Andrej Risteski:
Statistical Efficiency of Score Matching: The View from Isoperimetry.
		Yiming Zuo, Jia Deng:
View Synthesis with Sculpted Neural Points.
		Zizhao Zhang, Xin Wang, Chaoyu Guan, Ziwei Zhang, Haoyang Li, Wenwu Zhu:
AutoGT: Automated Graph Transformer Architecture Search.
		Yunhao Zhang, Junchi Yan:
Crossformer: Transformer Utilizing Cross-Dimension Dependency for Multivariate Time Series Forecasting.
		Sang Keun Choe, Willie Neiswanger, Pengtao Xie, Eric P. Xing:
Betty: An Automatic Differentiation Library for Multilevel Optimization.
		Haoran Xu, Li Jiang, Jianxiong Li, Zhuoran Yang, Zhaoran Wang, Wai Kin Victor Chan, Xianyuan Zhan:
Offline RL with No OOD Actions: In-Sample Learning via Implicit Value Regularization.
		Pan Zhou, Xingyu Xie, Shuicheng Yan:
Win: Weight-Decay-Integrated Nesterov Acceleration for Adaptive Gradient Algorithms.
		Shuaicheng Niu, Jiaxiang Wu, Yifan Zhang, Zhiquan Wen, Yaofo Chen, Peilin Zhao, Mingkui Tan:
Towards Stable Test-time Adaptation in Dynamic Wild World.
		Jingtao Li, Lingjuan Lyu, Daisuke Iso, Chaitali Chakrabarti, Michael Spranger:
MocoSFL: enabling cross-client collaborative self-supervised learning.
		Siwei Chen, Yiqing Xu, Cunjun Yu, Linfeng Li, Xiao Ma, Zhongwen Xu, David Hsu:
DaxBench: Benchmarking Deformable Object Manipulation with Differentiable Physics.
		Ivan Skorokhodov, Aliaksandr Siarohin, Yinghao Xu, Jian Ren, Hsin-Ying Lee, Peter Wonka, Sergey Tulyakov:
3D generation on ImageNet.
		Bohang Zhang, Shengjie Luo, Liwei Wang, Di He:
Rethinking the Expressive Power of GNNs via Graph Biconnectivity.
		Bo Li, Yifei Shen, Jingkang Yang, Yezhen Wang, Jiawei Ren, Tong Che, Jun Zhang, Ziwei Liu:
Sparse Mixture-of-Experts are Domain Generalizable Learners.
		Daniel Bolya, Cheng-Yang Fu, Xiaoliang Dai, Peizhao Zhang, Christoph Feichtenhofer, Judy Hoffman:
Token Merging: Your ViT But Faster.
		Jiajun Fan, Yuzheng Zhuang, Yuecheng Liu, Jianye Hao, Bin Wang, Jiangcheng Zhu, Hao Wang, Shu-Tao Xia:
Learnable Behavior Control: Breaking Atari Human World Records via Sample-Efficient Behavior Selection.
		Xu Ma, Yuqian Zhou, Huan Wang, Can Qin, Bin Sun, Chang Liu, Yun Fu:
Image as Set of Points.
		Florian E. Dorner, Momchil Peychev, Nikola Konstantinov, Naman Goel, Elliott Ash, Martin T. Vechev:
Human-Guided Fair Classification for Natural Language Processing.
		Qiongkai Xu, Christian Walder, Chenchen Xu:
Humanly Certifying Superhuman Classifiers.
		Jayaram Raghuram, Yijing Zeng, Dolores García, Rafael Ruiz, Somesh Jha, Joerg Widmer, Suman Banerjee:
Few-Shot Domain Adaptation For End-to-End Communication.
		Liyao Li, Haobo Wang, Liangyu Zha, Qingyi Huang, Sai Wu, Gang Chen, Junbo Zhao:
Learning a Data-Driven Policy Network for Pre-Training Automated Feature Engineering.
		Thomas M. Sutter, Laura Manduchi, Alain Ryser, Julia E. Vogt:
Learning Group Importance using the Differentiable Hypergeometric Distribution.
		Andrea Bontempelli, Stefano Teso, Katya Tentori, Fausto Giunchiglia, Andrea Passerini:
Concept-level Debugging of Part-Prototype Networks.
		Félix Chalumeau, Raphaël Boige, Bryan Lim, Valentin Macé, Maxime Allard, Arthur Flajolet, Antoine Cully, Thomas Pierrot:
Neuroevolution is a Competitive Alternative to Reinforcement Learning for Skill Discovery.
		Spencer Frei, Gal Vardi, Peter L. Bartlett, Nathan Srebro, Wei Hu:
Implicit Bias in Leaky ReLU Networks Trained on High-Dimensional Data.
		Zhenghai Xue, Zhenghao Peng, Quanyi Li, Zhihan Liu, Bolei Zhou:
Guarded Policy Optimization with Imperfect Online Demonstrations.
		Zenan Li, Zehua Liu, Yuan Yao, Jingwei Xu, Taolue Chen, Xiaoxing Ma, Jian Lü:
Learning with Logical Constraints but without Shortcut Satisfaction.
		Mark Niklas Müller, Franziska Eckert, Marc Fischer, Martin T. Vechev:
Certified Training: Small Boxes are All You Need.
		Jiyan Jiang, Wenpeng Zhang, Shiji Zhou, Lihong Gu, Xiaodong Zeng, Wenwu Zhu:
Multi-Objective Online Learning.
		Xin-Qiang Cai, Yao-Xiang Ding, Zi-Xuan Chen, Yuan Jiang, Masashi Sugiyama, Zhi-Hua Zhou:
Seeing Differently, Acting Similarly: Heterogeneously Observable Imitation Learning.
		Puja Trivedi, Danai Koutra, Jayaraman J. Thiagarajan:
A Closer Look at Model Adaptation using Feature Distortion and Simplicity Bias.
		Kuno Kim, Stefano Ermon:
Understanding and Adopting Rational Behavior by Bellman Score Estimation.
		Jaehyun Nam, Jihoon Tack, Kyungmin Lee, Hankook Lee, Jinwoo Shin:
STUNT: Few-shot Tabular Learning with Self-generated Tasks from Unlabeled Tables.
		Simran Arora, Avanika Narayan, Mayee F. Chen, Laurel J. Orr, Neel Guha, Kush Bhatia, Ines Chami, Christopher Ré:
Ask Me Anything: A simple strategy for prompting language models.
		Ziang Chen, Jialin Liu, Xinshang Wang, Wotao Yin:
On Representing Linear Programs by Graph Neural Networks.
		Sungyub Kim, Sihwan Park, Kyung-Su Kim, Eunho Yang:
Scale-invariant Bayesian Neural Networks with Connectivity Tangent Kernel.
		Yubei Chen, Zeyu Yun, Yi Ma, Bruno A. Olshausen, Yann LeCun:
Minimalistic Unsupervised Representation Learning with the Sparse Manifold Transform.
		Mingze Dong, Yuval Kluger:
GEASS: Neural causal feature selection for high-dimensional biological data.
		Sheng Li, Geng Yuan, Yue Dai, Youtao Zhang, Yanzhi Wang, Xulong Tang:
SmartFRZ: An Efficient Training Framework using Attention-Based Layer Freezing.
		Chenjun Xiao, Han Wang, Yangchen Pan, Adam White, Martha White:
The In-Sample Softmax for Offline Reinforcement Learning.
		Huiwon Jang, Hankook Lee, Jinwoo Shin:
Unsupervised Meta-learning via Few-shot Pseudo-supervised Contrastive Learning.
		Hankook Lee, Jongheon Jeong, Sejun Park, Jinwoo Shin:
Guiding Energy-based Models via Contrastive Latent Variables.
		Avrajit Ghosh, He Lyu, Xitong Zhang, Rongrong Wang:
Implicit regularization in Heavy-ball momentum accelerated stochastic gradient descent.
		Matthew Dowling, Yuan Zhao, Il Memming Park:
Real-time variational method for learning neural trajectory and its dynamics.
		Ze Wang, Jiang Wang, Zicheng Liu, Qiang Qiu:
Energy-Inspired Self-Supervised Pretraining for Vision Models.
		Zhoujun Cheng, Tianbao Xie, Peng Shi, Chengzu Li, Rahul Nadkarni, Yushi Hu, Caiming Xiong, Dragomir Radev, Mari Ostendorf, Luke Zettlemoyer, Noah A. Smith, Tao Yu:
Binding Language Models in Symbolic Languages.
		Zhong Yi Wan, Leonardo Zepeda-Núñez, Anudhyan Boral, Fei Sha:
Evolve Smoothly, Fit Consistently: Learning Smooth Latent Dynamics For Advection-Dominated Systems.
		Andrew Szot, Amy Zhang, Dhruv Batra, Zsolt Kira, Franziska Meier:
BC-IRL: Learning Generalizable Reward Functions from Demonstrations.
		Matthew Ricci, Noa Moriel, Zoe Piran, Mor Nitzan:
Phase2vec: dynamical systems embedding with a physics-informed convolutional network.
		Qinsheng Zhang, Molei Tao, Yongxin Chen:
gDDIM: Generalized denoising diffusion implicit models.
		Divyansh Jhunjhunwala, Shiqiang Wang, Gauri Joshi:
FedExP: Speeding Up Federated Averaging via Extrapolation.
		Si Si, Felix X. Yu, Ankit Singh Rawat, Cho-Jui Hsieh, Sanjiv Kumar:
Serving Graph Compression for Graph Neural Networks.
		Yijun Tian, Chuxu Zhang, Zhichun Guo, Xiangliang Zhang, Nitesh V. Chawla:
Learning MLPs on Graphs: A Unified View of Effectiveness, Robustness, and Efficiency.
		Yuan Gong, Andrew Rouditchenko, Alexander H. Liu, David Harwath, Leonid Karlinsky, Hilde Kuehne, James R. Glass:
Contrastive Audio-Visual Masked Autoencoder.
		Daniel Kunin, Atsushi Yamamura, Chao Ma, Surya Ganguli:
The Asymmetric Maximum Margin Bias of Quasi-Homogeneous Neural Networks.
		Yicheng Luo, Zhengyao Jiang, Samuel Cohen, Edward Grefenstette, Marc Peter Deisenroth:
Optimal Transport for Offline Imitation Learning.
		Rajkumar Ramamurthy, Prithviraj Ammanabrolu, Kianté Brantley, Jack Hessel, Rafet Sifa, Christian Bauckhage, Hannaneh Hajishirzi, Yejin Choi:
Is Reinforcement Learning (Not) for Natural Language Processing: Benchmarks, Baselines, and Building Blocks for Natural Language Policy Optimization.
		Zahra Kadkhodaie, Florentin Guth, Stéphane Mallat, Eero P. Simoncelli:
Learning multi-scale local conditional probability models of images.
		James C. R. Whittington, Will Dorrell, Surya Ganguli, Timothy Behrens:
Disentanglement with Biological Constraints: A Theory of Functional Cell Types.
		Kelsey R. Allen, Yulia Rubanova, Tatiana Lopez-Guevara, William Whitney, Alvaro Sanchez-Gonzalez, Peter W. Battaglia, Tobias Pfaff:
Learning rigid dynamics with face interaction graph networks.
		Arthur Jacot:
Implicit Bias of Large Depth Networks: a Notion of Rank for Nonlinear Functions.
		Yunwei Ren, Mo Zhou, Rong Ge:
Depth Separation with Multilayer Mean-Field Networks.
		Wenbo Gong, Joel Jennings, Cheng Zhang, Nick Pawlowski:
Rhino: Deep Causal Temporal Relationship Learning with History-dependent Noise.
		Lorenz Kuhn, Yarin Gal, Sebastian Farquhar:
Semantic Uncertainty: Linguistic Invariances for Uncertainty Estimation in Natural Language Generation.
		Hariprasath Govindarajan, Per Sidén, Jacob Roll, Fredrik Lindsten:
DINO as a von Mises-Fisher mixture model.
		Uday Kamal, Saurabh Dash, Saibal Mukhopadhyay:
Associative Memory Augmented Asynchronous Spatiotemporal Representation Learning for Event-based Perception.
		Yanchao Sun, Shuang Ma, Ratnesh Madaan, Rogerio Bonatti, Furong Huang, Ashish Kapoor:
SMART: Self-supervised Multi-task pretrAining with contRol Transformers.
		Tianjun Zhang, Xuezhi Wang, Denny Zhou, Dale Schuurmans, Joseph E. Gonzalez:
TEMPERA: Test-Time Prompt Editing via Reinforcement Learning.
		Rem Yang, Jacob Laurel, Sasa Misailovic, Gagandeep Singh:
Provable Defense Against Geometric Transformations.
		Polina Kirichenko, Pavel Izmailov, Andrew Gordon Wilson:
Last Layer Re-Training is Sufficient for Robustness to Spurious Correlations.
		Eoin M. Kenny, Mycal Tucker, Julie Shah:
Towards Interpretable Deep Reinforcement Learning with Human-Friendly Prototypes.
		Dian Wang, Jung Yeon Park, Neel Sortur, Lawson L. S. Wong, Robin Walters, Robert Platt:
The Surprising Effectiveness of Equivariant Models in Domains with Latent Symmetry.
		Zhili Liu, Kai Chen, Jianhua Han, Lanqing Hong, Hang Xu, Zhenguo Li, James T. Kwok:
Task-customized Masked Autoencoder via Mixture of Cluster-conditional Experts.
		Jivat Neet Kaur, Emre Kiciman, Amit Sharma:
Modeling the Data-Generating Process is Necessary for Out-of-Distribution Generalization.
		Lisa Dunlap, Clara Mohri, Devin Guillory, Han Zhang, Trevor Darrell, Joseph E. Gonzalez, Aditi Raghunathan, Anna Rohrbach:
Using Language to Extend to Unseen Domains.
		Zhuoqing Song, Jason D. Lee, Zhuoran Yang:
Can We Find Nash Equilibria at a Linear Rate in Markov Games?
		Adrien Journé, Hector Garcia Rodriguez, Qinghai Guo, Timoleon Moraitis:
Hebbian Deep Learning Without Feedback.
		Edoardo Balzani, Jean-Paul Noel, Pedro Herrero-Vidal, Dora E. Angelaki, Cristina Savin:
A probabilistic framework for task-aligned intra- and inter-area neural manifold estimation.
		Shoaib Ahmed Siddiqui, Nitarshan Rajkumar, Tegan Maharaj, David Krueger, Sara Hooker:
Metadata Archaeology: Unearthing Data Subsets by Leveraging Training Dynamics.
		Quentin Bouniot, Romaric Audigier, Angélique Loesch, Amaury Habrard:
Proposal-Contrastive Pretraining for Object Detection from Fewer Data.
		Badr Youbi Idrissi, Diane Bouchacourt, Randall Balestriero, Ivan Evtimov, Caner Hazirbas, Nicolas Ballas, Pascal Vincent, Michal Drozdzal, David Lopez-Paz, Mark Ibrahim:
ImageNet-X: Understanding Model Mistakes with Factor of Variation Annotations.
		Yuxin Wen, Arpit Bansal, Hamid Kazemi, Eitan Borgnia, Micah Goldblum, Jonas Geiping, Tom Goldstein:
Canary in a Coalmine: Better Membership Inference with Ensembled Adversarial Queries.
		Pietro Mazzaglia, Tim Verbelen, Bart Dhoedt, Alexandre Lacoste, Sai Rajeswar:
Choreographer: Learning and Adapting Skills in Imagination.
		Jake Bruce, Ankit Anand, Bogdan Mazoure, Rob Fergus:
Learning About Progress From Experts.
		Hongyi Ling, Zhimeng Jiang, Youzhi Luo, Shuiwang Ji, Na Zou:
Learning Fair Graph Representations via Automated Data Augmentations.
		Erik Wijmans, Manolis Savva, Irfan Essa, Stefan Lee, Ari S. Morcos, Dhruv Batra:
Emergence of Maps in the Memories of Blind Navigation Agents.
		Lu Lin, Jinghui Chen, Hongning Wang:
Spectral Augmentation for Self-Supervised Learning on Graphs.
		Thanh Nguyen-Tang, Raman Arora:
VIPeR: Provably Efficient Algorithm for Offline RL with Neural Function Approximation.
		Léon Zheng, Gilles Puy, Elisa Riccietti, Patrick Pérez, Rémi Gribonval:
Self-supervised learning with rotation-invariant kernels.
		Deniz Oktay, Mehran Mirramezani, Eder Medina, Ryan P. Adams:
Neuromechanical Autoencoders: Learning to Couple Elastic and Neural Network Nonlinearity.
		Yecheng Jason Ma, Shagun Sodhani, Dinesh Jayaraman, Osbert Bastani, Vikash Kumar, Amy Zhang:
VIP: Towards Universal Visual Reward and Representation via Value-Implicit Pre-Training.
		Ainesh Bakshi, Piotr Indyk, Praneeth Kacham, Sandeep Silwal, Samson Zhou:
Subquadratic Algorithms for Kernel Matrices via Kernel Density Estimation.
		Pankaj K. Agarwal, Sharath Raghvendra, Pouyan Shirzadian, Rachita Sowle:
A Higher Precision Algorithm for Computing the $1$-Wasserstein Distance.
		Sylvestre-Alvise Rebuffi, Francesco Croce, Sven Gowal:
Revisiting adapters with adversarial training.
		Zhenting Wang, Kai Mei, Juan Zhai, Shiqing Ma:
UNICORN: A Unified Backdoor Trigger Inversion Framework.
		Aleksandar Pavlovic, Emanuel Sallinger:
ExpressivE: A Spatio-Functional Embedding For Knowledge Graph Completion.
		Jan Schuchardt, Tom Wollschläger, Aleksandar Bojchevski, Stephan Günnemann:
Localized Randomized Smoothing for Collective Robustness Certification.
		Xiaoling Hu, Dimitris Samaras, Chao Chen:
Learning Probabilistic Topological Representations Using Discrete Morse Theory.
		Scott Sussex, Anastasia Makarova, Andreas Krause:
Model-based Causal Bayesian Optimization.
		Khai Loong Aw, Mariya Toneva:
Training language models to summarize narratives improves brain alignment.
		Danilo Numeroso, Davide Bacciu, Petar Velickovic:
Dual Algorithmic Reasoning.
		Tan Minh Nguyen, Tam Minh Nguyen, Nhat Ho, Andrea L. Bertozzi, Richard G. Baraniuk, Stanley J. Osher:
A Primal-Dual Framework for Transformers and Neural Networks.
		Jezabel R. Garcia, Federica Freddi, Stathi Fotiadis, Maolin Li, Sattar Vakili, Alberto Bernacchia, Guillaume Hennequin:
Fisher-Legendre (FishLeg) optimization of deep neural networks.
		Sen Yang, Wen Heng, Gang Liu, Guozhong Luo, Wankou Yang, Gang Yu:
Capturing the Motion of Every Joint: 3D Human Pose and Shape Estimation with Independent Tokens.
		Anand Subramoney, Khaleelulla Khan Nazeer, Mark Schöne, Christian Mayr, David Kappel:
Efficient recurrent architectures through activity sparsity and sparse back-propagation through time.
		Xingchao Liu, Chengyue Gong, Qiang Liu:
Flow Straight and Fast: Learning to Generate and Transfer Data with Rectified Flow.
		Ranjie Duan, Yuefeng Chen, Yao Zhu, Xiaojun Jia, Rong Zhang, Hui Xue:
Inequality phenomenon in l∞-adversarial training, and its unrealized threats.
		Xingchao Liu, Lemeng Wu, Mao Ye, Qiang Liu:
Learning Diffusion Bridges on Constrained Domains.
		Andrii Zadaianchuk, Matthäus Kleindessner, Yi Zhu, Francesco Locatello, Thomas Brox:
Unsupervised Semantic Segmentation with Self-supervised Object-centric Representations.
		Hao He, Kaiwen Zha, Dina Katabi:
Indiscriminate Poisoning Attacks on Unsupervised Contrastive Learning.
		Congyu Qiao, Ning Xu, Xin Geng:
Decompositional Generation Process for Instance-Dependent Partial Label Learning.
		Jean-Baptiste Gaya, Thang Doan, Lucas Caccia, Laure Soulier, Ludovic Denoyer, Roberta Raileanu:
Building a Subspace of Policies for Scalable Continual Learning.
		Jing Zhou, Zongyu Lin, Yanan Zheng, Jian Li, Zhilin Yang:
Not All Tasks Are Born Equal: Understanding Zero-Shot Generalization.
		Tong Yang, Michael I. Jordan, Tatjana Chavdarova:
Solving Constrained Variational Inequalities via a First-order Interior Point-based Method.
		Xinbiao Wang, Junyu Liu, Tongliang Liu, Yong Luo, Yuxuan Du, Dacheng Tao:
Symmetric Pruning in Quantum Neural Networks.
		Brian Chmiel, Itay Hubara, Ron Banner, Daniel Soudry:
Minimum Variance Unbiased N: M Sparsity for the Neural Gradients.
		Xiaoman Pan, Wenlin Yao, Hongming Zhang, Dian Yu, Dong Yu, Jianshu Chen:
Knowledge-in-Context: Towards Knowledgeable Semi-Parametric Language Models.
		Zhaoqing Wang, Ziyu Chen, Yaqian Li, Yandong Guo, Jun Yu, Mingming Gong, Tongliang Liu:
Mosaic Representation Learning for Self-supervised Visual Pre-training.
		Zhou Xian, Bo Zhu, Zhenjia Xu, Hsiao-Yu Tung, Antonio Torralba, Katerina Fragkiadaki, Chuang Gan:
FluidLab: A Differentiable Environment for Benchmarking Complex Fluid Manipulation.
		Yaron Lipman, Ricky T. Q. Chen, Heli Ben-Hamu, Maximilian Nickel, Matthew Le:
Flow Matching for Generative Modeling.
		Xuan Li, Yi-Ling Qiao, Peter Yichen Chen, Krishna Murthy Jatavallabhula, Ming C. Lin, Chenfanfu Jiang, Chuang Gan:
PAC-NeRF: Physics Augmented Continuum Neural Radiance Fields for Geometry-Agnostic System Identification.
		Tuomas P. Oikarinen, Tsui-Wei Weng:
CLIP-Dissect: Automatic Description of Neuron Representations in Deep Vision Networks.
		Eric Qu, Xufang Luo, Dongsheng Li:
Data Continuity Matters: Improving Sequence Modeling with Lipschitz Regularizer.
		Erik Nijkamp, Bo Pang, Hiroaki Hayashi, Lifu Tu, Huan Wang, Yingbo Zhou, Silvio Savarese, Caiming Xiong:
CodeGen: An Open Large Language Model for Code with Multi-Turn Program Synthesis.
		Olga Golovneva, Moya Chen, Spencer Poff, Martin Corredor, Luke Zettlemoyer, Maryam Fazel-Zarandi, Asli Celikyilmaz:
ROSCOE: A Suite of Metrics for Scoring Step-by-Step Reasoning.
		Peiyu Yang, Naveed Akhtar, Zeyi Wen, Mubarak Shah, Ajmal Saeed Mian:
Re-calibrating Feature Attributions for Model Interpretation.
		Brandon Cui, Andrei Lupu, Samuel Sokota, Hengyuan Hu, David J. Wu, Jakob Nicolaus Foerster:
Adversarial Diversity in Hanabi.
		Paria Rashidinejad, Hanlin Zhu, Kunhe Yang, Stuart Russell, Jiantao Jiao:
Optimal Conservative Offline RL with General Function Approximation via Augmented Lagrangian.
		Shuyan Zhou, Uri Alon, Frank F. Xu, Zhengbao Jiang, Graham Neubig:
DocPrompting: Generating Code by Retrieving the Docs.
		Hiroki Furuta, Yusuke Iwasawa, Yutaka Matsuo, Shixiang Shane Gu:
A System for Morphology-Task Generalization via Unified Representation and Behavior Distillation.
		Neel Nanda, Lawrence Chan, Tom Lieberum, Jess Smith, Jacob Steinhardt:
Progress measures for grokking via mechanistic interpretability.
		Zhangyang Gao, Cheng Tan, Stan Z. Li:
PiFold: Toward effective and efficient protein inverse folding.
		Edward S. Hu, Richard Chang, Oleh Rybkin, Dinesh Jayaraman:
Planning Goals for Exploration.
		Yijie Wang, Yuan Zhou, Xiaoqing Huang, Kun Huang, Jie Zhang, Jianzhu Ma:
Learning Sparse Group Models Through Boolean Relaxation.
		Zhen Liu, Yao Feng, Michael J. Black, Derek Nowrouzezahrai, Liam Paull, Weiyang Liu:
MeshDiffusion: Score-based Generative 3D Mesh Modeling.
		Fan Chen, Yu Bai, Song Mei:
Partially Observable RL with B-Stability: Unified Structural Condition and Sharp Sample-Efficient Algorithms.
		Hyungu Kahng, Hyungrok Do, Judy Zhong:
Domain Generalization via Heckman-type Selection Models.
		Vanshaj Khattar, Yuhao Ding, Bilgehan Sel, Javad Lavaei, Ming Jin:
A CMDP-within-online framework for Meta-Safe Reinforcement Learning.
		Aseem Baranwal, Kimon Fountoulakis, Aukosh Jagannath:
Effects of Graph Convolutions in Multi-layer Networks.
		Mert Yüksekgönül, Maggie Wang, James Zou:
Post-hoc Concept Bottleneck Models.
		Li Yi, Gezheng Xu, Pengcheng Xu, Jiaqi Li, Ruizhi Pu, Charles Ling, A. Ian McLeod, Boyu Wang:
When Source-Free Domain Adaptation Meets Learning with Noisy Labels.
		Alireza Mousavi Hosseini, Sejun Park, Manuela Girotti, Ioannis Mitliagkas, Murat A. Erdogdu:
Neural Networks Efficiently Learn Low-Dimensional Representations with SGD.
		Ahmed Touati, Jérémy Rapin, Yann Ollivier:
Does Zero-Shot Reinforcement Learning Exist?
		Edoardo Cetin, Benjamin Paul Chamberlain, Michael M. Bronstein, Jonathan J. Hunt:
Hyperbolic Deep Reinforcement Learning.
		Tailin Wu, Takashi Maruyama, Qingqing Zhao, Gordon Wetzstein, Jure Leskovec:
Learning Controllable Adaptive Simulation for Multi-resolution Physics.
		John Nguyen, Jianyu Wang, Kshitiz Malik, Maziar Sanjabi, Michael G. Rabbat:
Where to Begin? On the Impact of Pre-Training and Initialization in Federated Learning.
		Josua Sassen, Klaus Hildebrandt, Martin Rumpf, Benedikt Wirth:
Parametrizing Product Shape Manifolds by Composite Networks.
		Rui Wen, Zhengyu Zhao, Zhuoran Liu, Michael Backes, Tianhao Wang, Yang Zhang:
Is Adversarial Training Really a Silver Bullet for Mitigating Data Poisoning?
		Carles Domingo-Enrich, Yair Schiff, Youssef Mroueh:
Learning with Stochastic Orders.
		Yongshuo Zong, Yongxin Yang, Timothy M. Hospedales:
MEDFAIR: Benchmarking Fairness for Medical Imaging.
		Aldo Pacchiano, Drausin Wulsin, Robert A. Barton, Luis F. Voloch:
Neural Design for Genetic Perturbation Experiments.
		Ronak Mehta, Jeffery Kline, Vishnu Suresh Lokhande, Glenn Fung, Vikas Singh:
Efficient Discrete Multi Marginal Optimal Transport Regularization.
		Mansheej Paul, Feng Chen, Brett W. Larsen, Jonathan Frankle, Surya Ganguli, Gintare Karolina Dziugaite:
Unmasking the Lottery Ticket Hypothesis: What's Encoded in a Winning Ticket's Mask?
		Nicholas Carlini, Daphne Ippolito, Matthew Jagielski, Katherine Lee, Florian Tramèr, Chiyuan Zhang:
Quantifying Memorization Across Neural Language Models.
		Kevin Frans, Phillip Isola:
Powderworld: A Platform for Understanding Generalization via Rich Task Distributions.
		Jie Ren, Jiaming Luo, Yao Zhao, Kundan Krishna, Mohammad Saleh, Balaji Lakshminarayanan, Peter J. Liu:
Out-of-Distribution Detection and Selective Generation for Conditional Language Models.
		Jeremiah Blocki, Seunghoon Lee, Tamalika Mukherjee, Samson Zhou:
Differentially Private $L_2$-Heavy Hitters in the Sliding Window Model.
		Ruiqi Ni, Ahmed H. Qureshi:
NTFields: Neural Time Fields for Physics-Informed Robot Motion Planning.
		Guihong Li, Yuedong Yang, Kartikeya Bhardwaj, Radu Marculescu:
ZiCo: Zero-shot NAS via inverse Coefficient of Variation on Gradients.
		Onno Eberhard, Jakob J. Hollenstein, Cristina Pinneri, Georg Martius:
Pink Noise Is All You Need: Colored Noise Exploration in Deep Reinforcement Learning.
		Jayoung Kim, Chaejeong Lee, Noseong Park:
STaSy: Score-based Tabular data Synthesis.
		Alexandre Araujo, Aaron J. Havens, Blaise Delattre, Alexandre Allauzen, Bin Hu:
A Unified Algebraic Perspective on Lipschitz Neural Networks.
		Blake Bordelon, Cengiz Pehlevan:
The Influence of Learning Rule on Representation Dynamics in Wide Neural Networks.
		Arnab Kumar Mondal, Piyush Tiwary, Parag Singla, Prathosh AP:
Few-shot Cross-domain Image Generation via Inference-time Latent-code Learning.
		Yiqin Tan, Pihe Hu, Ling Pan, Jiatai Huang, Longbo Huang:
RLx2: Training a Sparse Deep Reinforcement Learning Model from Scratch.
		Shiwei Liu, Tianlong Chen, Zhenyu Zhang, Xuxi Chen, Tianjin Huang, Ajay Kumar Jaiswal, Zhangyang Wang:
Sparsity May Cry: Let Us Fail (Current) Sparse Neural Networks Together!
		Tianlong Chen, Zhenyu Zhang, Ajay Kumar Jaiswal, Shiwei Liu, Zhangyang Wang:
Sparse MoE as the New Dropout: Scaling Dense and Self-Slimmable Transformers.
		Zhiyuan Cheng, James Liang, Guanhong Tao, Dongfang Liu, Xiangyu Zhang:
Adversarial Training of Self-supervised Monocular Depth Estimation against Physical-World Attacks.
		Tianlin Liu, Joan Puigcerver, Mathieu Blondel:
Sparsity-Constrained Optimal Transport.
		Shuyang Yu, Junyuan Hong, Haotao Wang, Zhangyang Wang, Jiayu Zhou:
Turning the Curse of Heterogeneity in Federated Learning into a Blessing for Out-of-Distribution Detection.
		Qitian Wu, Chenxiao Yang, Wentao Zhao, Yixuan He, David Wipf, Junchi Yan:
DIFFormer: Scalable (Graph) Transformers Induced by Energy Constrained Diffusion.
		Takeshi Koshizuka, Issei Sato:
Neural Lagrangian Schrödinger Bridge: Diffusion Modeling for Population Dynamics.
		Ping-yeh Chiang, Renkun Ni, David Yu Miller, Arpit Bansal, Jonas Geiping, Micah Goldblum, Tom Goldstein:
Loss Landscapes are All You Need: Neural Network Generalization Can Be Explained Without the Implicit Bias of Gradient Descent.
		Jiahui Gao, Renjie Pi, Yong Lin, Hang Xu, Jiacheng Ye, Zhiyong Wu, Weizhong Zhang, Xiaodan Liang, Zhenguo Li, Lingpeng Kong:
Self-Guided Noise-Free Data Generation for Efficient Zero-Shot Learning.
		Tianbo Li, Min Lin, Zheyuan Hu, Kunhao Zheng, Giovanni Vignale, Kenji Kawaguchi, A. H. Castro Neto, Kostya S. Novoselov, Shuicheng Yan:
D4FT: A Deep Learning Approach to Kohn-Sham Density Functional Theory.
		Do-Yeon Kim, Dong-Jun Han, Jun Seo, Jaekyun Moon:
Warping the Space: Weight Space Rotation for Class-Incremental Few-Shot Learning.
		Sheheryar Zaidi, Michael Schaarschmidt, James Martens, Hyunjik Kim, Yee Whye Teh, Alvaro Sanchez-Gonzalez, Peter W. Battaglia, Razvan Pascanu, Jonathan Godwin:
Pre-training via Denoising for Molecular Property Prediction.
		Hyungi Lee, Eunggu Yun, Giung Nam, Edwin Fong, Juho Lee:
Martingale Posterior Neural Processes.
		Tiago Pimentel, Clara Meister, Ryan Cotterell:
On the Usefulness of Embeddings, Clusters and Strings for Text Generation Evaluation.
		Pierre Schumacher, Daniel F. B. Haeufle, Dieter Büchler, Syn Schmitt, Georg Martius:
DEP-RL: Embodied Exploration for Reinforcement Learning in Overactuated and Musculoskeletal Systems.
		Ian Gemp, Charlie Chen, Brian McWilliams:
The Symmetric Generalized Eigenvalue Problem as a Nash Equilibrium.
		Shuguang Dou, Xinyang Jiang, Cairong Zhao, Dongsheng Li:
EA-HAS-Bench: Energy-aware Hyperparameter and Architecture Search Benchmark.
		Krunoslav Lehman Pavasovic, Jonas Rothfuss, Andreas Krause:
MARS: Meta-learning as Score Matching in the Function Space.
		Hualin Zhang, Bin Gu:
Faster Gradient-Free Methods for Escaping Saddle Points.
		Ce Liu, Suryansh Kumar, Shuhang Gu, Radu Timofte, Luc Van Gool:
VA-DepthNet: A Variational Approach to Single Image Depth Prediction.
		Amir Hertz, Ron Mokady, Jay Tenenbaum, Kfir Aberman, Yael Pritch, Daniel Cohen-Or:
Prompt-to-Prompt Image Editing with Cross-Attention Control.
		Guillaume Couairon, Jakob Verbeek, Holger Schwenk, Matthieu Cord:
DiffEdit: Diffusion-based semantic image editing with mask guidance.
		Jiyeon Han, Hwanil Choi, Yunjey Choi, Junho Kim, Jung-Woo Ha, Jaesik Choi:
Rarity Score : A New Metric to Evaluate the Uncommonness of Synthesized Images.
		Yuxin Fang, Li Dong, Hangbo Bao, Xinggang Wang, Furu Wei:
Corrupted Image Modeling for Self-Supervised Visual Pre-Training.
		Longlin Yu, Cheng Zhang:
Semi-Implicit Variational Inference via Score Matching.
		Taeoh Kim, Jinhyung Kim, Minho Shim, Sangdoo Yun, Myunggu Kang, Dongyoon Wee, Sangyoun Lee:
Exploring Temporally Dynamic Data Augmentation for Video Recognition.
		Zixiang Chen, Chris Junchi Li, Huizhuo Yuan, Quanquan Gu, Michael I. Jordan:
A General Framework for Sample-Efficient Function Approximation in Reinforcement Learning.
		Yuzhe Ma, Zhijin Zhou:
Adversarial Attacks on Adversarial Bandits.
		Tianyu Zhao, Xiang Pan, Minghua Chen, Steven H. Low:
Ensuring DNN Solution Feasibility for Optimization Problems with Linear Constraints.
		Xuheng Cai, Chao Huang, Lianghao Xia, Xubin Ren:
LightGCL: Simple Yet Effective Graph Contrastive Learning for Recommendation.
		Jinxi Xiang, Kuan Tian, Jun Zhang:
MIMT: Masked Image Modeling Transformer for Video Compression.
		Daniel Y. Fu, Tri Dao, Khaled Kamal Saab, Armin W. Thomas, Atri Rudra, Christopher Ré:
Hungry Hungry Hippos: Towards Language Modeling with State Space Models.
		Yuelin Wang, Kai Yi, Xinliang Liu, Yu Guang Wang, Shi Jin:
ACMP: Allen-Cahn Message Passing with Attractive and Repulsive Forces for Graph Neural Networks.
		Cameron Diao, Ricky Loynd:
Relational Attention: Generalizing Transformers for Graph-Structured Tasks.
		Saachi Jain, Hannah Lawrence, Ankur Moitra, Aleksander Madry:
Distilling Model Failures as Directions in Latent Space.
		Shuting Shen, Junwei Lu:
Combinatorial-Probabilistic Trade-Off: P-Values of Community Properties Test in the Stochastic Block Models.
		Jun-Kun Wang, Andre Wibisono:
Continuized Acceleration for Quasar Convex Functions in Non-Convex Optimization.
		Ashish Gaurav, Kasra Rezaee, Guiliang Liu, Pascal Poupart:
Learning Soft Constraints From Constrained Expert Demonstrations.
		Peihao Wang, Rameswar Panda, Lucas Torroba Hennigen, Philip Greengard, Leonid Karlinsky, Rogério Feris, David Daniel Cox, Zhangyang Wang, Yoon Kim:
Learning to Grow Pretrained Models for Efficient Transformer Training.
		Daniel Fried, Armen Aghajanyan, Jessy Lin, Sida Wang, Eric Wallace, Freda Shi, Ruiqi Zhong, Scott Yih, Luke Zettlemoyer, Mike Lewis:
InCoder: A Generative Model for Code Infilling and Synthesis.
		Jiasen Lu, Christopher Clark, Rowan Zellers, Roozbeh Mottaghi, Aniruddha Kembhavi:
UNIFIED-IO: A Unified Model for Vision, Language, and Multi-modal Tasks.
		Nico Gürtler, Sebastian Blaes, Pavel Kolev, Felix Widmaier, Manuel Wuthrich, Stefan Bauer, Bernhard Schölkopf, Georg Martius:
Benchmarking Offline Reinforcement Learning on Real-Robot Hardware.
		Sumyeong Ahn, Jongwoo Ko, Se-Young Yun:
CUDA: Curriculum of Data Augmentation for Long-tailed Recognition.
		Ian Connick Covert, Chanwoo Kim, Su-In Lee:
Learning to Estimate Shapley Values with Vision Transformers.
		Ido Galil, Mohammed Dabbah, Ran El-Yaniv:
A framework for benchmarking Class-out-of-distribution detection and its application to ImageNet.
		Zichao Wang, Weili Nie, Zhuoran Qiao, Chaowei Xiao, Richard G. Baraniuk, Anima Anandkumar:
Retrieval-based Controllable Molecule Generation.
		Sirui Xu, Yu-Xiong Wang, Liangyan Gui:
Stochastic Multi-Person 3D Motion Forecasting.
		Derek Lim, Joshua David Robinson, Lingxiao Zhao, Tess E. Smidt, Suvrit Sra, Haggai Maron, Stefanie Jegelka:
Sign and Basis Invariant Networks for Spectral Graph Representation Learning.
		Xiajun Jiang, Ryan Missel, Zhiyuan Li, Linwei Wang:
Sequential Latent Variable Models for Few-Shot High-Dimensional Time-Series Forecasting.
		Marc Szafraniec, Baptiste Rozière, Hugh Leather, Patrick Labatut, François Charton, Gabriel Synnaeve:
Code Translation with Compiler Representations.
		Ziming Liu, Eric J. Michaud, Max Tegmark:
Omnigrok: Grokking Beyond Algorithmic Data.
		Laurence Illing Midgley, Vincent Stimper, Gregor N. C. Simm, Bernhard Schölkopf, José Miguel Hernández-Lobato:
Flow Annealed Importance Sampling Bootstrap.
		Zhiyuan Li, Xiajun Jiang, Ryan Missel, Prashnna Kumar Gyawali, Nilesh Kumar, Linwei Wang:
Continual Unsupervised Disentangling of Self-Organizing Representations.
		Zhihao Shi, Xize Liang, Jie Wang:
LMC: Fast Training of GNNs via Subgraph Sampling with Provable Convergence.
		Renhao Wang, Jiayuan Mao, Joy Hsu, Hang Zhao, Jiajun Wu, Yang Gao:
Programmatically Grounded, Compositionally Generalizable Robotic Manipulation.
		Qiang Wang, Haoge Deng, Yonggang Qi, Da Li, Yi-Zhe Song:
SketchKnitter: Vectorized Sketch Generation with Diffusion Models.
		Da-Wei Zhou, Qi-Wei Wang, Han-Jia Ye, De-Chuan Zhan:
A Model or 603 Exemplars: Towards Memory-Efficient Class-Incremental Learning.
		Zhen Qin, Xiaodong Han, Weixuan Sun, Bowen He, Dong Li, Dongxu Li, Yuchao Dai, Lingpeng Kong, Yiran Zhong:
Toeplitz Neural Network for Sequence Modeling.
		Marcel Seelbach Benkner, Maximilian Krahn, Edith Tretschk, Zorah Lähner, Michael Moeller, Vladislav Golyanik:
QuAnt: Quantum Annealing with Learnt Couplings.
		Yiming Gao, Feiyu Liu, Liang Wang, Zhenjie Lian, Weixuan Wang, Siqin Li, Xianliang Wang, Xianhan Zeng, Rundong Wang, Jiawei Wang, Qiang Fu, Wei Yang, Lanxiao Huang, Wei Liu:
Towards Effective and Interpretable Human-Agent Collaboration in MOBA Games: A Communication Perspective.
		Jérôme Bolte, Ryan Boustany, Edouard Pauwels, Béatrice Pesquet-Popescu:
On the complexity of nonsmooth automatic differentiation.
		Hyungjin Chung, Jeongsol Kim, Michael Thompson McCann, Marc Louis Klasky, Jong Chul Ye:
Diffusion Posterior Sampling for General Noisy Inverse Problems.
		Kevin Meng, Arnab Sen Sharma, Alex J. Andonian, Yonatan Belinkov, David Bau:
Mass-Editing Memory in a Transformer.
		Yi Li, Honghao Lin, Simin Liu, Ali Vakilian, David P. Woodruff:
Learning the Positions in CountSketch.
		Daesol Cho, Seungjae Lee, H. Jin Kim:
Outcome-directed Reinforcement Learning by Uncertainty \& Temporal Distance-Aware Curriculum Goal Generation.
		Yingda Yin, Yang Wang, He Wang, Baoquan Chen:
A Laplace-inspired Distribution on SO(3) for Probabilistic Rotation Estimation.
		Xiaosong Zhang, Yunjie Tian, Lingxi Xie, Wei Huang, Qi Dai, Qixiang Ye, Qi Tian:
HiViT: A Simpler and More Efficient Design of Hierarchical Vision Transformer.
		Qing Li, Siyuan Huang, Yining Hong, Yixin Zhu, Ying Nian Wu, Song-Chun Zhu:
A Minimalist Dataset for Systematic Generalization of Perception, Syntax, and Semantics.
		Mononito Goswami, Cristian I. Challu, Laurent Callot, Lenon Minorics, Andrey Kan:
Unsupervised Model Selection for Time Series Anomaly Detection.
		Lucio M. Dery, Paul Michel, Mikhail Khodak, Graham Neubig, Ameet Talwalkar:
AANG : Automating Auxiliary Learning.
		Maor Ashkenazi, Zohar Rimon, Ron Vainshtein, Shir Levi, Elad Richardson, Pinchas Mintz, Eran Treister:
NeRN: Learning Neural Representations for Neural Networks.
		Stanislas Polu, Jesse Michael Han, Kunhao Zheng, Mantas Baksys, Igor Babuschkin, Ilya Sutskever:
Formal Mathematics Statement Curriculum Learning.
		Nimrod Berman, Ilan Naiman, Omri Azencot:
Multifactor Sequential Disentanglement via Structured Koopman Autoencoders.
		Olivier Laurent, Adrien Lafage, Enzo Tartaglione, Geoffrey Daniel, Jean-Marc Martinez, Andrei Bursuc, Gianni Franchi:
Packed Ensembles for efficient uncertainty estimation.
		Shaolei Zhang, Yang Feng:
Hidden Markov Transformer for Simultaneous Machine Translation.
		Shaoan Xie, Lingjing Kong, Mingming Gong, Kun Zhang:
Multi-domain image generation and translation with identifiability guarantees.
		Matthias De Lange, Gido M. van de Ven, Tinne Tuytelaars:
Continual evaluation for lifelong learning: Identifying the stability gap.
		Zihao Xu, Guang-Yuan Hao, Hao He, Hao Wang:
Domain-Indexing Variational Bayes: Interpretable Domain Index for Domain Adaptation.
		Shutong Wu, Sizhe Chen, Cihang Xie, Xiaolin Huang:
One-Pixel Shortcut: On the Learning Preference of Deep Neural Networks.
		Gianluigi Silvestri, Daan Roos, Luca Ambrogioni:
Deterministic training of generative autoencoders using invertible layers.
		Yong Lin, Renjie Pi, Weizhong Zhang, Xiaobo Xia, Jiahui Gao, Xiao Zhou, Tongliang Liu, Bo Han:
A Holistic View of Label Noise Transition Matrix in Deep Learning and Beyond.
		Jae Oh Woo:
Active Learning in Bayesian Neural Networks with Balanced Entropy Learning Principle.
		Ming Shi, Yingbin Liang, Ness B. Shroff:
Near-Optimal Adversarial Reinforcement Learning with Switching Costs.
		Chenhongyi Yang, Jiarui Xu, Shalini De Mello, Elliot J. Crowley, Xiaolong Wang:
GPViT: A High Resolution Non-Hierarchical Vision Transformer with Group Propagation.
		Alexander Korotin, Daniil Selikhanovych, Evgeny Burnaev:
Neural Optimal Transport.
		Mixue Xie, Shuang Li, Rui Zhang, Chi Harold Liu:
Dirichlet-based Uncertainty Calibration for Active Domain Adaptation.
		Jiale Zhang, Yulun Zhang, Jinjin Gu, Yongbing Zhang, Linghe Kong, Xin Yuan:
Accurate Image Restoration with Attention Retractable Transformer.
		Zhuo Li, Derui Zhu, Yujing Hu, Xiaofei Xie, Lei Ma, Yan Zheng, Yan Song, Yingfeng Chen, Jianjun Zhao:
Neural Episodic Control with State Abstraction.
		Tuomas Kynkäänniemi, Tero Karras, Miika Aittala, Timo Aila, Jaakko Lehtinen:
The Role of ImageNet Classes in Fréchet Inception Distance.
		Mingi Kwon, Jaeseok Jeong, Youngjung Uh:
Diffusion Models Already Have A Semantic Latent Space.
		Yinhuai Wang, Jiwen Yu, Jian Zhang:
Zero-Shot Image Restoration Using Denoising Diffusion Null-Space Model.
		Samuel Lanthaler, Roberto Molinaro, Patrik Hadorn, Siddhartha Mishra:
Nonlinear Reconstruction for Operator Learning of PDEs with Discontinuities.
		Deval Shah, Tor M. Aamodt:
Learning Label Encodings for Deep Regression.
		Jiayuan Gu, Devendra Singh Chaplot, Hao Su, Jitendra Malik:
Multi-skill Mobile Manipulation for Object Rearrangement.
		Yi Zhou, Parikshit Ram, Theodoros Salonidis, Nathalie Baracaldo, Horst Samulowitz, Heiko Ludwig:
Single-shot General Hyper-parameter Optimization for Federated Learning.
		Samuel Lavoie, Christos Tsirigotis, Max Schwarzer, Ankit Vani, Michael Noukhovitch, Kenji Kawaguchi, Aaron C. Courville:
Simplicial Embeddings in Self-Supervised Learning and Downstream Classification.
		Zhe Chen, Yuchen Duan, Wenhai Wang, Junjun He, Tong Lu, Jifeng Dai, Yu Qiao:
Vision Transformer Adapter for Dense Predictions.
		Jianfei Yang, Xiangyu Peng, Kai Wang, Zheng Zhu, Jiashi Feng, Lihua Xie, Yang You:
Divide to Adapt: Mitigating Confirmation Bias for Domain Adaptation of Black-Box Predictors.
		Guangyi Chen, Weiran Yao, Xiangchen Song, Xinyue Li, Yongming Rao, Kun Zhang:
PLOT: Prompt Learning with Optimal Transport for Vision-Language Models.
		Alexander Tyurin, Peter Richtárik:
DASHA: Distributed Nonconvex Optimization with Communication Compression and Optimal Oracle Complexity.
		Hoang Anh Just, Feiyang Kang, Tianhao Wang, Yi Zeng, Myeongseob Ko, Ming Jin, Ruoxi Jia:
LAVA: Data Valuation without Pre-Specified Learning Algorithms.
		Hayeon Lee, Sohyun An, Minseon Kim, Sung Ju Hwang:
Meta-prediction Model for Distillation-Aware NAS on Unseen Datasets.
		Yoni Choukroun, Lior Wolf:
Denoising Diffusion Error Correction Codes.
		Yadan Luo, Zhuoxiao Chen, Zijian Wang, Xin Yu, Zi Huang, Mahsa Baktashmotlagh:
Exploring Active 3D Object Detection from a Generalization Perspective.
		Yujie Lu, Weixi Feng, Wanrong Zhu, Wenda Xu, Xin Eric Wang, Miguel P. Eckstein, William Yang Wang:
Neuro-Symbolic Procedural Planning with Commonsense Prompting.
		Ling Pan, Dinghuai Zhang, Aaron C. Courville, Longbo Huang, Yoshua Bengio:
Generative Augmented Flow Networks.
		Zhenmei Shi, Jiefeng Chen, Kunyang Li, Jayaram Raghuram, Xi Wu, Yingyu Liang, Somesh Jha:
The Trade-off between Universality and Label Efficiency of Representations from Contrastive Learning.
		Peter Yichen Chen, Jinxu Xiang, Dong Heon Cho, Yue Chang, G. A. Pershing, Henrique Teles Maia, Maurizio M. Chiaramonte, Kevin T. Carlberg, Eitan Grinspun:
CROM: Continuous Reduced-Order Modeling of PDEs Using Implicit Neural Representations.
		Andy Zeng, Maria Attarian, Brian Ichter, Krzysztof Marcin Choromanski, Adrian Wong, Stefan Welker, Federico Tombari, Aveek Purohit, Michael S. Ryoo, Vikas Sindhwani, Johnny Lee, Vincent Vanhoucke, Pete Florence:
Socratic Models: Composing Zero-Shot Multimodal Reasoning with Language.
		Ben Athiwaratkun, Sanjay Krishna Gouda, Zijian Wang, Xiaopeng Li, Yuchen Tian, Ming Tan, Wasi Uddin Ahmad, Shiqi Wang, Qing Sun, Mingyue Shang, Sujan Kumar Gonugondla, Hantian Ding, Varun Kumar, Nathan Fulton, Arash Farahani, Siddhartha Jain, Robert Giaquinto, Haifeng Qian, Murali Krishna Ramanathan, Ramesh Nallapati:
Multi-lingual Evaluation of Code Generation Models.
		Mohammadsajad Abavisani, David Danks, Sergey M. Plis:
GRACE-C: Generalized Rate Agnostic Causal Estimation via Constraints.
		Yi-Lun Liao, Tess E. Smidt:
Equiformer: Equivariant Graph Attention Transformer for 3D Atomistic Graphs.
		Dacheng Li, Hongyi Wang, Rulin Shao, Han Guo, Eric P. Xing, Hao Zhang:
MPCFORMER: Fast, Performant and Provate Transformer Inference with MPC.
		Maria S. Esipova, Atiyeh Ashari Ghomi, Yaqiao Luo, Jesse C. Cresswell:
Disparate Impact in Differential Privacy from Gradient Misalignment.
		Noah Hollmann, Samuel Müller, Katharina Eggensperger, Frank Hutter:
TabPFN: A Transformer That Solves Small Tabular Classification Problems in a Second.
		Guy Tevet, Sigal Raab, Brian Gordon, Yonatan Shafir, Daniel Cohen-Or, Amit Haim Bermano:
Human Motion Diffusion Model.
		Wenguan Wang, Cheng Han, Tianfei Zhou, Dongfang Liu:
Visual Recognition with Deep Nearest Centroids.
		Yuan Yin, Matthieu Kirchmeyer, Jean-Yves Franceschi, Alain Rakotomamonjy, Patrick Gallinari:
Continuous PDE Dynamics Forecasting with Implicit Neural Representations.
		Mert Bülent Sariyildiz, Yannis Kalantidis, Karteek Alahari, Diane Larlus:
No Reason for No Supervision: Improved Generalization in Supervised Models.
		Fangzhou Hong, Zhaoxi Chen, Yushi Lan, Liang Pan, Ziwei Liu:
EVA3D: Compositional 3D Human Generation from 2D Image Collections.
		Tong Wu, Jiaqi Wang, Xingang Pan, Xudong Xu, Christian Theobalt, Ziwei Liu, Dahua Lin:
Voxurf: Voxel-based Efficient and Accurate Neural Surface Reconstruction.
		Rujikorn Charakorn, Poramate Manoonpong, Nat Dilokthanakul:
Generating Diverse Cooperative Agents by Learning Incompatible Policies.
		Timo Schick, Jane A. Yu, Zhengbao Jiang, Fabio Petroni, Patrick S. H. Lewis, Gautier Izacard, Qingfei You, Christoforos Nalmpantis, Edouard Grave, Sebastian Riedel:
PEER: A Collaborative Language Model.
		Zhengzhe Liu, Peng Dai, Ruihui Li, Xiaojuan Qi, Chi-Wing Fu:
ISS: Image as Stepping Stone for Text-Guided 3D Shape Generation.
		Danilo Neves Ribeiro, Shen Wang, Xiaofei Ma, Henghui Zhu, Rui Dong, Deguang Kong, Juliette Burger, Anjelica Ramos, Zhiheng Huang, William Yang Wang, George Karypis, Bing Xiang, Dan Roth:
STREET: A Multi-Task Structured Reasoning and Explanation Benchmark.
		Yibo Yang, Haobo Yuan, Xiangtai Li, Zhouchen Lin, Philip H. S. Torr, Dacheng Tao:
Neural Collapse Inspired Feature-Classifier Alignment for Few-Shot Class-Incremental Learning.
		Grégoire Delétang, Anian Ruoss, Jordi Grau-Moya, Tim Genewein, Li Kevin Wenliang, Elliot Catt, Chris Cundy, Marcus Hutter, Shane Legg, Joel Veness, Pedro A. Ortega:
Neural Networks and the Chomsky Hierarchy.
		Lingshen He, Yuxuan Chen, Zhengyang Shen, Yibo Yang, Zhouchen Lin:
Neural ePDOs: Spatially Adaptive Equivariant Partial Differential Operator Based Networks.
		Rinon Gal, Yuval Alaluf, Yuval Atzmon, Or Patashnik, Amit Haim Bermano, Gal Chechik, Daniel Cohen-Or:
An Image is Worth One Word: Personalizing Text-to-Image Generation using Textual Inversion.
		Ruifei He, Shuyang Sun, Xin Yu, Chuhui Xue, Wenqing Zhang, Philip H. S. Torr, Song Bai, Xiaojuan Qi:
Is Synthetic Data from Generative Models Ready for Image Recognition?
		Bencheng Liao, Shaoyu Chen, Xinggang Wang, Tianheng Cheng, Qian Zhang, Wenyu Liu, Chang Huang:
MapTR: Structured Modeling and Learning for Online Vectorized HD Map Construction.
		Jikai Jin, Yiping Lu, José H. Blanchet, Lexing Ying:
Minimax Optimal Kernel Operator Learning via Multilevel Training.
		Keyu Tian, Yi Jiang, Qishuai Diao, Chen Lin, Liwei Wang, Zehuan Yuan:
Designing BERT for Convolutional Networks: Sparse and Hierarchical Masked Modeling.
		Julius Adebayo, Melissa Hall, Bowen Yu, Bobbie Chern:
Quantifying and Mitigating the Impact of Label Errors on Model Disparity Metrics.
		Alasdair Tran, Alexander Patrick Mathews, Lexing Xie, Cheng Soon Ong:
Factorized Fourier Neural Operators.
		Tanay Narshana, Chaitanya Murti, Chiranjib Bhattacharyya:
DFPC: Data flow driven pruning of coupled channels without data.
		Chaitanya Murti, Tanay Narshana, Chiranjib Bhattacharyya:
TVSPrune - Pruning Non-discriminative filters via Total Variation separability of intermediate representations without fine tuning.
		Fabian Latorre, Igor Krawczuk, Leello Tadesse Dadi, Thomas Pethick, Volkan Cevher:
Finding Actual Descent Directions for Adversarial Training.
		Shuangshuang Chen, Sihao Ding, Yiannis Karayiannidis, Mårten Björkman:
Learning Continuous Normalizing Flows For Faster Convergence To Target Distribution via Ascent Regularizations.
		Zenan Li, Yuan Yao, Taolue Chen, Jingwei Xu, Chun Cao, Xiaoxing Ma, Jian Lü:
Softened Symbol Grounding for Neuro-symbolic Systems.
		Gregory Schwartzman:
Mini-batch k-means terminates within O(d/ϵ) iterations.
		Yu Yu, Hassan Sajjad, Jia Xu:
Learning Uncertainty for Unknown Domains with Zero-Target-Assumption.
		Wenqiang Li, Weijun Li, Linjun Sun, Min Wu, Lina Yu, Jingyi Liu, Yanjie Li, Songsong Tian:
Transformer-based model for symbolic regression via joint supervised learning.
		Asaf Yehudai, Matan Vetzler, Yosi Mass, Koren Lazar, Doron Cohen, Boaz Carmeli:
QAID: Question Answering Inspired Few-shot Intent Detection.
		Thomas Pethick, Olivier Fercoq, Puya Latafat, Panagiotis Patrinos, Volkan Cevher:
Solving stochastic weak Minty variational inequalities without increasing batch size.
		Yuxing Wang, Shuang Wu, Haobo Fu, Qiang Fu, Tiantian Zhang, Yongzhe Chang, Xueqian Wang:
Curriculum-based Co-design of Morphology and Control of Voxel-based Soft Robots.
		Tribhuvanesh Orekondy, Kumar Pratik, Shreya Kadambi, Hao Ye, Joseph Soriaga, Arash Behboodi:
WiNeRT: Towards Neural Ray Tracing for Wireless Channel Modelling and Differentiable Simulations.
		Firas Al-Hafez, Davide Tateo, Oleg Arenz, Guoping Zhao, Jan Peters:
LS-IQ: Implicit Reward Regularization for Inverse Reinforcement Learning.
		Zebang Shen, Jiayuan Ye, Anmin Kang, Hamed Hassani, Reza Shokri:
Share Your Representation Only: Guaranteed Improvement of the Privacy-Utility Tradeoff in Federated Learning.
		Alexandre Devillers, Mathieu Lefort:
EquiMod: An Equivariance Module to Improve Visual Instance Discrimination.
		Prashant Shivaram Bhat, Bahram Zonooz, Elahe Arani:
Task-Aware Information Routing from Common Representation Space in Lifelong Learning.
		Nadezhda Chirkova, Sergey Troshin:
CodeBPE: Investigating Subtokenization Options for Large Language Model Pretraining on Source Code.
		André Ferreira Cruz, Catarina Belém, João Bravo, Pedro Saleiro, Pedro Bizarro:
FairGBM: Gradient Boosting with Fairness Constraints.
		Aristotelis Chrysakis, Marie-Francine Moens:
Online Bias Correction for Task-Free Continual Learning.
		Hugo Schmutz, Olivier Humbert, Pierre-Alexandre Mattei:
Don't fear the unlabelled: safe semi-supervised learning via debiasing.
		Qizhang Li, Yiwen Guo, Wangmeng Zuo, Hao Chen:
Making Substitute Models More Bayesian Can Enhance Transferability of Adversarial Examples.
		Yanwen Fang, Yuxi Cai, Jintai Chen, Jingyu Zhao, Guangjian Tian, Guodong Li:
Cross-Layer Retrospective Retrieving via Layer Attention.
		Shmuel Bar-David, Itamar Zimerman, Eliya Nachmani, Lior Wolf:
Decision S4: Efficient Sequence-Based RL via State Spaces Layers.
		Raffaele Paolino, Aleksandar Bojchevski, Stephan Günnemann, Gitta Kutyniok, Ron Levie:
Unveiling the sampling density in non-uniform geometric graphs.
		An Zhang, Fangfu Liu, Wenchang Ma, Zhibo Cai, Xiang Wang, Tat-Seng Chua:
Boosting Causal Discovery via Adaptive Sample Reweighting.
		Matthias Cosler, Frederik Schmitt, Christopher Hahn, Bernd Finkbeiner:
Iterative Circuit Repair Against Formal Specifications.
		Mingxu Tao, Yansong Feng, Dongyan Zhao:
Can BERT Refrain from Forgetting on Sequential Tasks? A Probing Study.
		Zifeng Zhuang, Kun Lei, Jinxin Liu, Donglin Wang, Yilang Guo:
Behavior Proximal Policy Optimization.
		Will Dorrell, Peter E. Latham, Tim E. J. Behrens, James C. R. Whittington:
Actionable Neural Representations: Grid Cells from Minimal Constraints.
		Jun Xia, Chengshuai Zhao, Bozhen Hu, Zhangyang Gao, Cheng Tan, Yue Liu, Siyuan Li, Stan Z. Li:
Mole-BERT: Rethinking Pre-training Graph Neural Networks for Molecules.
		Cheongjae Jang, Yonghyeon Lee, Yung-Kyun Noh, Frank C. Park:
Geometrically regularized autoencoders for non-Euclidean data.
		Yifei Wang, Qi Zhang, Tianqi Du, Jiansheng Yang, Zhouchen Lin, Yisen Wang:
A Message Passing Perspective on Learning Dynamics of Contrastive Learning.
		Yao Shu, Zhongxiang Dai, Weicong Sng, Arun Verma, Patrick Jaillet, Bryan Kian Hsiang Low:
Zeroth-Order Optimization with Trajectory-Informed Derivative Estimation.
		Taiji Suzuki, Atsushi Nitanda, Denny Wu:
Uniform-in-time propagation of chaos for the mean-field gradient Langevin dynamics.
		Yang Jiao, Kai Yang, Tiancheng Wu, Dongjin Song, Chengtao Jian:
Asynchronous Distributed Bilevel Optimization.
		Daeho Um, Jiwoong Park, Seulki Park, Jin Young Choi:
Confidence-Based Feature Imputation for Graphs with Partially Known Features.
		Ziwei Chen, Qiang Li, Xiaofeng Wang, Wankou Yang:
LiftedCL: Lifting Contrastive Learning for Human-Centric Perception.
		Antti Koskela, Marlon Tobaben, Antti Honkela:
Individual Privacy Accounting with Gaussian Differential Privacy.
		Thomas Pierrot, Arthur Flajolet:
Evolving Populations of Diverse RL Agents with MAP-Elites.
		Gresa Shala, André Biedenkapp, Frank Hutter, Josif Grabocka:
Gray-Box Gaussian Processes for Automated Reinforcement Learning.
		Chence Shi, Chuanrui Wang, Jiarui Lu, Bozitao Zhong, Jian Tang:
Protein Sequence and Structure Co-Design with Equivariant Translation.
		Matt Jones, Tyler R. Scott, Mengye Ren, Gamaleldin Fathy Elsayed, Katherine L. Hermann, David Mayo, Michael Curtis Mozer:
Learning in temporally structured environments.
		Laurent Condat, Peter Richtárik:
RandProx: Primal-Dual Optimization Algorithms with Randomized Proximal Updates.
		Guande He, Jianfei Chen, Jun Zhu:
Preserving Pre-trained Features Helps Calibrate Fine-tuned Language Models.
		Aviv A. Rosenberg, Sanketh Vedula, Yaniv Romano, Alexander M. Bronstein:
Fast Nonlinear Vector Quantile Regression.
		Joshua Robinson, David Wingate:
Leveraging Large Language Models for Multiple Choice Question Answering.
		Badih Ghazi, Pritish Kamath, Ravi Kumar, Ethan Leeman, Pasin Manurangsi, Avinash V. Varadarajan, Chiyuan Zhang:
Regression with Label Differential Privacy.
		Michael Chang, Alyssa L. Dayan, Franziska Meier, Thomas L. Griffiths, Sergey Levine, Amy Zhang:
Hierarchical Abstraction for Combinatorial Generalization in Object Rearrangement.
		Yuning Cui, Yi Tao, Zhenshan Bing, Wenqi Ren, Xinwei Gao, Xiaochun Cao, Kai Huang, Alois Knoll:
Selective Frequency Network for Image Restoration.
		Parth Sheth, Pengtao Xie:
Improving Differentiable Neural Architecture Search by Encouraging Transferability.
		Neo Wei Ming, Zhehui Wang, Cheng Liu, Rick Siow Mong Goh, Tao Luo:
MA-BERT: Towards Matrix Arithmetic-only BERT Inference by Eliminating Complex Non-Linear Functions.
		Mustafa Zeqiri, Mark Niklas Müller, Marc Fischer, Martin T. Vechev:
Efficient Certified Training and Robustness Verification of Neural ODEs.
		Yu Liu, Mingbo Zhao, Zhao Zhang, Jicong Fan, Yang Lou, Shuicheng Yan:
Arbitrary Virtual Try-on Network: Characteristics Representation and Trade-off between Body and Clothing.
		Yi Tay, Mostafa Dehghani, Vinh Q. Tran, Xavier Garcia, Jason Wei, Xuezhi Wang, Hyung Won Chung, Dara Bahri, Tal Schuster, Huaixiu Steven Zheng, Denny Zhou, Neil Houlsby, Donald Metzler:
UL2: Unifying Language Learning Paradigms.
		Hongwei Han, Mengyu Zhou, Shi Han, Xiu Li, Dongmei Zhang:
CASR: Generating Complex Sequences with Autoregressive Self-Boost Refinement.
		Amrith Setlur, Don Kurian Dennis, Benjamin Eysenbach, Aditi Raghunathan, Chelsea Finn, Virginia Smith, Sergey Levine:
Bitrate-Constrained DRO: Beyond Worst Case Robustness To Unknown Group Shifts.
		Matus Telgarsky:
Feature selection and low test error in shallow low-rotation ReLU networks.
		Subham Sekhar Sahoo, Anselm Paulus, Marin Vlastelica, Vít Musil, Volodymyr Kuleshov, Georg Martius:
Backpropagation through Combinatorial Algorithms: Identity with Projection Works.
		Xiongye Xiao, Defu Cao, Ruochen Yang, Gaurav Gupta, Gengshuo Liu, Chenzhong Yin, Radu Balan, Paul Bogdan:
Coupled Multiwavelet Operator Learning for Coupled Differential Equations.
		Michael Maynord, Eadom Dessalene, Cornelia Fermüller, Yiannis Aloimonos:
Mid-Vision Feedback.
		Yannick Hogewind, Thiago D. Simão, Tal Kachman, Nils Jansen:
Safe Reinforcement Learning From Pixels Using a Stochastic Latent Representation.
		Qian Lou, Yepeng Liu, Bo Feng:
TrojText: Test-time Invisible Textual Trojan Insertion.
		Akarsh Pokkunuru, Pedram Rooshenas, Thilo Strauss, Anuj Abhishek, Taufiquar Khan:
Improved Training of Physics-Informed Neural Networks Using Energy-Based Priors: a Study on Electrical Impedance Tomography.
		Yunchong Song, Chenghu Zhou, Xinbing Wang, Zhouhan Lin:
Ordered GNN: Ordering Message Passing to Deal with Heterophily and Over-smoothing.
		Trenton Bricken, Xander Davies, Deepak Singh, Dmitry Krotov, Gabriel Kreiman:
Sparse Distributed Memory is a Continual Learner.
		Kaiyuan Zhang, Guanhong Tao, Qiuling Xu, Siyuan Cheng, Shengwei An, Yingqi Liu, Shiwei Feng, Guangyu Shen, Pin-Yu Chen, Shiqing Ma, Xiangyu Zhang:
FLIP: A Provable Defense Framework for Backdoor Mitigation in Federated Learning.
		Hyung Won Chung, Xavier Garcia, Adam Roberts, Yi Tay, Orhan Firat, Sharan Narang, Noah Constant:
UniMax: Fairer and More Effective Language Sampling for Large-Scale Multilingual Pretraining.
		Xiaoqi Wang, Han-Wei Shen:
GNNInterpreter: A Probabilistic Generative Model-Level Explanation for Graph Neural Networks.
		Kei Sen Fong, Shelvia Wongso, Mehul Motani:
Rethinking Symbolic Regression: Morphology and Adaptability in the Context of Evolutionary Algorithms.
		Danqing Wang, Fei Ye, Hao Zhou:
On Pre-training Language Model for Antibody.
		Shanka Subhra Mondal, Taylor Whittington Webb, Jonathan Cohen:
Learning to reason over visual objects.
		Junsu Kim, Younggyo Seo, Sungsoo Ahn, Kyunghwan Son, Jinwoo Shin:
Imitating Graph-Based Planning with Goal-Conditioned Policies.
		Jeff Z. HaoChen, Tengyu Ma:
A theoretical study of inductive biases in contrastive learning.
		Nuoya Xiong, Wei Chen:
Combinatorial Pure Exploration of Causal Bandits.
		Andy Liu, Hao Zhu, Emmy Liu, Yonatan Bisk, Graham Neubig:
Computational Language Acquisition with Theory of Mind.
		Yongqiang Chen, Kaiwen Zhou, Yatao Bian, Binghui Xie, Bingzhe Wu, Yonggang Zhang, Kaili Ma, Han Yang, Peilin Zhao, Bo Han, James Cheng:
Pareto Invariant Risk Minimization: Towards Mitigating the Optimization Dilemma in Out-of-Distribution Generalization.
		Yuhong Li, Tianle Cai, Yi Zhang, Deming Chen, Debadeepta Dey:
What Makes Convolutional Models Great on Long Sequence Modeling?
		Gabriel Ilharco, Marco Túlio Ribeiro, Mitchell Wortsman, Ludwig Schmidt, Hannaneh Hajishirzi, Ali Farhadi:
Editing models with task arithmetic.
		Gautam Singh, Yeongbin Kim, Sungjin Ahn:
Neural Systematic Binder.
		Weixi Feng, Xuehai He, Tsu-Jui Fu, Varun Jampani, Arjun R. Akula, Pradyumna Narayana, Sugato Basu, Xin Eric Wang, William Yang Wang:
Training-Free Structured Diffusion Guidance for Compositional Text-to-Image Synthesis.
		Li-Cheng Lan, Huan Zhang, Cho-Jui Hsieh:
Can Agents Run Relay Race with Strangers? Generalization of RL to Out-of-Distribution Trajectories.
		Zehao Dong, Weidong Cao, Muhan Zhang, Dacheng Tao, Yixin Chen, Xuan Zhang:
CktGNN: Circuit Graph Neural Network for Electronic Design Automation.
		Deyu Bo, Chuan Shi, Lele Wang, Renjie Liao:
Specformer: Spectral Graph Neural Networks Meet Transformers.
		Abulhair Saparov, He He:
Language Models Are Greedy Reasoners: A Systematic Formal Analysis of Chain-of-Thought.
		Amine Mohamed Aboussalah, Min-Jae Kwon, Raj G. Patel, Cheng Chi, Chi-Guhn Lee:
Recursive Time Series Data Augmentation.
		Aaron Palmer, Zhiyi Chi, Derek Aguiar, Jinbo Bi:
Auto-Encoding Goodness of Fit.
		Asher Trockman, Devin Willmott, J. Zico Kolter:
Understanding the Covariance Structure of Convolutional Filters.
		Tao Huang, Yuan Zhang, Shan You, Fei Wang, Chen Qian, Jian Cao, Chang Xu:
Masked Distillation with Receptive Tokens.
		Linbo Liu, Youngsuk Park, Trong Nghia Hoang, Hilaf Hasson, Luke Huan:
Robust Multivariate Time-Series Forecasting: Adversarial Attacks and Defense Mechanisms.
		Lingfeng Shen, Ze Zhang, Haiyun Jiang, Ying Chen:
TextShield: Beyond Successfully Detecting Adversarial Sentences in text classification.
		Qiyang Li, Aviral Kumar, Ilya Kostrikov, Sergey Levine:
Efficient Deep Reinforcement Learning Requires Regulating Overfitting.
		Ming Yin, Mengdi Wang, Yu-Xiang Wang:
Offline Reinforcement Learning with Differentiable Function Approximation is Provably Efficient.
		Jesse Farebrother, Joshua Greaves, Rishabh Agarwal, Charline Le Lan, Ross Goroshin, Pablo Samuel Castro, Marc G. Bellemare:
Proto-Value Networks: Scaling Representation Learning with Auxiliary Tasks.
		Yeshwanth Cherapanamjeri, Sandeep Silwal, David P. Woodruff, Fred Zhang, Qiuyi Zhang, Samson Zhou:
Robust Algorithms on Adaptive Inputs from Bounded Adversaries.
		Chunhui Zhang, Yijun Tian, Mingxuan Ju, Zheyuan Liu, Yanfang Ye, Nitesh V. Chawla, Chuxu Zhang:
Chasing All-Round Graph Representation Robustness: Model, Training, and Optimization.
		Ziang Chen, Jialin Liu, Xinshang Wang, Wotao Yin:
On Representing Mixed-Integer Linear Programs by Graph Neural Networks.
		Hong-You Chen, Cheng-Hao Tu, Ziwei Li, Han-Wei Shen, Wei-Lun Chao:
On the Importance and Applicability of Pre-Training for Federated Learning.
		Filipe de Avila Belbute-Peres, J. Zico Kolter:
Simple initialization and parametrization of sinusoidal networks via their kernel bandwidth.
		Huancheng Chen, Chianing Wang, Haris Vikalo:
The Best of Both Worlds: Accurate Global and Personalized Models through Federated Learning with Data-Free Hyper-Knowledge Distillation.
		Zixuan Liu, Ziqiao Wang, Hongyu Guo, Yongyi Mao:
Over-Training with Mixup May Hurt Generalization.
		Shijie Geng, Jianbo Yuan, Yu Tian, Yuxiao Chen, Yongfeng Zhang:
HiCLIP: Contrastive Language-Image Pretraining with Hierarchy-aware Attention.
		Jake Snell, Thomas P. Zollo, Zhun Deng, Toniann Pitassi, Richard S. Zemel:
Quantile Risk Control: A Flexible Framework for Bounding the Probability of High-Loss Predictions.
		Griffin Floto, Stefan Kremer, Mihai Nica:
The Tilted Variational Autoencoder: Improving Out-of-Distribution Detection.
		Dianbo Liu, Vedant Shah, Oussama Boussif, Cristian Meo, Anirudh Goyal, Tianmin Shu, Michael Curtis Mozer, Nicolas Heess, Yoshua Bengio:
Stateful Active Facilitator: Coordination and Environmental Heterogeneity in Cooperative Multi-Agent Reinforcement Learning.
		Zihan Zhou, Animesh Garg:
Learning Achievement Structure for Structured Exploration in Domains with Sparse Reward.
		Peifeng Wang, Aaron Chan, Filip Ilievski, Muhao Chen, Xiang Ren:
PINTO: Faithful Language Reasoning Using Prompt-Generated Rationales.
		Shunta Akiyama, Taiji Suzuki:
Excess Risk of Two-Layer ReLU Neural Networks in Teacher-Student Settings and its Superiority to Kernel Methods.
		Jack Merullo, Louis Castricato, Carsten Eickhoff, Ellie Pavlick:
Linearly Mapping from Image to Text Space.
		Shikhar Murty, Pratyusha Sharma, Jacob Andreas, Christopher D. Manning:
Characterizing intrinsic compositionality in transformers with Tree Projections.
		Lu Han, Han-Jia Ye, De-Chuan Zhan:
Augmentation Component Analysis: Modeling Similarity via the Augmentation Overlaps.
		Hossein Esfandiari, Alkis Kalavasis, Amin Karbasi, Andreas Krause, Vahab Mirrokni, Grigoris Velegkas:
Replicable Bandits.
		Fred Lu, Edward Raff, Francis Ferraro:
Neural Bregman Divergences for Distance Learning.
		Hongyan Chang, Reza Shokri:
Bias Propagation in Federated Learning.
		Jeremy Tien, Jerry Zhi-Yang He, Zackory Erickson, Anca D. Dragan, Daniel S. Brown:
Causal Confusion and Reward Misidentification in Preference-Based Reward Learning.
		Jinhao Jiang, Kun Zhou, Xin Zhao, Ji-Rong Wen:
UniKGQA: Unified Retrieval and Reasoning for Solving Multi-hop Question Answering Over Knowledge Graph.
		Shicong Cen, Yuejie Chi, Simon Shaolei Du, Lin Xiao:
Faster Last-iterate Convergence of Policy Optimization in Zero-Sum Markov Games.
		Erdem Koyuncu:
Memorization Capacity of Neural Networks with Conditional Computation.
		Ruixuan Yan, Yunshi Wen, Debarun Bhattacharjya, Ronny Luss, Tengfei Ma, Achille Fokoue, Anak Agung Julius:
Weighted Clock Logic Point Process.
		Pu Hua, Yubei Chen, Huazhe Xu:
Simple Emergent Action Representations from Multi-Task Policy Training.
		Akihiro Nakano, Masahiro Suzuki, Yutaka Matsuo:
Interaction-Based Disentanglement of Entities for Object-Centric World Models.
		Youngjoong Kwon, Dahun Kim, Duygu Ceylan, Henry Fuchs:
Neural Image-based Avatars: Generalizable Radiance Fields for Human Avatar Modeling.
		Zhongxiang Dai, Yao Shu, Arun Verma, Flint Xiaofeng Fan, Bryan Kian Hsiang Low, Patrick Jaillet:
Federated Neural Bandits.
		Nan Shao, Zefan Cai, Hanwei Xu, Chonghua Liao, Yanan Zheng, Zhilin Yang:
Compositional Task Representations for Large Language Models.
		Keller Jordan, Hanie Sedghi, Olga Saukh, Rahim Entezari, Behnam Neyshabur:
REPAIR: REnormalizing Permuted Activations for Interpolation Repair.
		Zhendong Wang, Huangjie Zheng, Pengcheng He, Weizhu Chen, Mingyuan Zhou:
Diffusion-GAN: Training GANs with Diffusion.
		Bilal Alsallakh, David Yan, Narine Kokhlikyan, Vivek Miglani, Orion Reblitz-Richardson, Pamela Bhattacharya:
Mind the Pool: Convolutional Neural Networks Can Overfit Input Size.
		Alexander Detkov, Mohammad Salameh, Muhammad Fetrat Qharabagh, Jialin Zhang, Robin Luwei, Shangling Jui, Di Niu:
Reparameterization through Spatial Gradient Scaling.
		Haoyu Peter Wang, Pan Li:
Unsupervised Learning for Combinatorial Optimization Needs Meta Learning.
		Liam H. Fowl, Jonas Geiping, Steven Reich, Yuxin Wen, Wojciech Czaja, Micah Goldblum, Tom Goldstein:
Decepticons: Corrupted Transformers Breach Privacy in Federated Learning for Language Models.
		Etai Littwin, Greg Yang:
Adaptive Optimization in the ∞-Width Limit.
		Ethan Caballero, Kshitij Gupta, Irina Rish, David Krueger:
Broken Neural Scaling Laws.
		Sheng Liu, Xu Zhang, Nitesh Sekhar, Yue Wu, Prateek Singhal, Carlos Fernandez-Granda:
Avoiding spurious correlations via logit correction.
		Ruiquan Huang, Jing Yang, Yingbin Liang:
Safe Exploration Incurs Nearly No Additional Sample Complexity for Reward-Free RL.
		Gihyun Kwon, Jong Chul Ye:
Diffusion-based Image Translation using disentangled style and content representation.
		Jiangyuan Li, Thanh Van Nguyen, Chinmay Hegde, Raymond K. W. Wong:
Implicit Regularization for Group Sparsity.
		Yongchao Zhou, Andrei Ioan Muresanu, Ziwen Han, Keiran Paster, Silviu Pitis, Harris Chan, Jimmy Ba:
Large Language Models are Human-Level Prompt Engineers.
		Enmao Diao, Ganghua Wang, Jiawei Zhang, Yuhong Yang, Jie Ding, Vahid Tarokh:
Pruning Deep Neural Networks from a Sparsity Perspective.
		Runsheng Yu, Weiyu Chen, Xinrun Wang, James Kwok:
Enhancing Meta Learning via Multi-Objective Soft Improvement Functions.
		José Lezama, Tim Salimans, Lu Jiang, Huiwen Chang, Jonathan Ho, Irfan Essa:
Discrete Predictor-Corrector Diffusion Models for Image Synthesis.
		Elias Frantar, Saleh Ashkboos, Torsten Hoefler, Dan Alistarh:
OPTQ: Accurate Quantization for Generative Pre-trained Transformers.
		Sungyoon Lee, Cheongjae Jang:
A new characterization of the edge of stability based on a sharpness measure aware of batch gradient distribution.
		Evangelos Chatzipantazis, Stefanos Pertigkiozoglou, Edgar Dobriban, Kostas Daniilidis:
SE(3)-Equivariant Attention Networks for Shape Reconstruction in Function Space.
		Zixuan Ke, Yijia Shao, Haowei Lin, Tatsuya Konishi, Gyuhak Kim, Bing Liu:
Continual Pre-training of Language Models.
		Alex Gu, Songtao Lu, Parikshit Ram, Tsui-Wei Weng:
Min-Max Multi-objective Bilevel Optimization with Applications in Robust Machine Learning.
		Zeyuan Allen-Zhu, Yuanzhi Li:
Forward Super-Resolution: How Can GANs Learn Hierarchical Generative Models for Real-World Distributions.
		Gang Li, Yang Li:
Spotlight: Mobile UI Understanding using Vision-Language Models with a Focus.
		Stephen Tian, Chelsea Finn, Jiajun Wu:
A Control-Centric Benchmark for Video Prediction.
		Marc Anton Finzi, Andres Potapczynski, Matthew Choptuik, Andrew Gordon Wilson:
A Stable and Scalable Method for Solving Initial Value PDEs with Neural Networks.
		Frederik Kunstner, Jacques Chen, Jonathan Wilder Lavington, Mark Schmidt:
Noise Is Not the Main Factor Behind the Gap Between Sgd and Adam on Transformers, But Sign Descent Might Be.
		Michael S. Albergo, Eric Vanden-Eijnden:
Building Normalizing Flows with Stochastic Interpolants.
		James Beetham, Navid Kardan, Ajmal Saeed Mian, Mubarak Shah:
Dual Student Networks for Data-Free Model Stealing.
		Mingu Lee, Saurabh Pitre, Tianyu Jiang, Pierre-David Letourneau, Matthew J. Morse, Kanghwan Jang, Joseph Soriaga, Parham Noorzad, Hsin-Pai Cheng, Christopher Lott:
Composite Slice Transformer: An Efficient Transformer with Composition of Multi-Scale Multi-Range Attentions.
		Ozgur Guldogan, Yuchen Zeng, Jy-yong Sohn, Ramtin Pedarsani, Kangwook Lee:
Equal Improvability: A New Fairness Notion Considering the Long-term Impact.
		Qi Zeng, Yash Kothari, Spencer H. Bryngelson, Florian Schäfer:
Competitive Physics Informed Networks.
		Tushar Khot, Harsh Trivedi, Matthew Finlayson, Yao Fu, Kyle Richardson, Peter Clark, Ashish Sabharwal:
Decomposed Prompting: A Modular Approach for Solving Complex Tasks.
		Sizhe Chen, Geng Yuan, Xinwen Cheng, Yifan Gong, Minghai Qin, Yanzhi Wang, Xiaolin Huang:
Self-Ensemble Protection: Training Checkpoints Are Good Data Protectors.
		Michael Zhang, Khaled Kamal Saab, Michael Poli, Tri Dao, Karan Goel, Christopher Ré:
Effectively Modeling Time Series with Simple Discrete State Spaces.
		Yuqi Nie, Nam H. Nguyen, Phanwadee Sinthong, Jayant Kalagnanam:
A Time Series is Worth 64 Words: Long-term Forecasting with Transformers.
		Yihao Feng, Shentao Yang, Shujian Zhang, Jianguo Zhang, Caiming Xiong, Mingyuan Zhou, Huan Wang:
Fantastic Rewards and How to Tame Them: A Case Study on Reward Learning for Task-oriented Dialogue Systems.
		Hrayr Harutyunyan, Ankit Singh Rawat, Aditya Krishna Menon, Seungyeon Kim, Sanjiv Kumar:
Supervision Complexity and its Role in Knowledge Distillation.
		Jie Ren, Han Xu, Yuxuan Wan, Xingjun Ma, Lichao Sun, Jiliang Tang:
Transferable Unlearnable Examples.
		Tao Yu, Christopher De Sa:
Random Laplacian Features for Learning with Hyperbolic Space.
		Hongming Zhang, Chenjun Xiao, Han Wang, Jun Jin, Bo Xu, Martin Müller:
Replay Memory as An Empirical MDP: Combining Conservative Estimation with Experience Replay.
		Kevin Muyuan Xia, Yushu Pan, Elias Bareinboim:
Neural Causal Models for Counterfactual Identification and Estimation.
		Lingkai Kong, Yuqing Wang, Molei Tao:
Momentum Stiefel Optimizer, with Applications to Suitably-Orthogonal Attention, and Optimal Transport.
		Xianghao Kong, Rob Brekelmans, Greg Ver Steeg:
Information-Theoretic Diffusion.
		Kareem Ahmed, Zhe Zeng, Mathias Niepert, Guy Van den Broeck:
SIMPLE: A Gradient Estimator for k-Subset Sampling.
		Xiangyu Chen, Varsha Kishore, Kilian Q. Weinberger:
Learning Iterative Neural Optimizers for Image Steganography.
		Jonas Geiping, Micah Goldblum, Gowthami Somepalli, Ravid Shwartz-Ziv, Tom Goldstein, Andrew Gordon Wilson:
How Much Data Are Augmentations Worth? An Investigation into Scaling Laws, Invariance, and Implicit Regularization.
		Weijie Liu, Jiahao Xie, Chao Zhang, Makoto Yamada, Nenggan Zheng, Hui Qian:
Robust Graph Dictionary Learning.
		Zheng Dai, David Gifford:
Fundamental limits on the robustness of image classifiers.
		Nikunj Saunshi, Arushi Gupta, Mark Braverman, Sanjeev Arora:
Understanding Influence Functions and Datamodels via Harmonic Analysis.
		Bairu Hou, Jinghan Jia, Yihua Zhang, Guanhua Zhang, Yang Zhang, Sijia Liu, Shiyu Chang:
TextGrad: Advancing Robustness Evaluation in NLP by Gradient-Driven Optimization.
		Linara Adilova, Bernhard C. Geiger, Asja Fischer:
Information Plane Analysis for Dropout Neural Networks.
		Yiqun Wang, Yuning Shen, Shi Chen, Lihao Wang, Fei Ye, Hao Zhou:
Learning Harmonic Molecular Representations on Riemannian Manifold.
		Samuel Neumann, Sungsu Lim, Ajin George Joseph, Yangchen Pan, Adam White, Martha White:
Greedy Actor-Critic: A New Conditional Cross-Entropy Method for Policy Improvement.
		Bracha Laufer-Goldshtein, Adam Fisch, Regina Barzilay, Tommi S. Jaakkola:
Efficiently Controlling Multiple Risks with Pareto Testing.
		Xingzi Xu, Ali Hasan, Khalil Elkhalil, Jie Ding, Vahid Tarokh:
Characteristic Neural Ordinary Differential Equation.
		Qinsheng Zhang, Yongxin Chen:
Fast Sampling of Diffusion Models with Exponential Integrator.
		Hong-Min Chu, Jonas Geiping, Liam H. Fowl, Micah Goldblum, Tom Goldstein:
Panning for Gold in Federated Learning: Targeted Text Extraction under Arbitrarily Large-Scale Aggregation.
		Matthew J. Tilley, Michelle Miller, David Freedman:
Artificial Neuronal Ensembles with Learned Context Dependent Gating.
		Jianshu Chen:
Learning Language Representations with Logical Inductive Bias.
		Yiwen Kou, Zixiang Chen, Yuan Cao, Quanquan Gu:
How Does Semi-supervised Learning with Pseudo-labelers Work? A Case Study.
		Wei Jin, Tong Zhao, Jiayuan Ding, Yozen Liu, Jiliang Tang, Neil Shah:
Empowering Graph Representation Learning with Test-Time Graph Transformation.
		Aounon Kumar, Alexander Levine, Tom Goldstein, Soheil Feizi:
Provable Robustness against Wasserstein Distribution Shifts via Input Randomization.
		Huan-Hsin Tseng, Hsin-Yi Lin, Kuo-Hsuan Hung, Yu Tsao:
Interpretations of Domain Adaptations via Layer Variational Analysis.
		Francisco Vargas, Will Sussman Grathwohl, Arnaud Doucet:
Denoising Diffusion Samplers.
		Max Zimmer, Christoph Spiegel, Sebastian Pokutta:
How I Learned to Stop Worrying and Love Retraining.
		Siqi Miao, Yunan Luo, Mia Liu, Pan Li:
Interpretable Geometric Deep Learning via Learnable Randomness Injection.
		Tennison Liu, Zhaozhi Qian, Jeroen Berrevoets, Mihaela van der Schaar:
GOGGLE: Generative Modelling for Tabular Data by Learning Relational Structure.
		Anastasia Razdaibiedina, Yuning Mao, Rui Hou, Madian Khabsa, Mike Lewis, Amjad Almahairi:
Progressive Prompts: Continual Learning for Language Models.
		Shahana Ibrahim, Tri Nguyen, Xiao Fu:
Deep Learning From Crowdsourced Labels: Coupled Cross-Entropy Minimization, Identifiability, and Regularization.
		Yingzhen Yang, Ping Li:
Projective Proximal Gradient Descent for Nonconvex Nonsmooth Optimization: Fast Convergence Without Kurdyka-Lojasiewicz (KL) Property.
		Kefan Dong, Tengyu Ma:
First Steps Toward Understanding the Extrapolation of Nonlinear Models to Unseen Domains.
		Henry Conklin, Kenny Smith:
Compositionality with Variation Reliably Emerges in Neural Networks.
		Meng Cao, Mehdi Fatemi, Jackie C. K. Cheung, Samira Shabanian:
Systematic Rectification of Language Models via Dead-end Analysis.
		Edo Dotan, Yonatan Belinkov, Oren Avram, Elya Wygoda, Noa Ecker, Michael Alburquerque, Omri Keren, Gil Loewenthal, Tal Pupko:
Multiple sequence alignment as a sequence-to-sequence learning problem.
		Yinlam Chow, Aza Tulepbergenov, Ofir Nachum, Dhawal Gupta, Moonkyung Ryu, Mohammad Ghavamzadeh, Craig Boutilier:
A Mixture-of-Expert Approach to RL-based Dialogue Management.
		Jiatao Gu, Shuangfei Zhai, Yizhe Zhang, Miguel Ángel Bautista, Joshua M. Susskind:
f-DM: A Multi-stage Diffusion Model via Progressive Signal Transformation.
		Beren Millidge, Yuhang Song, Tommaso Salvatori, Thomas Lukasiewicz, Rafal Bogacz:
Backpropagation at the Infinitesimal Inference Limit of Energy-Based Models: Unifying Predictive Coding, Equilibrium Propagation, and Contrastive Hebbian Learning.
		Beren Millidge, Yuhang Song, Tommaso Salvatori, Thomas Lukasiewicz, Rafal Bogacz:
A Theoretical Framework for Inference and Learning in Predictive Coding Networks.
		Alexander Atanasov, Blake Bordelon, Sabarish Sainathan, Cengiz Pehlevan:
The Onset of Variance-Limited Behavior for Networks in the Lazy and Rich Regimes.
		Brandon Trabucco, Gunnar A. Sigurdsson, Robinson Piramuthu, Gaurav S. Sukhatme, Ruslan Salakhutdinov:
A Simple Approach for Visual Room Rearrangement: 3D Mapping and Semantic Search.
		Ronghang Zhu, Xiang Yu, Sheng Li:
Progressive Mix-Up for Few-Shot Supervised Multi-Source Domain Transfer.
		Kewei Cheng, Nesreen K. Ahmed, Yizhou Sun:
Neural Compositional Rule Learning for Knowledge Graph Reasoning.
		Koosha Khalvati, Samantha Johnson, Stefan Mihalas, Michael A. Buice:
Efficient approximation of neural population structure and correlations with probabilistic circuits.
		Anne Harrington, Vasha DuTell, Ayush Tewari, Mark Hamilton, Simon Stent, Ruth Rosenholtz, William T. Freeman:
Exploring perceptual straightness in learned visual representations.
		Jiefeng Chen, Timothy Nguyen, Dilan Görür, Arslan Chaudhry:
Is Forgetting Less a Good Inductive Bias for Forward Transfer?
		Siqi Zeng, Remi Tachet des Combes, Han Zhao:
Learning Structured Representations by Embedding Class Hierarchy.
		Zhuyun Dai, Vincent Y. Zhao, Ji Ma, Yi Luan, Jianmo Ni, Jing Lu, Anton Bakalov, Kelvin Guu, Keith B. Hall, Ming-Wei Chang:
Promptagator: Few-shot Dense Retrieval From 8 Examples.
		Tahereh Toosi, Elias B. Issa:
Brain-like representational straightening of natural movies in robust feedforward neural networks.
		AmirEhsan Khorashadizadeh, Anadi Chaman, Valentin Debarnot, Ivan Dokmanic:
FunkNN: Neural Interpolation for Functional Generation.
		Rattana Pukdee, Dylan Sam, Pradeep Kumar Ravikumar, Nina Balcan:
Label Propagation with Weak Supervision.
		Jiayi Wei, Greg Durrett, Isil Dillig:
TypeT5: Seq2seq Type Inference using Static Analysis.
		Bhargavi Paranjape, Pradeep Dasigi, Vivek Srikumar, Luke Zettlemoyer, Hannaneh Hajishirzi:
AGRO: Adversarial discovery of error-prone Groups for Robust Optimization.
		Yuan Yang, Faramarz Fekri, James Clayton Kerce, Ali Payani:
LogicDP: Creating Labels for Graph Data via Inductive Logic Programming.
		Kaixin Wang, Kuangqi Zhou, Bingyi Kang, Jiashi Feng, Shuicheng Yan:
Revisiting Intrinsic Reward for Exploration in Procedurally Generated Environments.
		Jan Robine, Marc Höftmann, Tobias Uelwer, Stefan Harmeling:
Transformer-based World Models Are Happy With 100k Interactions.
		Aaron Traylor, Roman Feiman, Ellie Pavlick:
Can Neural Networks Learn Implicit Logic from Physical Reasoning?
		Stephen Marcus McAleer, Gabriele Farina, Marc Lanctot, Tuomas Sandholm:
ESCHER: Eschewing Importance Sampling in Games by Computing a History Value Function to Estimate Regret.
		Justin D. Li, Matus Telgarsky:
On Achieving Optimal Adversarial Test Error.
		Jun-Kun Wang, Andre Wibisono:
Towards Understanding GD with Hard and Conjugate Pseudo-labels for Test-Time Adaptation.
		James Henderson, Fabio Fehr:
A VAE for Transformers with Nonparametric Variational Information Bottleneck.
		Devon Jarvis, Richard Klein, Benjamin Rosman, Andrew M. Saxe:
On The Specialization of Neural Modules.
		Chen Liang, Haoming Jiang, Zheng Li, Xianfeng Tang, Bing Yin, Tuo Zhao:
HomoDistil: Homotopic Task-Agnostic Distillation of Pre-trained Transformers.
		Albert Yu, Raymond J. Mooney:
Using Both Demonstrations and Language Instructions to Efficiently Learn Robotic Tasks.
		Dimitri von Rütte, Luca Biggio, Yannic Kilcher, Thomas Hofmann:
FIGARO: Controllable Music Generation using Learned and Expert Features.
		Freda Shi, Mirac Suzgun, Markus Freitag, Xuezhi Wang, Suraj Srivats, Soroush Vosoughi, Hyung Won Chung, Yi Tay, Sebastian Ruder, Denny Zhou, Dipanjan Das, Jason Wei:
Language models are multilingual chain-of-thought reasoners.
		Zhiqing Sun, Xuezhi Wang, Yi Tay, Yiming Yang, Denny Zhou:
Recitation-Augmented Language Models.
		Sandeep Silwal, Sara Ahmadian, Andrew Nystrom, Andrew McCallum, Deepak Ramachandran, Seyed Mehran Kazemi:
KwikBucks: Correlation Clustering with Cheap-Weak and Expensive-Strong Signals.
		Minae Kwon, Sang Michael Xie, Kalesha Bullard, Dorsa Sadigh:
Reward Design with Language Models.
		Bowen Lei, Ruqi Zhang, Dongkuan Xu, Bani K. Mallick:
Calibrating the Rigged Lottery: Making All Tickets Reliable.
		Kaan Ozkara, Antonious M. Girgis, Deepesh Data, Suhas N. Diggavi:
A Statistical Framework for Personalized Federated Learning and Estimation: Theory, Algorithms, and Privacy.
		Shushan Wu, Huimin Cheng, Jiazhang Cai, Ping Ma, Wenxuan Zhong:
Subsampling in Large Graphs Using Ricci Curvature.
		Jihwan Jeong, Xiaoyu Wang, Michael Gimelfarb, Hyunwoo Kim, Baher Abdulhai, Scott Sanner:
Conservative Bayesian Model-Based Value Expansion for Offline Policy Optimization.
		Linfeng Zhao, Huazhe Xu, Lawson L. S. Wong:
Scaling up and Stabilizing Differentiable Planning with Implicit Differentiation.
		Haoran Sun, Lijun Yu, Bo Dai, Dale Schuurmans, Hanjun Dai:
Score-based Continuous-time Discrete Diffusion Models.
		Kaizhe Hu, Ray Chen Zheng, Yang Gao, Huazhe Xu:
Decision Transformer under Random Frame Dropping.
		Aleksandar Taranovic, Andras Gabor Kupcsik, Niklas Freymuth, Gerhard Neumann:
Adversarial Imitation Learning with Preferences.
		Ruijie Zheng, Xiyao Wang, Huazhe Xu, Furong Huang:
Is Model Ensemble Necessary? Model-based RL via a Single Model with Lipschitz Regularized Value Function.
		Kai Xu, Georgi Ganev, Emile Joubert, Rees Davison, Olivier Van Acker, Luke Robinson:
Synthetic Data Generation of Many-to-Many Datasets via Random Graph Generation.
		Edo Cohen-Karlik, Itamar Menuhin-Gruman, Raja Giryes, Nadav Cohen, Amir Globerson:
Learning Low Dimensional State Spaces with Overparameterized Recurrent Neural Nets.
		Kazuki Irie, Jürgen Schmidhuber:
Images as Weight Matrices: Sequential Image Generation Through Synaptic Learning Rules.
		Xinran Gu, Kaifeng Lyu, Longbo Huang, Sanjeev Arora:
Why (and When) does Local SGD Generalize Better than SGD?
		Jeremiah Birrell, Yannis Pantazis, Paul Dupuis, Luc Rey-Bellet, Markos A. Katsoulakis:
Function-space regularized Rényi divergences.
		Nikolaos Gkanatsios, Mayank Singh, Zhaoyuan Fang, Shubham Tulsiani, Katerina Fragkiadaki:
Analogy-Forming Transformers for Few-Shot 3D Parsing.
		Hossein Mirzaei, Mohammadreza Salehi, Sajjad Shahabi, Efstratios Gavves, Cees G. M. Snoek, Mohammad Sabokrou, Mohammad Hossein Rohban:
Fake It Until You Make It : Towards Accurate Near-Distribution Novelty Detection.
		Syed Zawad, Cheng Li, Zhewei Yao, Elton Zheng, Yuxiong He, Feng Yan:
DySR: Adaptive Super-Resolution via Algorithm and System Co-design.
		Linfeng Zhao, Xupeng Zhu, Lingzhi Kong, Robin Walters, Lawson L. S. Wong:
Integrating Symmetry into Differentiable Planning with Steerable Convolutions.
		Matthew Ashman, Chao Ma, Agrin Hilmkil, Joel Jennings, Cheng Zhang:
Causal Reasoning in the Presence of Latent Confounders via Neural ADMG Learning.
		Yuepeng Yang, Cong Ma:
O(T-1 Convergence of Optimistic-Follow-the-Regularized-Leader in Two-Player Zero-Sum Markov Games.
		Sophia Sanborn, Christian Shewmake, Bruno A. Olshausen, Christopher J. Hillar:
Bispectral Neural Networks.
		Konstantinos E. Nikolakakis, Farzin Haddadpour, Amin Karbasi, Dionysios S. Kalogerias:
Beyond Lipschitz: Sharp Generalization and Excess Risk Bounds for Full-Batch GD.
		Mengdi Xu, Yuchen Lu, Yikang Shen, Shun Zhang, Ding Zhao, Chuang Gan:
Hyper-Decision Transformer for Efficient Online Policy Adaptation.
		Tim Seyde, Peter Werner, Wilko Schwarting, Igor Gilitschenski, Martin A. Riedmiller, Daniela Rus, Markus Wulfmeier:
Solving Continuous Control via Q-learning.
		Uriel Singer, Adam Polyak, Thomas Hayes, Xi Yin, Jie An, Songyang Zhang, Qiyuan Hu, Harry Yang, Oron Ashual, Oran Gafni, Devi Parikh, Sonal Gupta, Yaniv Taigman:
Make-A-Video: Text-to-Video Generation without Text-Video Data.
		Jessica Maghakian, Paul Mineiro, Kishan Panaganti, Mark Rucker, Akanksha Saran, Cheng Tan:
Personalized Reward Learning with Interaction-Grounded Learning (IGL).
		Fivos Kalogiannis, Ioannis Panageas, Emmanouil-Vasileios Vlatakis-Gkaragkounis:
Towards convergence to Nash equilibria in two-team zero-sum games.
		Robert Tjarko Lange, Tom Schaul, Yutian Chen, Tom Zahavy, Valentin Dalibard, Chris Lu, Satinder Singh, Sebastian Flennerhag:
Discovering Evolution Strategies via Meta-Black-Box Optimization.
		Chaowei Xiao, Zhongzhu Chen, Kun Jin, Jiongxiao Wang, Weili Nie, Mingyan Liu, Anima Anandkumar, Bo Li, Dawn Song:
DensePure: Understanding Diffusion Models for Adversarial Robustness.
		Jonas Linkerhägner, Niklas Freymuth, Paul Maria Scheikl, Franziska Mathis-Ullrich, Gerhard Neumann:
Grounding Graph Network Simulators using Physical Sensor Observations.
		Raghav Singhal, Mark Goldstein, Rajesh Ranganath:
Where to Diffuse, How to Diffuse, and How to Get Back: Automated Learning for Multivariate Diffusions.
		Chris Lin, Hugh Chen, Chanwoo Kim, Su-In Lee:
Contrastive Corpus Attribution for Explaining Representations.
		Zheng Dong, Xiuyuan Cheng, Yao Xie:
Spatio-temporal point processes with deep non-stationary kernels.
		Michael Kamp, Jonas Fischer, Jilles Vreeken:
Federated Learning from Small Datasets.
		Lin Guan, Karthik Valmeekam, Subbarao Kambhampati:
Relative Behavioral Attributes: Filling the Gap between Symbolic Goal Specification and Reward Learning from Human Preferences.
		Renyu Zhang, Aly A. Khan, Robert L. Grossman, Yuxin Chen:
Scalable Batch-Mode Deep Bayesian Active Learning via Equivalence Class Annealing.
		Richa Rastogi, Yair Schiff, Alon Hacohen, Zhaozhi Li, Ian Lee, Yuntian Deng, Mert R. Sabuncu, Volodymyr Kuleshov:
Semi-Parametric Inducing Point Networks and Neural Processes.
		Valentina Zantedeschi, Luca Franceschi, Jean Kaddour, Matt J. Kusner, Vlad Niculae:
DAG Learning on the Permutahedron.
		Gustav Bredell, Kyriakos Flouris, Krishna Chaitanya, Ertunc Erdil, Ender Konukoglu:
Explicitly Minimizing the Blur Error of Variational Autoencoders.
		Jiaqi Guan, Wesley Wei Qian, Xingang Peng, Yufeng Su, Jian Peng, Jianzhu Ma:
3D Equivariant Diffusion for Target-Aware Molecule Generation and Affinity Prediction.
		Arna Ghosh, Yuhan Helena Liu, Guillaume Lajoie, Konrad P. Körding, Blake Aaron Richards:
How gradient estimator variance and bias impact learning in neural networks.
		Yazhe Li, Jörg Bornschein, Marcus Hutter:
Evaluating Representations with Readout Model Switching.
		Ziqi Wang, Yuexin Wu, Frederick Liu, Daogao Liu, Le Hou, Hongkun Yu, Jing Li, Heng Ji:
Augmentation with Projection: Towards an Effective and Efficient Data Augmentation Paradigm for Distillation.
		Jiaming Song, Arash Vahdat, Morteza Mardani, Jan Kautz:
Pseudoinverse-Guided Diffusion Models for Inverse Problems.
		Hongyi Chen, Yilun Du, Yiye Chen, Joshua B. Tenenbaum, Patricio A. Vela:
Planning with Sequence Models through Iterative Energy Minimization.
		Bradley C. A. Brown, Anthony L. Caterini, Brendan Leigh Ross, Jesse C. Cresswell, Gabriel Loaiza-Ganem:
Verifying the Union of Manifolds Hypothesis for Image Data.
		Fahad Sarfraz, Elahe Arani, Bahram Zonooz:
Error Sensitivity Modulation based Experience Replay: Mitigating Abrupt Representation Drift in Continual Learning.
		Daksh Idnani, Vivek Madan, Naman Goyal, David J. Schwab, Ramakrishna Vedantam:
Don't forget the nullspace! Nullspace occupancy as a mechanism for out of distribution failure.
		Xiaojun Guo, Yifei Wang, Tianqi Du, Yisen Wang:
ContraNorm: A Contrastive Learning Perspective on Oversmoothing and Beyond.
		Yang Cai, Weiqiang Zheng:
Accelerated Single-Call Methods for Constrained Min-Max Optimization.
		Ali Ramezani-Kebrya, Kimon Antonakopoulos, Igor Krawczuk, Justin Deschenaux, Volkan Cevher:
Distributed Extra-gradient with Optimal Complexity and Communication Guarantees.
		Haotian Fu, Jiayu Yao, Omer Gottesman, Finale Doshi-Velez, George Konidaris:
Performance Bounds for Model and Policy Transfer in Hidden-parameter MDPs.
		Wilka Carvalho, Angelos Filos, Richard L. Lewis, Honglak Lee, Satinder Singh:
Composing Task Knowledge With Modular Successor Feature Approximators.
		Sizhe Li, Zhiao Huang, Tao Chen, Tao Du, Hao Su, Joshua B. Tenenbaum, Chuang Gan:
DexDeform: Dexterous Deformable Object Manipulation with Human Demonstrations and Differentiable Physics.
		Jiacheng Li, Ninghui Li, Bruno Ribeiro:
Effective passive membership inference attacks in federated learning against overparameterized models.
		Sheng Zhang, Hao Cheng, Jianfeng Gao, Hoifung Poon:
Optimizing Bi-Encoder for Named Entity Recognition via Contrastive Learning.
		Zhen Lin, Shubhendu Trivedi, Jimeng Sun:
Taking a Step Back with KCal: Multi-Class Kernel-Based Calibration for Deep Neural Networks.
		Matko Bosnjak, Pierre Harvey Richemond, Nenad Tomasev, Florian Strub, Jacob C. Walker, Felix Hill, Lars Holger Buesing, Razvan Pascanu, Charles Blundell, Jovana Mitrovic:
SemPPL: Predicting Pseudo-Labels for Better Contrastive Representations.
		Tian Li, Manzil Zaheer, Ken Liu, Sashank J. Reddi, Hugh Brendan McMahan, Virginia Smith:
Differentially Private Adaptive Optimization with Delayed Preconditioners.
		Ruben Villegas, Mohammad Babaeizadeh, Pieter-Jan Kindermans, Hernan Moraldo, Han Zhang, Mohammad Taghi Saffar, Santiago Castro, Julius Kunze, Dumitru Erhan:
Phenaki: Variable Length Video Generation from Open Domain Textual Descriptions.
		Harsh Mehta, Ankit Gupta, Ashok Cutkosky, Behnam Neyshabur:
Long Range Language Modeling via Gated State Spaces.
		Yufei Cui, Ziquan Liu, Xiangyu Liu, Xue Liu, Cong Wang, Tei-Wei Kuo, Chun Jason Xue, Antoni B. Chan:
Bayes-MIL: A New Probabilistic Perspective on Attention-based Multiple Instance Learning for Whole Slide Images.
		Adrien Ali Taïga, Rishabh Agarwal, Jesse Farebrother, Aaron C. Courville, Marc G. Bellemare:
Investigating Multi-task Pretraining and Generalization in Reinforcement Learning.
		Ben Zandonati, Adrian Alan Pol, Maurizio Pierini, Olya Sirkin, Tal Kopetz:
FIT: A Metric for Model Sensitivity.
		Roman Levin, Valeriia Cherepanova, Avi Schwarzschild, Arpit Bansal, C. Bayan Bruss, Tom Goldstein, Andrew Gordon Wilson, Micah Goldblum:
Transfer Learning with Deep Tabular Models.
		Alexandra Peste, Adrian Vladu, Eldar Kurtic, Christoph H. Lampert, Dan Alistarh:
CrAM: A Compression-Aware Minimizer.
		Xinzhe Zuo, Zixiang Chen, Huaxiu Yao, Yuan Cao, Quanquan Gu:
Understanding Train-Validation Split in Meta-Learning with Neural Networks.
		Lukas Gosch, Daniel Sturm, Simon Geisler, Stephan Günnemann:
Revisiting Robustness in Graph Machine Learning.
		Aditya Chattopadhyay, Kwan Ho Ryan Chan, Benjamin David Haeffele, Donald Geman, René Vidal:
Variational Information Pursuit for Interpretable Predictions.
		Aran Komatsuzaki, Joan Puigcerver, James Lee-Thorp, Carlos Riquelme Ruiz, Basil Mustafa, Joshua Ainslie, Yi Tay, Mostafa Dehghani, Neil Houlsby:
Sparse Upcycling: Training Mixture-of-Experts from Dense Checkpoints.
		Mohit Sharma, Claudio Fantacci, Yuxiang Zhou, Skanda Koppula, Nicolas Heess, Jon Scholz, Yusuf Aytar:
Lossless Adaptation of Pretrained Vision Models For Robotic Manipulation.
		Zihao Wang, Yangqiu Song, Ginny Y. Wong, Simon See:
Logical Message Passing Networks with One-hop Inference on Atomic Formulas.
		Emily Silcock, Luca D'Amico-Wong, Jinglin Yang, Melissa Dell:
Noise-Robust De-Duplication at Scale.
		Jonathan Hayase, Sewoong Oh:
Few-shot Backdoor Attacks via Neural Tangent Kernels.
		Bruno Mlodozeniec, Matthias Reisser, Christos Louizos:
Hyperparameter Optimization through Neural Network Partitioning.
		Bo Zhao, Iordan Ganev, Robin Walters, Rose Yu, Nima Dehmamy:
Symmetries, Flat Minima, and the Conserved Quantities of Gradient Flow.
		Swarnadeep Saha, Shiyue Zhang, Peter Hase, Mohit Bansal:
Summarization Programs: Interpretable Abstractive Summarization with Neural Modular Trees.
		Shun Zhang, Zhenfang Chen, Yikang Shen, Mingyu Ding, Joshua B. Tenenbaum, Chuang Gan:
Planning with Large Language Models for Code Generation.
		Kaitlin Maile, Dennis George Wilson, Patrick Forré:
Equivariance-aware Architectural Optimization of Neural Networks.
		Jun-Kun Wang, Andre Wibisono:
Accelerating Hamiltonian Monte Carlo via Chebyshev Integration Time.
		Xihuai Wang, Zheng Tian, Ziyu Wan, Ying Wen, Jun Wang, Weinan Zhang:
Order Matters: Agent-by-agent Policy Optimization.
		Zijian Liu, Ta Duy Nguyen, Alina Ene, Huy L. Nguyen:
On the Convergence of AdaGrad(Norm) on ℝd: Beyond Convexity, Non-Asymptotic Rate and Acceleration.
		Shuang Li, William J. Swartworth, Martin Takác, Deanna Needell, Robert M. Gower:
SP2 : A Second Order Stochastic Polyak Method.
		Jinhua Zhu, Yue Wang, Lijun Wu, Tao Qin, Wengang Zhou, Tie-Yan Liu, Houqiang Li:
Making Better Decision by Directly Planning in Continuous Control.
		Chang Li, Dongjin Song, Dacheng Tao:
HiT-MDP: Learning the SMDP option framework on MDPs with Hidden Temporal Embeddings.
		Nicholas Carlini, Florian Tramèr, Krishnamurthy (Dj) Dvijotham, Leslie Rice, Mingjie Sun, J. Zico Kolter:
(Certified!!) Adversarial Robustness for Free!
		Biswadeep Chakraborty, Saibal Mukhopadhyay:
Heterogeneous Neuronal and Synaptic Dynamics for Spike-Efficient Unsupervised Learning: Theory and Design Principles.
		Emanuele Palumbo, Imant Daunhawer, Julia E. Vogt:
MMVAE+: Enhancing the Generative Quality of Multimodal VAEs without Compromises.
		Ashish R. Mittal, Sunita Sarawagi, Preethi Jyothi:
In-Situ Text-Only Adaptation of Speech Models with Low-Overhead Speech Imputations.
		Tobit Klug, Reinhard Heckel:
Scaling Laws For Deep Learning Based Image Reconstruction.
		Ivona Najdenkoska, Xiantong Zhen, Marcel Worring:
Meta Learning to Bridge Vision and Language Models for Multimodal Few-Shot Learning.
		Tsun-Hsuan Wang, Pingchuan Ma, Andrew Everett Spielberg, Zhou Xian, Hao Zhang, Joshua B. Tenenbaum, Daniela Rus, Chuang Gan:
SoftZoo: A Soft Robot Co-design Benchmark For Locomotion In Diverse Environments.
		Thy Dinh Nguyen, Anamay Chaturvedi, Huy L. Nguyen:
Improved Learning-augmented Algorithms for k-means and k-medians Clustering.
		Arturs Berzins, Moritz Ibing, Leif Kobbelt:
Neural Implicit Shape Editing using Boundary Sensitivity.
		Ruchika Chavhan, Jan Stuehmer, Calum Heggan, Mehrdad Yaghoobi, Timothy M. Hospedales:
Amortised Invariance Learning for Contrastive Self-Supervision.
		Paul Michel, Mathieu Rita, Kory Wallace Mathewson, Olivier Tieleman, Angeliki Lazaridou:
Revisiting Populations in multi-agent Communication.
		Muralee Nikhil Krishnan, MohammadReza Ebrahimi, Ashish J. Khisti:
Sequential Gradient Coding For Straggler Mitigation.
		Hyesu Lim, Byeonggeun Kim, Jaegul Choo, Sungha Choi:
TTN: A Domain-Shift Aware Batch Normalization in Test-Time Adaptation.
		Karsten Roth, Mark Ibrahim, Zeynep Akata, Pascal Vincent, Diane Bouchacourt:
Disentanglement of Correlated Factors via Hausdorff Factorized Support.
		Sean Welleck, Ximing Lu, Peter West, Faeze Brahman, Tianxiao Shen, Daniel Khashabi, Yejin Choi:
Generating Sequences by Learning to Self-Correct.
		David Lipshutz, Cengiz Pehlevan, Dmitri B. Chklovskii:
Interneurons accelerate learning dynamics in recurrent neural networks for statistical adaptation.
		Valentin Khrulkov, Gleb V. Ryzhakov, Andrei Chertkov, Ivan V. Oseledets:
Understanding DDPM Latent Codes Through Optimal Transport.
		Valerii Iakovlev, Çagatay Yildiz, Markus Heinonen, Harri Lähdesmäki:
Latent Neural ODEs with Sparse Bayesian Multiple Shooting.
		Jinhua Zhu, Kehan Wu, Bohan Wang, Yingce Xia, Shufang Xie, Qi Meng, Lijun Wu, Tao Qin, Wengang Zhou, Houqiang Li, Tie-Yan Liu:
𝒪-GNN: incorporating ring priors into molecular modeling.
		Jiaxun Cui, Xiaomeng Yang, Mulong Luo, Geunbae Lee, Peter Stone, Hsien-Hsin S. Lee, Benjamin Lee, G. Edward Suh, Wenjie Xiong, Yuandong Tian:
MACTA: A Multi-agent Reinforcement Learning Approach for Cache Timing Attacks and Detection.
		Wenhao Zhan, Masatoshi Uehara, Wen Sun, Jason D. Lee:
PAC Reinforcement Learning for Predictive State Representations.
		Wenhao Zhan, Jason D. Lee, Zhuoran Yang:
Decentralized Optimistic Hyperpolicy Mirror Descent: Provably No-Regret Learning in Markov Games.
		David W. Zhang, Corrado Rainone, Markus Peschl, Roberto Bondesan:
Robust Scheduling with GFlowNets.
		Wessel P. Bruinsma, Stratis Markou, James Requeima, Andrew Y. K. Foong, Tom R. Andersson, Anna Vaughan, Anthony Buonomo, J. Scott Hosking, Richard E. Turner:
Autoregressive Conditional Neural Processes.
		Benfeng Xu, Quan Wang, Zhendong Mao, Yajuan Lyu, Qiaoqiao She, Yongdong Zhang:
$k$NN Prompting: Beyond-Context Learning with Calibration-Free Nearest Neighbor Inference.
		Zhun Deng, Jiayao Zhang, Linjun Zhang, Ting Ye, Yates Coley, Weijie J. Su, James Zou:
FIFA: Making Fairness More Generalizable in Classifiers Trained on Imbalanced Data.
		Zeping Luo, Shiyou Wu, Cindy Weng, Mo Zhou, Rong Ge:
Understanding The Robustness of Self-supervised Learning Through Topic Modeling.
		Mhairi Dunion, Trevor McInroe, Kevin Sebastian Luck, Josiah P. Hanna, Stefano V. Albrecht:
Temporal Disentanglement of Representations for Improved Generalisation in Reinforcement Learning.
		Jiyan He, Xuechen Li, Da Yu, Huishuai Zhang, Janardhan Kulkarni, Yin Tat Lee, Arturs Backurs, Nenghai Yu, Jiang Bian:
Exploring the Limits of Differentially Private Deep Learning with Group-wise Clipping.
		Michael Aerni, Marco Milanta, Konstantin Donhauser, Fanny Yang:
Strong inductive biases provably prevent harmless interpolation.
		Maximilian Seitzer, Max Horn, Andrii Zadaianchuk, Dominik Zietlow, Tianjun Xiao, Carl-Johann Simon-Gabriel, Tong He, Zheng Zhang, Bernhard Schölkopf, Thomas Brox, Francesco Locatello:
Bridging the Gap to Real-World Object-Centric Learning.
		Zhijian Zhuo, Yifei Wang, Jinwen Ma, Yisen Wang:
Towards a Unified Theoretical Understanding of Non-contrastive Learning via Rank Differential Mechanism.
		Zijing Shi, Meng Fang, Yunqiu Xu, Ling Chen, Yali Du:
Stay Moral and Explore: Learn to Behave Morally in Text-based Games.
		Sirui Zheng, Lingxiao Wang, Shuang Qiu, Zuyue Fu, Zhuoran Yang, Csaba Szepesvári, Zhaoran Wang:
Optimistic Exploration with Learned Features Provably Solves Markov Decision Processes with Neural Dynamics.
		Nan Rosemary Ke, Silvia Chiappa, Jane X. Wang, Jörg Bornschein, Anirudh Goyal, Mélanie Rey, Theophane Weber, Matthew M. Botvinick, Michael Curtis Mozer, Danilo Jimenez Rezende:
Learning to Induce Causal Structure.
		Zhendong Wang, Jonathan J. Hunt, Mingyuan Zhou:
Diffusion Policies as an Expressive Policy Class for Offline Reinforcement Learning.
		Xuchuang Wang, Lin Yang, Yu-Zhen Janice Chen, Xutong Liu, Mohammad Hajiesmaili, Don Towsley, John C. S. Lui:
Achieving Near-Optimal Individual Regret & Low Communications in Multi-Agent Bandits.
		Hyunseo Koh, Minhyuk Seo, Jihwan Bang, Hwanjun Song, Deokki Hong, Seulki Park, Jung-Woo Ha, Jonghyun Choi:
Online Boundary-Free Continual Learning by Scheduled Data Prior.
		Zefeng Cai, Chongyang Tao, Tao Shen, Can Xu, Xiubo Geng, Xin Alex Lin, Liang He, Daxin Jiang:
HypeR: Multitask Hyper-Prompted Training Enables Large-Scale Retrieval Generalization.
		Yuanhao Wang, Dingwen Kong, Yu Bai, Chi Jin:
Learning Rationalizable Equilibria in Multiplayer Games.
		Zehao Xiao, Xiantong Zhen, Shengcai Liao, Cees G. M. Snoek:
Energy-Based Test Sample Adaptation for Domain Generalization.
		Ajay Patel, Bryan Li, Mohammad Sadegh Rasooli, Noah Constant, Colin Raffel, Chris Callison-Burch:
Bidirectional Language Models Are Also Few-shot Learners.
		Michael Crawshaw, Yajie Bao, Mingrui Liu:
EPISODE: Episodic Gradient Clipping with Periodic Resampled Corrections for Federated Learning with Heterogeneous Data.
		Ali Shirali, Rediet Abebe, Moritz Hardt:
A Theory of Dynamic Benchmarks.
		Martin Pawelczyk, Tobias Leemann, Asia Biega, Gjergji Kasneci:
On the Trade-Off between Actionable Explanations and the Right to be Forgotten.
		Manuel Traub, Sebastian Otte, Tobias Menge, Matthias Karlbauer, Jannik Thümmel, Martin V. Butz:
Learning What and Where: Disentangling Location and Identity Tracking Without Supervision.
		Jun Bi, Xiaqing Li, Qi Guo, Rui Zhang, Yuanbo Wen, Xing Hu, Zidong Du, Xinkai Song, Yifan Hao, Yunji Chen:
BALTO: fast tensor program optimization with diversity-based active learning.
		Abhijeet Phatak, Sharath Raghvendra, Chittaranjan Tripathy, Kaiyi Zhang:
Computing all Optimal Partial Transports.
		Yuzhong Zhao, Qiaoqiao Ding, Xiaoqun Zhang:
AE-FLOW: Autoencoders with Normalizing Flows for Medical Images Anomaly Detection.
		Ingrid von Glehn, James S. Spencer, David Pfau:
A Self-Attention Ansatz for Ab-initio Quantum Chemistry.
		Martin Pawelczyk, Teresa Datta, Johannes van den Heuvel, Gjergji Kasneci, Himabindu Lakkaraju:
Probabilistically Robust Recourse: Navigating the Trade-offs between Costs and Robustness in Algorithmic Recourse.
		Yuge Shi, Imant Daunhawer, Julia E. Vogt, Philip H. S. Torr, Amartya Sanyal:
How robust is unsupervised representation learning to distribution shift?
		Benjamin Hsu, Anna Currey, Xing Niu, Maria Nadejde, Georgiana Dinu:
Pseudo-label Training and Model Inertia in Neural Machine Translation.
		Jae Yong Lee, Sung Woong Cho, Hyung Ju Hwang:
HyperDeepONet: learning operator with complex target function space using the limited resources via hypernetwork.
		Hao Tang, Xiaojuan Qi, Guolei Sun, Dan Xu, Nicu Sebe, Radu Timofte, Luc Van Gool:
Edge Guided GANs with Contrastive Learning for Semantic Image Synthesis.
		Samuel Maddock, Alexandre Sablayrolles, Pierre Stock:
CANIFE: Crafting Canaries for Empirical Privacy Measurement in Federated Learning.
		Jerone Theodore Alexander Andrews, Przemyslaw Joniak, Alice Xiang:
A View From Somewhere: Human-Centric Face Representations.
		Imant Daunhawer, Alice Bizeul, Emanuele Palumbo, Alexander Marx, Julia E. Vogt:
Identifiability Results for Multimodal Contrastive Learning.
		Han Guo, Philip Greengard, Hongyi Wang, Andrew Gelman, Yoon Kim, Eric P. Xing:
Federated Learning as Variational Inference: A Scalable Expectation Propagation Approach.
		Haitz Sáez de Ocáriz Borde, Anees Kazi, Federico Barbero, Pietro Liò:
Latent Graph Inference using Product Manifolds.
		Yuki Ukai, Tsubasa Hirakawa, Takayoshi Yamashita, Hironobu Fujiyoshi:
This Looks Like It Rather Than That: ProtoKNN For Similarity-Based Classifiers.
		Joris Quist, Yunqiang Li, Jan van Gemert:
Understanding weight-magnitude hyperparameters in training binary networks.
		Tim Pearce, Tabish Rashid, Anssi Kanervisto, David Bignell, Mingfei Sun, Raluca Georgescu, Sergio Valcarcel Macua, Shan Zheng Tan, Ida Momennejad, Katja Hofmann, Sam Devlin:
Imitating Human Behaviour with Diffusion Models.
		Adam Jelley, Amos J. Storkey, Antreas Antoniou, Sam Devlin:
Contrastive Meta-Learning for Partially Observable Few-Shot Learning.
		Suresh Bishnoi, Ravinder Bhattoo, Jayadeva, Sayan Ranu, N. M. Anoop Krishnan:
Enhancing the Inductive Biases of Graph Neural ODE for Modeling Physical Systems.
		Zhengyao Jiang, Tianjun Zhang, Michael Janner, Yueying Li, Tim Rocktäschel, Edward Grefenstette, Yuandong Tian:
Efficient Planning in a Compact Latent Action Space.
		Bariscan Bozkurt, Ates Isfendiyaroglu, Cengiz Pehlevan, Alper Tunga Erdogan:
Correlative Information Maximization Based Biologically Plausible Neural Networks for Correlated Source Separation.
		Gui Citovsky, Giulia DeSalvo, Sanjiv Kumar, Srikumar Ramalingam, Afshin Rostamizadeh, Yunjuan Wang:
Leveraging Importance Weights in Subset Selection.
		Tian Lan, Deng Cai, Yan Wang, Heyan Huang, Xian-Ling Mao:
Copy is All You Need.
		Jacob Clarysse, Julia Hörrmann, Fanny Yang:
Why adversarial training can hurt robust accuracy.
		Lyndon R. Duong, Jingyang Zhou, Josue Nassar, Jules Berman, Jeroen Olieslagers, Alex H. Williams:
Representational Dissimilarity Metric Spaces for Stochastic Neural Networks.
		Jörg Bornschein, Yazhe Li, Marcus Hutter:
Sequential Learning of Neural Networks for Prequential MDL.
		Ilya Trofimov, Daniil Cherniavskii, Eduard Tulchinskii, Nikita Balabin, Evgeny Burnaev, Serguei Barannikov:
Learning topology-preserving data representations.
		Sotiris Anagnostidis, Gregor Bachmann, Lorenzo Noci, Thomas Hofmann:
The Curious Case of Benign Memorization.
		Carlo Alberto Barbano, Benoit Dufumier, Enzo Tartaglione, Marco Grangetto, Pietro Gori:
Unbiased Supervised Contrastive Learning.
		Kaifeng Gao, Long Chen, Hanwang Zhang, Jun Xiao, Qianru Sun:
Compositional Prompt Tuning with Motion Cues for Open-vocabulary Video Relation Detection.
		Jim Boelrijk, Bernd Ensing, Patrick Forré:
Multi-objective optimization via equivariant deep hypervolume approximation.
		Machel Reid, Vincent Josua Hellendoorn, Graham Neubig:
DiffusER: Diffusion via Edit-based Reconstruction.
		Jiaxing Wang, Yong Li, Jingwei Zhuo, Xupeng Shi, Weizhong Zhang, Lixing Gong, Tong Tao, Pengzhang Liu, Yongjun Bao, Weipeng Yan:
DynaMS: Dyanmic Margin Selection for Efficient Deep Learning.
		Alan Jeffares, Tennison Liu, Jonathan Crabbé, Fergus Imrie, Mihaela van der Schaar:
TANGOS: Regularizing Tabular Neural Networks through Gradient Orthogonalization and Specialization.
		Zhun Yang, Adam Ishay, Joohyung Lee:
Learning to Solve Constraint Satisfaction Problems with Recurrent Transformer.
		Yang Liu, Anthony C. Constantinou:
Improving the imputation of missing data with Markov Blanket discovery.
		Yinan Huang, Xingang Peng, Jianzhu Ma, Muhan Zhang:
Boosting the Cycle Counting Power of Graph Neural Networks with I$^2$-GNNs.
		Marco Sälzer, Martin Lange:
Fundamental Limits in Formal Verification of Message-Passing Neural Networks.
		Grzegorz Stefanski, Krzysztof Arendt, Pawel Daniluk, Bartlomiej Jasik, Artur Szumaczuk:
Short-Term Memory Convolutions.
		Tao Shen, Xiubo Geng, Chongyang Tao, Can Xu, Xiaolong Huang, Binxing Jiao, Linjun Yang, Daxin Jiang:
LexMAE: Lexicon-Bottlenecked Pretraining for Large-Scale Retrieval.
		Qingyu Han, Linxin Yang, Qian Chen, Xiang Zhou, Dong Zhang, Akang Wang, Ruoyu Sun, Xiaodong Luo:
A GNN-Guided Predict-and-Search Framework for Mixed-Integer Linear Programming.
		Ziping Jiang:
On Explaining Neural Network Robustness with Activation Path.
		Felix Leeb, Giulia Lanzillotta, Yashas Annadani, Michel Besserve, Stefan Bauer, Bernhard Schölkopf:
Structure by Architecture: Structured Representations without Regularization.
		Martin Bjerke, Lukas Schott, Kristopher T. Jensen, Claudia Battistin, David A. Klindt, Benjamin Adric Dunn:
Understanding Neural Coding on Latent Manifolds by Sharing Features and Dividing Ensembles.
		Quang Pham, Chenghao Liu, Doyen Sahoo, Steven C. H. Hoi:
Learning Fast and Slow for Online Time Series Forecasting.
		Seonghyeon Ye, Doyoung Kim, Joel Jang, Joongbo Shin, Minjoon Seo:
Guess the Instruction! Flipped Learning Makes Language Models Stronger Zero-Shot Learners.
		David Henry Mguni, Aivar Sootla, Juliusz Ziomek, Oliver Slumbers, Zipeng Dai, Kun Shao, Jun Wang:
Timing is Everything: Learning to Act Selectively with Costly Actions and Budgetary Constraints.
		Wei Li, Linchao Zhu, Longyin Wen, Yi Yang:
DeCap: Decoding CLIP Latents for Zero-Shot Captioning via Text-Only Training.
		Kilian Zepf, Eike Petersen, Jes Frellsen, Aasa Feragen:
That Label's got Style: Handling Label Style Bias for Uncertain Image Segmentation.
		Qi Zhao, Christian Wressnegger:
Holistic Adversarially Robust Pruning.
		Ondrej Bohdal, Lukas Balles, Martin Wistuba, Beyza Ermis, Cédric Archambeau, Giovanni Zappella:
PASHA: Efficient HPO and NAS with Progressive Resource Allocation.
		Haoxuan Li, Chunyuan Zheng, Peng Wu:
StableDR: Stabilized Doubly Robust Learning for Recommendation on Data Missing Not at Random.
		Javier Antorán, Shreyas Padhy, Riccardo Barbano, Eric T. Nalisnick, David Janz, José Miguel Hernández-Lobato:
Sampling-based inference for large linear models, with application to linearised Laplace.
		Shutong Wu, Jiongxiao Wang, Wei Ping, Weili Nie, Chaowei Xiao:
Defending against Adversarial Audio via Diffusion Model.
		Peizhong Ju, Yingbin Liang, Ness B. Shroff:
Theoretical Characterization of the Generalization Performance of Overfitted Meta-Learning.
		Matthew Wicker, Juyeon Heo, Luca Costabello, Adrian Weller:
Robust Explanation Constraints for Neural Networks.
		Huayu Chen, Cheng Lu, Chengyang Ying, Hang Su, Jun Zhu:
Offline Reinforcement Learning via High-Fidelity Generative Behavior Modeling.
		Wenyi Hong, Ming Ding, Wendi Zheng, Xinghan Liu, Jie Tang:
CogVideo: Large-scale Pretraining for Text-to-Video Generation via Transformers.
		Heng Wang, Tan Yue, Xiang Ye, Zihang He, Bohan Li, Yong Li:
Revisit Finetuning strategy for Few-Shot Learning to Transfer the Emdeddings.
		Chunchun Yang, Malik Tiomoko, Zengfu Wang:
Optimizing Spca-based Continual Learning: A Theoretical Approach.
		Deyao Zhu, Li Erran Li, Mohamed Elhoseiny:
Value Memory Graph: A Graph-Structured World Model for Offline Reinforcement Learning.
		Nicholas Gao, Stephan Günnemann:
Sampling-free Inference for Ab-Initio Potential Energy Surface Networks.
		Qing Wang, Dillon Ze Chen, Asiri Wijesinghe, Shouheng Li, Muhammad Farhan:
𝒩-WL: A New Hierarchy of Expressivity for Graph Neural Networks.
		Yoonjeon Kim, Hyunsu Kim, Junho Kim, Yunjey Choi, Eunho Yang:
Learning Input-agnostic Manipulation Directions in StyleGAN with Text Guidance.
		Benjamin Estermann, Roger Wattenhofer:
DAVA: Disentangling Adversarial Variational Autoencoder.
		Haoxuan Li, Yan Lyu, Chunyuan Zheng, Peng Wu:
TDR-CL: Targeted Doubly Robust Collaborative Learning for Debiased Recommendations.
		Minyoung Kim, Da Li, Timothy M. Hospedales:
Domain Generalisation via Domain Adaptation: An Adversarial Fourier Amplitude Approach.
		Tianxiang Hao, Hui Chen, Yuchen Guo, Guiguang Ding:
Consolidator: Mergable Adapter with Group Connections for Visual Adaptation.
		Ximing Li, Chendi Wang, Guang Cheng:
Statistical Theory of Differentially Private Marginal-based Data Synthesis Algorithms.
		Alessio Gravina, Davide Bacciu, Claudio Gallicchio:
Anti-Symmetric DGN: a stable architecture for Deep Graph Networks.
		Yilmazcan Özyurt, Stefan Feuerriegel, Ce Zhang:
Contrastive Learning for Unsupervised Domain Adaptation of Time Series.
		Soumyabrata Pal, Prateek Jain:
Online Low Rank Matrix Completion.
		Shripad Vilasrao Deshmukh, Arpan Dasgupta, Balaji Krishnamurthy, Nan Jiang, Chirag Agarwal, Georgios Theocharous, Jayakumar Subramanian:
Explaining RL Decisions with Trajectories.
		Florian Jaeckle, Fartash Faghri, Ali Farhadi, Oncel Tuzel, Hadi Pouransari:
FastFill: Efficient Compatible Model Update.
		Adrián Javaloy, Pablo Sánchez-Martín, Amit Levi, Isabel Valera:
Learnable Graph Convolutional Attention Networks.
		Anil Kag, Durmus Alp Emre Acar, Aditya Gangrade, Venkatesh Saligrama:
Scaffolding a Student to Instill Knowledge.
		Phillip Swazinna, Steffen Udluft, Thomas A. Runkler:
User-Interactive Offline Reinforcement Learning.
		Biao Zhang, Mathias Müller, Rico Sennrich:
SLTUNET: A Simple Unified Model for Sign Language Translation.
		Difan Zou, Yuan Cao, Yuanzhi Li, Quanquan Gu:
Understanding the Generalization of Adam in Learning Neural Networks with Proper Regularization.
		Daniel Paleka, Amartya Sanyal:
A law of adversarial risk, interpolation, and label noise.
		Julius Berner, Philipp Grohs, Felix Voigtländer:
Learning ReLU networks to high uniform accuracy is intractable.
		Younghyun Park, Wonjeong Choi, Soyeong Kim, Dong-Jun Han, Jaekyun Moon:
Active Learning for Object Detection with Evidential Deep Learning and Hierarchical Uncertainty Aggregation.
		Kaiyue Wen, Tengyu Ma, Zhiyuan Li:
How Sharpness-Aware Minimization Minimizes Sharpness?
		Mor Shpigel Nacson, Rotem Mulayoff, Greg Ongie, Tomer Michaeli, Daniel Soudry:
The Implicit Bias of Minima Stability in Multivariate Shallow ReLU Networks.
		Chen Huang, Hanlin Goh, Jiatao Gu, Joshua M. Susskind:
MAST: Masked Augmentation Subspace Training for Generalizable Self-Supervised Priors.
		Zhongyuan Zhao, Ananthram Swami, Santiago Segarra:
Graph-based Deterministic Policy Gradient for Repetitive Combinatorial Optimization Problems.
		Christian Haase, Christoph Hertrich, Georg Loho:
Lower Bounds on the Depth of Integral ReLU Neural Networks via Lattice Polytopes.
		Florent Delgrange, Ann Nowé, Guillermo A. Pérez:
Wasserstein Auto-encoded MDPs: Formal Verification of Efficiently Distilled RL Policies with Many-sided Guarantees.
		Steve Azzolin, Antonio Longa, Pietro Barbiero, Pietro Liò, Andrea Passerini:
Global Explainability of GNNs via Logic Combination of Learned Concepts.
		T. Konstantin Rusch, Benjamin Paul Chamberlain, Michael W. Mahoney, Michael M. Bronstein, Siddhartha Mishra:
Gradient Gating for Deep Multi-Rate Learning on Graphs.
		Mikayel Samvelyan, Akbir Khan, Michael Dennis, Minqi Jiang, Jack Parker-Holder, Jakob Nicolaus Foerster, Roberta Raileanu, Tim Rocktäschel:
MAESTRO: Open-Ended Environment Design for Multi-Agent Reinforcement Learning.
		Alexander Munteanu, Simon Omlor, David P. Woodruff:
Almost Linear Constant-Factor Sketching for $\ell_1$ and Logistic Regression.
		Marine Collery, Philippe Bonnard, François Fages, Remy Kusters:
Neural-based classification rule learning for sequential data.
		Mahsa Forouzesh, Hanie Sedghi, Patrick Thiran:
Leveraging Unlabeled Data to Track Memorization.
		Jonathan Pirnay, Quirin Göttl, Jakob Burger, Dominik Gerhard Grimm:
Policy-Based Self-Competition for Planning Problems.
		Jinsong Zhang, Qiang Fu, Xu Chen, Lun Du, Zelin Li, Gang Wang, Xiaoguang Liu, Shi Han, Dongmei Zhang:
Out-of-Distribution Detection based on In-Distribution Data Patterns Memorization with Modern Hopfield Energy.
		Baiting Zhu, Meihua Dang, Aditya Grover:
Scaling Pareto-Efficient Decision Making via Offline Multi-Objective RL.
		Jinsong Chen, Kaiyuan Gao, Gaichao Li, Kun He:
NAGphormer: A Tokenized Graph Transformer for Node Classification in Large Graphs.
		Konstantin-Klemens Lurz, Mohammad Bashiri, Edgar Y. Walker, Fabian H. Sinz:
Bayesian Oracle for bounding information gain in neural encoding models.
		Sajad Movahedi, Melika Adabinejad, Ayyoob Imani, Arezou Keshavarz, Mostafa Dehghani, Azadeh Shakery, Babak Nadjar Araabi:
$\Lambda$-DARTS: Mitigating Performance Collapse by Harmonizing Operation Selection among Cells.
		Yitong Deng, Hong-Xing Yu, Jiajun Wu, Bo Zhu:
Learning Vortex Dynamics for Fluid Inference and Prediction.
		Fuxiang Zhang, Chengxing Jia, Yi-Chen Li, Lei Yuan, Yang Yu, Zongzhang Zhang:
Discovering Generalizable Multi-agent Coordination Skills from Multi-task Offline Data.
		Shuang Wu, Jian Yao, Haobo Fu, Ye Tian, Chao Qian, Yaodong Yang, Qiang Fu, Wei Yang:
Quality-Similar Diversity via Population Based Reinforcement Learning.
		Martin Zong, Zengyu Qiu, Xinzhu Ma, Kunlin Yang, Chunya Liu, Jun Hou, Shuai Yi, Wanli Ouyang:
Better Teacher Better Student: Dynamic Prior Knowledge for Knowledge Distillation.
		Cuiyu Liu, Chuanfu Xiao, Mingshuo Ding, Chao Yang:
Tensor-Based Sketching Method for the Low-Rank Approximation of Data Streams.
		Vadim Borisov, Kathrin Seßler, Tobias Leemann, Martin Pawelczyk, Gjergji Kasneci:
Language Models are Realistic Tabular Data Generators.
		Lin Li, Michael W. Spratling:
Data augmentation alone can improve adversarial training.
		Yuxiao Cheng, Runzhao Yang, Tingxiong Xiao, Zongren Li, Jinli Suo, Kunlun He, Qionghai Dai:
CUTS: Neural Causal Discovery from Irregular Time-Series Data.
		Xiangming Meng, Yoshiyuki Kabashima:
Quantized Compressed Sensing with Score-Based Generative Models.
		Daiki Miwa, Vo Nguyen Le Duy, Ichiro Takeuchi:
Valid P-Value for Deep Learning-driven Salient Region.
		Yao Fu, Hao Peng, Ashish Sabharwal, Peter Clark, Tushar Khot:
Complexity-Based Prompting for Multi-step Reasoning.
		Beomseok Kang, Biswadeep Chakraborty, Saibal Mukhopadhyay:
Unsupervised 3D Object Learning through Neuron Activity aware Plasticity.
		Weizhi Wang, Li Dong, Hao Cheng, Haoyu Song, Xiaodong Liu, Xifeng Yan, Jianfeng Gao, Furu Wei:
Visually-Augmented Language Modeling.
		Shengbang Tong, Xili Dai, Ziyang Wu, Mingyang Li, Brent Yi, Yi Ma:
Incremental Learning of Structured Memory via Closed-Loop Transcription.
		Jianxiong Li, Xianyuan Zhan, Haoran Xu, Xiangyu Zhu, Jingjing Liu, Ya-Qin Zhang:
When Data Geometry Meets Deep Function: Generalizing Offline Reinforcement Learning.
		Zhuofan Xia, Xuran Pan, Xuan Jin, Yuan He, Hui Xue, Shiji Song, Gao Huang:
Budgeted Training for Vision Transformer.
		Ruibo Liu, Jason Wei, Shixiang Shane Gu, Te-Yen Wu, Soroush Vosoughi, Claire Cui, Denny Zhou, Andrew M. Dai:
Mind's Eye: Grounded Language Model Reasoning through Simulation.
		Namuk Park, Wonjae Kim, Byeongho Heo, Taekyung Kim, Sangdoo Yun:
What Do Self-Supervised Vision Transformers Learn?
		Pengdeng Li, Xinrun Wang, Shuxin Li, Hau Chan, Bo An:
Population-size-Aware Policy Optimization for Mean-Field Games.
		Kuan Cheng, Shaofeng H.-C. Jiang, Luojian Wei, Zhide Wei:
On The Relative Error of Random Fourier Features for Preserving Kernel Distance.
		Pengcheng He, Jianfeng Gao, Weizhu Chen:
DeBERTaV3: Improving DeBERTa using ELECTRA-Style Pre-Training with Gradient-Disentangled Embedding Sharing.
		Qizhang Li, Yiwen Guo, Wangmeng Zuo, Hao Chen:
Squeeze Training for Adversarial Robustness.
		Jeremiah Zhe Liu, Krishnamurthy (Dj) Dvijotham, Jihyeon Lee, Quan Yuan, Balaji Lakshminarayanan, Deepak Ramachandran:
Pushing the Accuracy-Group Robustness Frontier with Introspective Self-play.
		Margalit Glasgow, Colin Wei, Mary Wootters, Tengyu Ma:
Max-Margin Works while Large Margin Fails: Generalization without Uniform Convergence.
		Kefan Dong, Tengyu Ma:
Asymptotic Instance-Optimal Algorithms for Interactive Decision Making.
		Dan Qiao, Yu-Xiang Wang:
Near-Optimal Deployment Efficiency in Reward-Free Reinforcement Learning with Linear Function Approximation.
		Yuqiao Wen, Yongchang Hao, Yanshuai Cao, Lili Mou:
An Equal-Size Hard EM Algorithm for Diverse Dialogue Generation.
		Mido Assran, Randall Balestriero, Quentin Duval, Florian Bordes, Ishan Misra, Piotr Bojanowski, Pascal Vincent, Michael G. Rabbat, Nicolas Ballas:
The hidden uniform cluster prior in self-supervised learning.
		Feng Hong, Jiangchao Yao, Zhihan Zhou, Ya Zhang, Yanfeng Wang:
Long-Tailed Partial Label Learning via Dynamic Rebalancing.
		Alex Tamkin, Kunal Handa, Avash Shrestha, Noah D. Goodman:
Task Ambiguity in Humans and Language Models.
		Yulhwa Kim, Jaeyong Jang, Jehun Lee, Jihoon Park, Jeonghoon Kim, Byeongwook Kim, Baeseong Park, Se Jung Kwon, Dongsoo Lee, Jae-Joon Kim:
Winning Both the Accuracy of Floating Point Activation and the Simplicity of Integer Arithmetic.
		Changyeon Kim, Jongjin Park, Jinwoo Shin, Honglak Lee, Pieter Abbeel, Kimin Lee:
Preference Transformer: Modeling Human Preferences using Transformers for RL.
		Jiangxing Wang, Deheng Ye, Zongqing Lu:
More Centralized Training, Still Decentralized Execution: Multi-Agent Conditional Policy Factorization.
		Bowen Jin, Yu Zhang, Yu Meng, Jiawei Han:
Edgeformers: Graph-Empowered Transformers for Representation Learning on Textual-Edge Networks.
		Haoran Sun, Bo Dai, Charles Sutton, Dale Schuurmans, Hanjun Dai:
Any-scale Balanced Samplers for Discrete Space.
		Keir Adams, Connor W. Coley:
Equivariant Shape-Conditioned Generation of 3D Molecules for Ligand-Based Drug Design.
		Renzhen Wang, Xixi Jia, Quanziang Wang, Yichen Wu, Deyu Meng:
Imbalanced Semi-supervised Learning with Bias Adaptive Classifier.
		Zi Lin, Du Phan, Panupong Pasupat, Jeremiah Zhe Liu, Jingbo Shang:
On Compositional Uncertainty Quantification for Seq2seq Graph Parsing.
		Yifan Zhang, Xue Wang, Jian Liang, Zhang Zhang, Liang Wang, Rong Jin, Tieniu Tan:
Free Lunch for Domain Adversarial Training: Environment Label Smoothing.
		Mengye Ren, Simon Kornblith, Renjie Liao, Geoffrey E. Hinton:
Scaling Forward Gradient With Local Losses.
		Yang Li, Xiaoxue Chen, Hao Zhao, Jiangtao Gong, Guyue Zhou, Federico Rossano, Yixin Zhu:
Understanding Embodied Reference with Touch-Line Transformer.
		Yewen Fan, Nian Si, Kun Zhang:
Calibration Matters: Tackling Maximization Bias in Large-scale Advertising Recommendation Systems.
		Duc Anh Nguyen, Ron Levie, Julian Lienen, Eyke Hüllermeier, Gitta Kutyniok:
Memorization-Dilation: Modeling Neural Collapse Under Noise.
		Marc T. Law, James Lucas:
Spacetime Representation Learning.
		Aviv Netanyahu, Abhishek Gupta, Max Simchowitz, Kaiqing Zhang, Pulkit Agrawal:
Learning to Extrapolate: A Transductive Approach.
		Tuomas P. Oikarinen, Subhro Das, Lam M. Nguyen, Tsui-Wei Weng:
Label-free Concept Bottleneck Models.
		Zeyuan Wang, Qiang Zhang, Shuangwei Hu, Haoran Yu, Xurui Jin, Zhichen Gong, Huajun Chen:
Multi-level Protein Structure Pre-training via Prompt Learning.
		Aohan Zeng, Xiao Liu, Zhengxiao Du, Zihan Wang, Hanyu Lai, Ming Ding, Zhuoyi Yang, Yifan Xu, Wendi Zheng, Xiao Xia, Weng Lam Tam, Zixuan Ma, Yufei Xue, Jidong Zhai, Wenguang Chen, Zhiyuan Liu, Peng Zhang, Yuxiao Dong, Jie Tang:
GLM-130B: An Open Bilingual Pre-trained Model.
		Lin Gui, Victor Veitch:
Causal Estimation for Text Data with (Apparent) Overlap Violations.
		Nicklas Hansen, Yixin Lin, Hao Su, Xiaolong Wang, Vikash Kumar, Aravind Rajeswaran:
MoDem: Accelerating Visual Model-Based Reinforcement Learning with Demonstrations.
		Toygun Basaklar, Suat Gumussoy, Ümit Y. Ogras:
PD-MORL: Preference-Driven Multi-Objective Reinforcement Learning Algorithm.
		Yuandong Tian:
Understanding the Role of Nonlinearity in Training Dynamics of Contrastive Learning.
		Junjie Yang, Xuxi Chen, Tianlong Chen, Zhangyang Wang, Yingbin Liang:
M-L2O: Towards Generalizable Learning-to-Optimize by Test-Time Fast Self-Adaptation.
		Ho Hin Lee, Shunxing Bao, Yuankai Huo, Bennett A. Landman:
3D UX-Net: A Large Kernel Volumetric ConvNet Modernizing Hierarchical Transformer for Medical Image Segmentation.
		Kevin Ro Wang, Alexandre Variengien, Arthur Conmy, Buck Shlegeris, Jacob Steinhardt:
Interpretability in the Wild: a Circuit for Indirect Object Identification in GPT-2 Small.
		Hyunwoo Ryu, Hong-in Lee, Jeong-Hoon Lee, Jongeun Choi:
Equivariant Descriptor Fields: SE(3)-Equivariant Energy-Based Models for End-to-End Visual Robotic Manipulation Learning.
		Wenwen Xia, Mincai Lai, Caihua Shan, Yao Zhang, Xinnan Dai, Xiang Li, Dongsheng Li:
Explaining Temporal Graph Models through an Explorer-Navigator Framework.
		Chongjian Ge, Jiangliu Wang, Zhan Tong, Shoufa Chen, Yibing Song, Ping Luo:
Soft Neighbors are Positive Supporters in Contrastive Visual Representation Learning.
		Charlie Snell, Ilya Kostrikov, Yi Su, Sherry Yang, Sergey Levine:
Offline RL for Natural Language Generation with Implicit Language Q Learning.
		Hao-Wen Dong, Naoya Takahashi, Yuki Mitsufuji, Julian J. McAuley, Taylor Berg-Kirkpatrick:
CLIPSep: Learning Text-queried Sound Separation with Noisy Unlabeled Videos.
		Haeyong Kang, Jaehong Yoon, Sultan Rizky Hikmawan Madjid, Sung Ju Hwang, Chang D. Yoo:
On the Soft-Subnetwork for Few-Shot Class Incremental Learning.
		Weisen Jiang, Hansi Yang, Yu Zhang, James T. Kwok:
An Adaptive Policy to Employ Sharpness-Aware Minimization.
		Thai-Hoang Pham, Xueru Zhang, Ping Zhang:
Fairness and Accuracy under Domain Generalization.
		Patrick Haluptzok, Matthew Bowers, Adam Tauman Kalai:
Language Models Can Teach Themselves to Program Better.
		Leo Feng, Hossein Hajimirsadeghi, Yoshua Bengio, Mohamed Osama Ahmed:
Latent Bottlenecked Attentive Neural Processes.
		Lingxiao Wang, Qi Cai, Zhuoran Yang, Zhaoran Wang:
Represent to Control Partially Observed Systems: Representation Learning with Provable Sample Efficiency.
		Leo Feng, Mohamed Osama Ahmed, Hossein Hajimirsadeghi, Amir H. Abdi:
Towards Better Selective Classification.
		Chuanhao Li, Huazheng Wang, Mengdi Wang, Hongning Wang:
Learning Kernelized Contextual Bandits in a Distributed and Asynchronous Environment.
		Chao Chen, Haoyu Geng, Gang Zeng, Zhaobing Han, Hua Chai, Xiaokang Yang, Junchi Yan:
Graph Signal Sampling for Inductive One-Bit Matrix Completion: a Closed-form Solution.
		Xianbiao Qi, Jianan Wang, Yihao Chen, Yukai Shi, Lei Zhang:
LipsFormer: Introducing Lipschitz Continuity to Vision Transformers.
		Zhuosheng Zhang, Aston Zhang, Mu Li, Alex Smola:
Automatic Chain of Thought Prompting in Large Language Models.
		Kai Li, Runxuan Yang, Xiaolin Hu:
An efficient encoder-decoder architecture with top-down attention for speech separation.
		Chao Pan, Jin Sima, Saurav Prakash, Vishal Rana, Olgica Milenkovic:
Machine Unlearning of Federated Clusters.
		Xiaobo Xia, Jiale Liu, Jun Yu, Xu Shen, Bo Han, Tongliang Liu:
Moderate Coreset: A Universal Method of Data Selection for Real-world Data-efficient Deep Learning.
		Yichao Du, Zhirui Zhang, Bingzhe Wu, Lemao Liu, Tong Xu, Enhong Chen:
Federated Nearest Neighbor Machine Translation.
		Tongzheng Ren, Chenjun Xiao, Tianjun Zhang, Na Li, Zhaoran Wang, Sujay Sanghavi, Dale Schuurmans, Bo Dai:
Latent Variable Representation for Reinforcement Learning.
		Han Lu, Zenan Li, Runzhong Wang, Qibing Ren, Xijun Li, Mingxuan Yuan, Jia Zeng, Xiaokang Yang, Junchi Yan:
ROCO: A General Framework for Evaluating Robustness of Combinatorial Optimization Solvers on Graphs.
		Raja Marjieh, Pol van Rijn, Ilia Sucholutsky, Theodore R. Sumers, Harin Lee, Thomas L. Griffiths, Nori Jacoby:
Words are all you need? Language as an approximation for human similarity judgments.
		Yidong Wang, Hao Chen, Qiang Heng, Wenxin Hou, Yue Fan, Zhen Wu, Jindong Wang, Marios Savvides, Takahiro Shinozaki, Bhiksha Raj, Bernt Schiele, Xing Xie:
FreeMatch: Self-adaptive Thresholding for Semi-supervised Learning.
		Chen Li, Xiaoling Hu, Chao Chen:
Confidence Estimation Using Unlabeled Data.
		Tongzheng Ren, Tianjun Zhang, Lisa Lee, Joseph E. Gonzalez, Dale Schuurmans, Bo Dai:
Spectral Decomposition Representation for Reinforcement Learning.
		Guanghui Wang, Rafael Hanashiro, Etash Kumar Guha, Jacob D. Abernethy:
On Accelerated Perceptrons and Beyond.
		Hao Chen, Ran Tao, Yue Fan, Yidong Wang, Jindong Wang, Bernt Schiele, Xing Xie, Bhiksha Raj, Marios Savvides:
SoftMatch: Addressing the Quantity-Quality Tradeoff in Semi-supervised Learning.
		Yanchao Sun, Ruijie Zheng, Parisa Hassanzadeh, Yongyuan Liang, Soheil Feizi, Sumitra Ganesh, Furong Huang:
Certifiably Robust Policy Learning against Adversarial Multi-Agent Communication.
		Zachary Novack, Simran Kaur, Tanya Marwah, Saurabh Garg, Zachary Chase Lipton:
Disentangling the Mechanisms Behind Implicit Regularization in SGD.
		Taisuke Yasuda, Mohammad Hossein Bateni, Lin Chen, Matthew Fahrbach, Gang Fu, Vahab Mirrokni:
Sequential Attention for Feature Selection.
		Yuan Cheng, Ruiquan Huang, Yingbin Liang, Jing Yang:
Improved Sample Complexity for Reward-free Reinforcement Learning under Low-rank MDPs.
		Wenhu Chen, Hexiang Hu, Chitwan Saharia, William W. Cohen:
Re-Imagen: Retrieval-Augmented Text-to-Image Generator.
		Sanae Amani, Lin Yang, Ching-An Cheng:
Provably Efficient Lifelong Reinforcement Learning with Linear Representation.
		William Shiao, Zhichun Guo, Tong Zhao, Evangelos E. Papalexakis, Yozen Liu, Neil Shah:
Link Prediction with Non-Contrastive Learning.
		Sayak Ray Chowdhury, Xingyu Zhou:
Distributed Differential Privacy in Multi-Armed Bandits.
		Hongkang Li, Meng Wang, Sijia Liu, Pin-Yu Chen:
A Theoretical Understanding of Shallow Vision Transformers: Learning, Generalization, and Sample Complexity.
		Daniel D. Johnson, Ayoub El Hanchi, Chris J. Maddison:
Contrastive Learning Can Find An Optimal Basis For Approximately View-Invariant Functions.
		Ankur Moitra, Dhruv Rohatgi:
Provably Auditing Ordinary Least Squares in Low Dimensions.
		Sudhanshu Chanpuriya, Ryan A. Rossi, Sungchul Kim, Tong Yu, Jane Hoffswell, Nedim Lipka, Shunan Guo, Cameron Musco:
Direct Embedding of Temporal Network Edges via Time-Decayed Line Graphs.
		Wonseok Jeon, Mukul Gagrani, Burak Bartan, Weiliang Will Zeng, Harris Teague, Piero Zappi, Christopher Lott:
Neural DAG Scheduling via One-Shot Priority Sampling.
		Wonho Bae, Mohamed Osama Ahmed, Frederick Tung, Gabriel L. Oliveira:
Meta Temporal Point Processes.
		Zehao Niu, Mihai Anitescu, Jie Chen:
Graph Neural Network-Inspired Kernels for Gaussian Processes in Semi-Supervised Learning.
		Gal Kaplun, Nikhil Ghosh, Saurabh Garg, Boaz Barak, Preetum Nakkiran:
Deconstructing Distributions: A Pointwise Framework of Learning.
		Pedro Sanchez, Xiao Liu, Alison Q. O'Neil, Sotirios A. Tsaftaris:
Diffusion Models for Causal Discovery via Topological Ordering.
		Jeremy Ocampo, Matthew A. Price, Jason D. McEwen:
Scalable and Equivariant Spherical CNNs by Discrete-Continuous (DISCO) Convolutions.
		Zijun Wu, Zi Xuan Zhang, Atharva Naik, Zhijian Mei, Mauajama Firdaus, Lili Mou:
Weakly Supervised Explainable Phrasal Reasoning with Neural Fuzzy Logic.
		Cian Eastwood, Andrei Liviu Nicolicioiu, Julius von Kügelgen, Armin Kekic, Frederik Träuble, Andrea Dittadi, Bernhard Schölkopf:
DCI-ES: An Extended Disentanglement Framework with Connections to Identifiability.
		Ahmed Khaled, Chi Jin:
Faster federated optimization under second-order similarity.
		Yan Yan, Yuhong Guo:
Mutual Partial Label Learning with Competitive Label Noise.
		Yan Yan, Yuhong Guo:
Partial Label Unsupervised Domain Adaptation with Class-Prototype Alignment.
		Zitao Liu, Qiongqiong Liu, Jiahao Chen, Shuyan Huang, Weiqi Luo:
simpleKT: A Simple But Tough-to-Beat Baseline for Knowledge Tracing.
		Yangjun Ruan, Saurabh Singh, Warren Richard Morningstar, Alexander A. Alemi, Sergey Ioffe, Ian Fischer, Joshua V. Dillon:
Weighted Ensemble Self-Supervised Learning.
		Shibani Santurkar, Yann Dubois, Rohan Taori, Percy Liang, Tatsunori Hashimoto:
Is a Caption Worth a Thousand Images? A Study on Representation Learning.
		Jiaao Chen, Aston Zhang, Xingjian Shi, Mu Li, Alex Smola, Diyi Yang:
Parameter-Efficient Fine-Tuning Design Spaces.
		Andrew Bai, Chih-Kuan Yeh, Neil Y. C. Lin, Pradeep Kumar Ravikumar, Cho-Jui Hsieh:
Concept Gradient: Concept-based Interpretation Without Linear Assumption.
		João Monteiro, Pau Rodríguez, Pierre-André Noël, Issam H. Laradji, David Vázquez:
Constraining Representations Yields Models That Know What They Don't Know.
		Trevor Scott Standley, Ruohan Gao, Dawn Chen, Jiajun Wu, Silvio Savarese:
An Extensible Multi-modal Multi-task Object Dataset with Materials.
		Lingxiao Li, Qiang Liu, Anna Korba, Mikhail Yurochkin, Justin Solomon:
Sampling with Mollified Interaction Energy Descent.
		Alex Damian, Eshaan Nichani, Jason D. Lee:
Self-Stabilization: The Implicit Bias of Gradient Descent at the Edge of Stability.
		Siheng Xiong, Yuan Yang, Faramarz Fekri, James Clayton Kerce:
TILP: Differentiable Learning of Temporal Logical Rules on Knowledge Graphs.
		Weicheng Kuo, Yin Cui, Xiuye Gu, A. J. Piergiovanni, Anelia Angelova:
Open-Vocabulary Object Detection upon Frozen Vision and Language Models.
		Xiangyu Qi, Tinghao Xie, Yiming Li, Saeed Mahloujifar, Prateek Mittal:
Revisiting the Assumption of Latent Separability for Backdoor Defenses.
		Arindam Banerjee, Pedro Cisneros-Velarde, Libin Zhu, Misha Belkin:
Restricted Strong Convexity of Deep Learning Models with Smooth Activations.
		Rui Wang, Yihe Dong, Sercan Ö. Arik, Rose Yu:
Koopman Neural Operator Forecaster for Time-series with Temporal Distributional Shifts.
		Namyong Park, Ryan A. Rossi, Nesreen K. Ahmed, Christos Faloutsos:
MetaGL: Evaluation-Free Selection of Graph Learning Models via Meta-Learning.
		Ted Moskovitz, Ta-Chu Kao, Maneesh Sahani, Matt M. Botvinick:
Minimum Description Length Control.
		Mehdi Setayesh, Xiaoxiao Li, Vincent W. S. Wong:
PerFedMask: Personalized Federated Learning with Optimized Masking Vectors.
		Qitong Gao, Ge Gao, Min Chi, Miroslav Pajic:
Variational Latent Branching Model for Off-Policy Evaluation.
		Annan Yu, Yunan Yang, Alex Townsend:
Tuning Frequency Bias in Neural Network Training with Nonuniform Data.
		Zichang Liu, Zhiqiang Tang, Xingjian Shi, Aston Zhang, Mu Li, Anshumali Shrivastava, Andrew Gordon Wilson:
Learning Multimodal Data Augmentation in Feature Space.
		Sang-gil Lee, Wei Ping, Boris Ginsburg, Bryan Catanzaro, Sungroh Yoon:
BigVGAN: A Universal Neural Vocoder with Large-Scale Training.
		Arnob Ghosh, Xingyu Zhou, Ness B. Shroff:
Achieving Sub-linear Regret in Infinite Horizon Average Reward Constrained MDP with Linear Function Approximation.
		Kangrui Ruan, Junzhe Zhang, Xuan Di, Elias Bareinboim:
Causal Imitation Learning via Inverse Reinforcement Learning.
		Brian DuSell, David Chiang:
The Surprising Computational Power of Nondeterministic Stack RNNs.
		Pranjal Awasthi, Alex Tang, Aravindan Vijayaraghavan:
Agnostic Learning of General ReLU Activation Using Gradient Descent.
		Renzhi Wu, Shen-En Chen, Jieyu Zhang, Xu Chu:
Learning Hyper Label Model for Programmatic Weak Supervision.
		Tianfei Zhou, Ender Konukoglu:
FedFA: Federated Feature Augmentation.
		Haozhe Jiang, Qiwen Cui, Zhihan Xiong, Maryam Fazel, Simon Shaolei Du:
Offline Congestion Games: How Feedback Type Affects Data Coverage Requirement.
		Lirui Wang, Kaiqing Zhang, Yunzhu Li, Yonglong Tian, Russ Tedrake:
Does Learning from Decentralized Non-IID Unlabeled Data Benefit from Self Supervision?
		Yoav Wald, Gal Yona, Uri Shalit, Yair Carmon:
Malign Overfitting: Interpolation and Invariance are Fundamentally at Odds.
		Yuancheng Xu, Yanchao Sun, Micah Goldblum, Tom Goldstein, Furong Huang:
Exploring and Exploiting Decision Boundary Dynamics for Adversarial Robustness.
		Reinald Kim Amplayo, Peter J. Liu, Yao Zhao, Shashi Narayan:
SMART: Sentences as Basic Units for Text Evaluation.
		Zeyu Tang, Yatong Chen, Yang Liu, Kun Zhang:
Tier Balancing: Towards Dynamic Fairness over Underlying Causal Factors.
		Edward De Brouwer, Rahul G. Krishnan:
Anamnesic Neural Differential Equations with Orthogonal Polynomial Projections.
		Kaidi Cao, Jiaxuan You, Jiaju Liu, Jure Leskovec:
AutoTransfer: AutoML with Knowledge Transfer - An Application to Graph Neural Networks.
		Kin Kwan Leung, Clayton Rooke, Jonathan Smith, Saba Zuberi, Maksims Volkovs:
Temporal Dependencies in Feature Importance for Time Series Prediction.
		Michael Murray, Hui Jin, Benjamin Bowman, Guido Montúfar:
Characterizing the spectrum of the NTK via a power series expansion.
		Oleg Platonov, Denis Kuznedelev, Michael Diskin, Artem Babenko, Liudmila Prokhorenkova:
A critical look at the evaluation of GNNs under heterophily: Are we really making progress?
		Eugene Choi, Kyunghyun Cho, Cheolhyoung Lee:
A Non-monotonic Self-terminating Language Model.
		Jiachen Yao, Yikai Zhang, Songzhu Zheng, Mayank Goswami, Prateek Prasanna, Chao Chen:
Learning to Segment from Noisy Annotations: A Spatial Correction Approach.
		Matthew Jagielski, Om Thakkar, Florian Tramèr, Daphne Ippolito, Katherine Lee, Nicholas Carlini, Eric Wallace, Shuang Song, Abhradeep Guha Thakurta, Nicolas Papernot, Chiyuan Zhang:
Measuring Forgetting of Memorized Training Examples.
		Agrim Gupta, Stephen Tian, Yunzhi Zhang, Jiajun Wu, Roberto Martín-Martín, Li Fei-Fei:
MaskViT: Masked Visual Pre-Training for Video Prediction.
		Yumo Xu, Mirella Lapata:
Text Summarization with Oracle Expectation.
		Gerben Izaak Beintema, Maarten Schoukens, Roland Tóth:
Continuous-time identification of dynamic state-space models by deep subspace encoding.
		Albert Gu, Isys Johnson, Aman Timalsina, Atri Rudra, Christopher Ré:
How to Train your HIPPO: State Space Models with Generalized Orthogonal Basis Projections.
		Prince Osei Aboagye, Yan Zheng, Jack Shunn, Chin-Chia Michael Yeh, Junpeng Wang, Zhongfang Zhuang, Huiyuan Chen, Liang Wang, Wei Zhang, Jeff M. Phillips:
Interpretable Debiasing of Vectorized Language Representations with Iterative Orthogonalization.
		Ziyu Jiang, Yinpeng Chen, Mengchen Liu, Dongdong Chen, Xiyang Dai, Lu Yuan, Zicheng Liu, Zhangyang Wang:
Layer Grafted Pre-training: Bridging Contrastive Learning And Masked Image Modeling For Label-Efficient Representations.
		Collin Burns, Haotian Ye, Dan Klein, Jacob Steinhardt:
Discovering Latent Knowledge in Language Models Without Supervision.
		Boah Kim, Yujin Oh, Jong Chul Ye:
Diffusion Adversarial Representation Learning for Self-supervised Vessel Segmentation.
		Noam Levi, Itay M. Bloch, Marat Freytsis, Tomer Volansky:
Noise Injection Node Regularization for Robust Learning.
		Anil Kag, Igor Fedorov, Aditya Gangrade, Paul N. Whatmough, Venkatesh Saligrama:
Efficient Edge Inference by Selective Query.
		Steven Kapturowski, Victor Campos, Ray Jiang, Nemanja Rakicevic, Hado van Hasselt, Charles Blundell, Adrià Puigdomènech Badia:
Human-level Atari 200x faster.
		Charles Jin, Melinda Sun, Martin C. Rinard:
Incompatibility Clustering as a Defense Against Backdoor Poisoning Attacks.
		Samuel Sokota, Ryan D'Orazio, J. Zico Kolter, Nicolas Loizou, Marc Lanctot, Ioannis Mitliagkas, Noam Brown, Christian Kroer:
A Unified Approach to Reinforcement Learning, Quantal Response Equilibria, and Two-Player Zero-Sum Games.
		Holden Lee, Chirag Pabbaraju, Anish Prasad Sevekari, Andrej Risteski:
Pitfalls of Gaussians as a noise distribution in NCE.
		Oren Neumann, Claudius Gros:
Scaling Laws for a Multi-Agent Reinforcement Learning Model.
		Christian Schröder de Witt, Samuel Sokota, J. Zico Kolter, Jakob Nicolaus Foerster, Martin Strohmeier:
Perfectly Secure Steganography Using Minimum Entropy Coupling.
		Wenlong Chen, Yingzhen Li:
Calibrating Transformers via Sparse Gaussian Processes.
		Niv Cohen, Jonathan Kahana, Yedid Hoshen:
Red PANDA: Disambiguating Image Anomaly Detection by Removing Nuisance Factors.
		Mukund Varma T, Peihao Wang, Xuxi Chen, Tianlong Chen, Subhashini Venugopalan, Zhangyang Wang:
Is Attention All That NeRF Needs?
		Yichi Zhou, Fang Kong, Shuai Li:
Stochastic No-regret Learning for General Games with Variance Reduction.
		Ren Pang, Changjiang Li, Zhaohan Xi, Shouling Ji, Ting Wang:
The Dark Side of AutoML: Towards Architectural Backdoor Search.
		Avner Shultzman, Eyar Azar, Miguel R. D. Rodrigues, Yonina C. Eldar:
Generalization and Estimation Error Bounds for Model-based Neural Networks.
		Ruslan Khalitov, Tong Yu, Lei Cheng, Zhirong Yang:
ChordMixer: A Scalable Neural Attention Model for Sequences with Different Length.
		Muzammal Naseer, Ahmad Mahmood, Salman Khan, Fahad Shahbaz Khan:
Boosting Adversarial Transferability using Dynamic Cues.
		David Bieber, Rishab Goel, Daniel Zheng, Hugo Larochelle, Daniel Tarlow:
Static Prediction of Runtime Errors by Learning to Execute Programs with External Resource Descriptions.
		Matej Hladis, Maxence Lalis, Sébastien Fiorucci, Jérémie Topin:
Matching receptor to odorant with protein language and graph neural networks.
		Hanseul Cho, Chulhee Yun:
SGDA with shuffling: faster convergence for nonconvex-PŁ minimax optimization.
		Chenglin Yang, Siyuan Qiao, Qihang Yu, Xiaoding Yuan, Yukun Zhu, Alan L. Yuille, Hartwig Adam, Liang-Chieh Chen:
MOAT: Alternating Mobile Convolution and Attention Brings Strong Vision Models.
		Chawin Sitawarin, Kornrapat Pongmala, Yizheng Chen, Nicholas Carlini, David A. Wagner:
Part-Based Models Improve Adversarial Robustness.
		Zhe Wang, Jake Grigsby, Yanjun Qi:
PGrad: Learning Principal Gradients For Domain Generalization.
		Andrija Djurisic, Nebojsa Bozanic, Arjun Ashok, Rosanne Liu:
Extremely Simple Activation Shaping for Out-of-Distribution Detection.
		Zhixin Zhou, Gautam Dudeja, Arash A. Amini:
Statistical Guarantees for Consensus Clustering.
		Niklas Nolte, Ouail Kitouni, Mike Williams:
Expressive Monotonic Neural Networks.
		Pierre Fernandez, Matthijs Douze, Hervé Jégou, Teddy Furon:
Active Image Indexing.
		Wenyu Han, Haoran Wu, Eisuke Hirota, Alexander Gao, Lerrel Pinto, Ludovic Righetti, Chen Feng:
Learning Simultaneous Navigation and Construction in Grid Worlds.
		Minjun Kim, Junyoung Park, Jinkyoo Park:
Learning to CROSS exchange to solve min-max vehicle routing problems.
		James Oldfield, Christos Tzelepis, Yannis Panagakis, Mihalis Nicolaou, Ioannis Patras:
PandA: Unsupervised Learning of Parts and Appearances in the Feature Maps of GANs.
		Fan Shi, Bin Li, Xiangyang Xue:
Compositional Law Parsing with Latent Random Functions.
		Sharath Girish, Kamal Gupta, Saurabh Singh, Abhinav Shrivastava:
LilNetX: Lightweight Networks with EXtreme Model Compression and Structured Sparsification.
		Sumyeong Ahn, Seongyoon Kim, Se-Young Yun:
Mitigating Dataset Bias by Using Per-Sample Gradient.
		Eli Chien, Chao Pan, Olgica Milenkovic:
Efficient Model Updates for Approximate Unlearning of Graph-Structured Data.
		Felix Kreuk, Gabriel Synnaeve, Adam Polyak, Uriel Singer, Alexandre Défossez, Jade Copet, Devi Parikh, Yaniv Taigman, Yossi Adi:
AudioGen: Textually Guided Audio Generation.
		Yu Duan, Zhongfan Jia, Qian Li, Yi Zhong, Kaisheng Ma:
Hebbian and Gradient-based Plasticity Enables Robust Memory and Rapid Learning in RNNs.
		Pihe Hu, Yu Chen, Longbo Huang:
Towards Minimax Optimal Reward-free Reinforcement Learning in Linear MDPs.
		Sicong Liu, Xi Sheryl Zhang, Yushuo Li, Yifan Zhang, Jian Cheng:
On the Data-Efficiency with Contrastive Image Transformation in Reinforcement Learning.
		Qitian Wu, Yiting Chen, Chenxiao Yang, Junchi Yan:
Energy-based Out-of-Distribution Detection for Graph Neural Networks.
		Yuhan Li, Wenzhuo Zhou, Ruoqing Zhu:
Quasi-optimal Reinforcement Learning with Continuous Actions.
		Xiaolin Hu, Shaojie Li, Yong Liu:
Generalization Bounds for Federated Learning: Fast Rates, Unparticipating Clients and Unbounded Losses.
		Shiwei Liu, Tianlong Chen, Xiaohan Chen, Xuxi Chen, Qiao Xiao, Boqian Wu, Tommi Kärkkäinen, Mykola Pechenizkiy, Decebal Constantin Mocanu, Zhangyang Wang:
More ConvNets in the 2020s: Scaling up Kernels Beyond 51x51 using Sparsity.
		Yixiong Chen, Alan L. Yuille, Zongwei Zhou:
Which Layer is Learning Faster? A Systematic Exploration of Layer-wise Convergence Rate for Deep Neural Networks.
		Xinyi Wu, Zhengdao Chen, William Wei Wang, Ali Jadbabaie:
A Non-Asymptotic Analysis of Oversmoothing in Graph Neural Networks.
		Mohammad Amin Shabani, Amir H. Abdi, Lili Meng, Tristan Sylvain:
Scaleformer: Iterative Multi-scale Refining Transformers for Time Series Forecasting.
		Ramin M. Hasani, Mathias Lechner, Tsun-Hsuan Wang, Makram Chahine, Alexander Amini, Daniela Rus:
Liquid Structural State-Space Models.
		Peihao Wang, Shenghao Yang, Yunyu Liu, Zhangyang Wang, Pan Li:
Equivariant Hypergraph Diffusion Neural Operators.
		Corinna Coupette, Sebastian Dalleiger, Bastian Rieck:
Ollivier-Ricci Curvature for Hypergraphs: A Unified Framework.
		Samyadeep Basu, Megan Stanley, John Bronskill, Soheil Feizi, Daniela Massiceti:
Hard-Meta-Dataset++: Towards Understanding Few-Shot Performance on Difficult Tasks.
		Andrew Drozdov, Nathanael Schärli, Ekin Akyürek, Nathan Scales, Xinying Song, Xinyun Chen, Olivier Bousquet, Denny Zhou:
Compositional Semantic Parsing with Large Language Models.
		Xiang Li, Junchi Yang, Niao He:
TiAda: A Time-scale Adaptive Algorithm for Nonconvex Minimax Optimization.
		Puheng Li, James Zou, Linjun Zhang:
FaiREE: fair classification with finite-sample and distribution-free guarantee.
		Xiaotong Yuan, Ping Li:
Exponential Generalization Bounds with Near-Optimal Rates for $L_q$-Stable Algorithms.
		Eric C. Yeats, Frank Y. Liu, Hai Helen Li:
Disentangling Learning Representations with Density Estimation.
		Manzil Zaheer, Ankit Singh Rawat, Seungyeon Kim, Chong You, Himanshu Jain, Andreas Veit, Rob Fergus, Sanjiv Kumar:
Teacher Guided Training: An Efficient Framework for Knowledge Transfer.
		Valentin Taillandier, Dieuwke Hupkes, Benoît Sagot, Emmanuel Dupoux, Paul Michel:
Neural Agents Struggle to Take Turns in Bidirectional Emergent Communication.
		Chenglei Si, Zhe Gan, Zhengyuan Yang, Shuohang Wang, Jianfeng Wang, Jordan L. Boyd-Graber, Lijuan Wang:
Prompting GPT-3 To Be Reliable.
		Lukas Muttenthaler, Jonas Dippel, Lorenz Linhardt, Robert A. Vandermeulen, Simon Kornblith:
Human alignment of neural network representations.
		Mingjie Li, Yifei Wang, Yisen Wang, Zhouchen Lin:
Unbiased Stochastic Proximal Solver for Graph Neural Networks with Equilibrium States.
		Clément Vignac, Igor Krawczuk, Antoine Siraudin, Bohan Wang, Volkan Cevher, Pascal Frossard:
DiGress: Discrete Denoising diffusion for graph generation.
		Yi Ren, Shangmin Guo, Wonho Bae, Danica J. Sutherland:
How to prepare your task head for finetuning.
		Shansan Gong, Mukai Li, Jiangtao Feng, Zhiyong Wu, Lingpeng Kong:
DiffuSeq: Sequence to Sequence Text Generation with Diffusion Models.
		Haichao Zhang, Wei Xu, Haonan Yu:
Policy Expansion for Bridging Offline-to-Online Reinforcement Learning.
		Hao Cheng, Zhaowei Zhu, Xing Sun, Yang Liu:
Mitigating Memorization of Noisy Labels via Regularization between Representations.
		Chenxiao Yang, Qitian Wu, Jiahua Wang, Junchi Yan:
Graph Neural Networks are Inherently Good Generalizers: Insights by Bridging GNNs and MLPs.
		Zhihai Wang, Xijun Li, Jie Wang, Yufei Kuang, Mingxuan Yuan, Jia Zeng, Yongdong Zhang, Feng Wu:
Learning Cut Selection for Mixed-Integer Linear Programming via Hierarchical Sequence Model.
		Yuchen Liu, Ziyu Jia:
BSTT: A Bayesian Spatial-Temporal Transformer for Sleep Staging.
		Enrico Marchesini, Christopher Amato:
Improving Deep Policy Gradients with Value Function Search.
		Ziyuan Qin, Huahui Yi, Qicheng Lao, Kang Li:
MEDICAL IMAGE UNDERSTANDING WITH PRETRAINED VISION LANGUAGE MODELS: A COMPREHENSIVE STUDY.
		Chenyu Yi, Siyuan Yang, Yufei Wang, Haoliang Li, Yap-Peng Tan, Alex C. Kot:
Temporal Coherent Test Time Optimization for Robust Video Classification.
		Tom Ginsberg, Zhongyuan Liang, Rahul G. Krishnan:
A Learning Based Hypothesis Test for Harmful Covariate Shift.
		Bobby He, James Martens, Guodong Zhang, Aleksandar Botev, Andrew Brock, Samuel L. Smith, Yee Whye Teh:
Deep Transformers without Shortcuts: Modifying Self-attention for Faithful Signal Propagation.
		Kaifeng Zhang, Yang Fu, Shubhankar Borse, Hong Cai, Fatih Porikli, Xiaolong Wang:
Self-Supervised Geometric Correspondence for Category-Level 6D Object Pose Estimation in the Wild.
		Leitian Tao, Xuefeng Du, Jerry Zhu, Yixuan Li:
Non-parametric Outlier Synthesis.
		Namjoon Suh, Tian-Yi Zhou, Xiaoming Huo:
Approximation and non-parametric estimation of functions over high-dimensional spheres via deep ReLU networks.
		Canzhe Zhao, Ruofeng Yang, Baoxiang Wang, Shuai Li:
Learning Adversarial Linear Mixture Markov Decision Processes with Bandit Feedback and Unknown Transition.
		Martijn Oldenhof, Adam Arany, Yves Moreau, Edward De Brouwer:
Weakly Supervised Knowledge Transfer with Probabilistic Logical Reasoning for Object Detection.
		Liyuan Xu, Arthur Gretton:
A Neural Mean Embedding Approach for Back-door and Front-door Adjustment.
		Rongjie Huang, Jinglin Liu, Huadai Liu, Yi Ren, Lichao Zhang, Jinzheng He, Zhou Zhao:
TranSpeech: Speech-to-Speech Translation With Bilateral Perturbation.
		Yixuan Chen, Yubin Shi, Mingzhi Dong, Xiaochen Yang, Dongsheng Li, Yujiang Wang, Robert P. Dick, Qin Lv, Yingying Zhao, Fan Yang, Ning Gu, Li Shang:
Over-parameterized Model Optimization with Polyak-Łojasiewicz Condition.
		Alexandros Haliassos, Pingchuan Ma, Rodrigo Mira, Stavros Petridis, Maja Pantic:
Jointly Learning Visual and Auditory Speech Representations from Raw Data.
		Daniel Palenicek, Michael Lutter, Joao Carvalho, Jan Peters:
Diminishing Return of Value Expansion Methods in Model-Based Reinforcement Learning.
		Hongwei Xue, Yuchong Sun, Bei Liu, Jianlong Fu, Ruihua Song, Houqiang Li, Jiebo Luo:
CLIP-ViP: Adapting Pre-trained Image-Text Model to Video-Language Alignment.
		Fan Bao, Min Zhao, Zhongkai Hao, Peiyao Li, Chongxuan Li, Jun Zhu:
Equivariant Energy-Guided SDE for Inverse Molecular Design.
		Yifan Xu, Nicklas Hansen, Zirui Wang, Yung-Chieh Chan, Hao Su, Zhuowen Tu:
On the Feasibility of Cross-Task Transfer with Model-Based Reinforcement Learning.
		Seohyeon Jung, Sanghyun Kim, Juho Lee:
A Simple Yet Powerful Deep Active Learning With Snapshots Ensembles.
		Giung Nam, Sunguk Jang, Juho Lee:
Decoupled Training for Long-Tailed Classification With Stochastic Representations.
		Pengzhen Ren, Changlin Li, Hang Xu, Yi Zhu, Guangrun Wang, Jianzhuang Liu, Xiaojun Chang, Xiaodan Liang:
ViewCo: Discovering Text-Supervised Segmentation Masks via Multi-View Semantic Consistency.
		Guiliang Liu, Yudong Luo, Ashish Gaurav, Kasra Rezaee, Pascal Poupart:
Benchmarking Constraint Inference in Inverse Reinforcement Learning.
		Marco Pleines, Matthias Pallasch, Frank Zimmer, Mike Preuss:
Memory Gym: Partially Observable Challenges to Memory-Based Agents.
		Tom Zahavy, Yannick Schroecker, Feryal M. P. Behbahani, Kate Baumli, Sebastian Flennerhag, Shaobo Hou, Satinder Singh:
Discovering Policies with DOMiNO: Diversity Optimization Maintaining Near Optimality.
		Yixuan Mei, Jiaxuan Gao, Weirui Ye, Shaohuai Liu, Yang Gao, Yi Wu:
SpeedyZero: Mastering Atari with Limited Data and Time.
		Steffen Jung, Jovita Lukasik, Margret Keuper:
Neural Architecture Design and Robustness: A Dataset.
		Shengnan An, Zeqi Lin, Bei Chen, Qiang Fu, Nanning Zheng, Jian-Guang Lou:
Does Deep Learning Learn to Abstract? A Systematic Probing Framework.
		Kha Pham, Hung Le, Man Ngo, Truyen Tran:
Improving Out-of-distribution Generalization with Indirection Representations.
		Suttisak Wizadwongsa, Supasorn Suwajanakorn:
Accelerating Guided Diffusion Sampling with Splitting Numerical Methods.
		Christopher Jung, Georgy Noarov, Ramya Ramalingam, Aaron Roth:
Batch Multivalid Conformal Prediction.
		Michael Volpp, Philipp Dahlinger, Philipp Becker, Christian Daniel, Gerhard Neumann:
Accurate Bayesian Meta-Learning by Accurate Task Posterior Inference.
		Feng Wang, Manling Li, Xudong Lin, Hairong Lv, Alexander G. Schwing, Heng Ji:
Learning to Decompose Visual Features with Latent Textual Prompts.
		Johannes Schimunek, Philipp Seidl, Lukas Friedrich, Daniel Kuhn, Friedrich Rippmann, Sepp Hochreiter, Günter Klambauer:
Context-enriched molecule representations improve few-shot drug discovery.
		Minguk Jang, Sae-Young Chung, Hye Won Chung:
Test-Time Adaptation via Self-Training with Nearest Neighbor Information.
		Brian Chmiel, Ron Banner, Elad Hoffer, Hilla Ben-Yaacov, Daniel Soudry:
Accurate Neural Training with 4-bit Matrix Multiplications at Standard Formats.
		Dexiong Chen, Bowen Fan, Carlos G. Oliver, Karsten M. Borgwardt:
Unsupervised Manifold Alignment with Joint Multidimensional Scaling.
		Yuhan Dai, Zhirui Zhang, Qiuzhi Liu, Qu Cui, Weihua Li, Yichao Du, Tong Xu:
Simple and Scalable Nearest Neighbor Machine Translation.
		Jianhong Bai, Zuozhu Liu, Hualiang Wang, Jin Hao, Yang Feng, Huanpeng Chu, Haoji Hu:
On the Effectiveness of Out-of-Distribution Data in Self-Supervised Long-Tail Learning.
		Nicolai Dorka, Tim Welschehold, Wolfram Burgard:
Dynamic Update-to-Data Ratio: Minimizing World Model Overfitting.
		Gengmo Zhou, Zhifeng Gao, Qiankun Ding, Hang Zheng, Hongteng Xu, Zhewei Wei, Linfeng Zhang, Guolin Ke:
Uni-Mol: A Universal 3D Molecular Representation Learning Framework.
		Sunghyeon Woo, Dongsuk Jeon:
Learning with Auxiliary Activation for Memory-Efficient Training.
		Mark Collier, Rodolphe Jenatton, Basil Mustafa, Neil Houlsby, Jesse Berent, Effrosyni Kokiopoulou:
Massively Scaling Heteroscedastic Classifiers.
		Yufei Wang, Jiayi Zheng, Can Xu, Xiubo Geng, Tao Shen, Chongyang Tao, Daxin Jiang:
KnowDA: All-in-One Knowledge Mixture Model for Data Augmentation in Low-Resource NLP.
		Jaewoong Choi, Geonho Hwang, Hyunsoo Cho, Myungjoo Kang:
Finding the Global Semantic Representation in GAN through Fréchet Mean.
		Paul Pu Liang, Yiwei Lyu, Gunjan Chhablani, Nihal Jain, Zihao Deng, Xingbo Wang, Louis-Philippe Morency, Ruslan Salakhutdinov:
MultiViz: Towards Visualizing and Understanding Multimodal Models.
		Jetze Schuurmans, Kim Batselier, Julian F. P. Kooij:
How Informative is the Approximation Error from Tensor Decomposition for Neural Network Compression?
		Emiel Hoogeboom, Tim Salimans:
Blurring Diffusion Models.
		Luca Franco, Paolo Mandica, Bharti Munjal, Fabio Galasso:
Hyperbolic Self-paced Learning for Self-supervised Skeleton-based Action Representations.
		Zichen Liu, Siyi Li, Wee Sun Lee, Shuicheng Yan, Zhongwen Xu:
Efficient Offline Policy Optimization with a Learned Model.
		Dahuin Jung, Dongjin Lee, Sunwon Hong, Hyemi Jang, Ho Bae, Sungroh Yoon:
New Insights for the Stability-Plasticity Dilemma in Online Continual Learning.
		Qihao Zhao, Yangyu Huang, Wei Hu, Fan Zhang, Jun Liu:
MixPro: Data Augmentation with MaskMix and Progressive Attention Labeling for Vision Transformer.
		Eric-Tuan Le, Edward Bartrum, Iasonas Kokkinos:
StyleMorph: Disentangled 3D-Aware Image Synthesis with a 3D Morphable StyleGAN.
		Kun Wang, Yuxuan Liang, Pengkun Wang, Xu Wang, Pengfei Gu, Junfeng Fang, Yang Wang:
Searching Lottery Tickets in Graph Neural Networks: A Dual Perspective.
		Siqi Chen, Jun Xiao, Long Chen:
Video Scene Graph Generation from Single-Frame Weak Supervision.
		Jan Niklas Böhm, Philipp Berens, Dmitry Kobak:
Unsupervised visualization of image datasets using contrastive learning.
		Edouard Yvinec, Arnaud Dapogny, Matthieu Cord, Kevin Bailly:
PowerQuant: Automorphism Search for Non-Uniform Quantization.
		Jinchuan Tian, Brian Yan, Jianwei Yu, Chao Weng, Dong Yu, Shinji Watanabe:
Bayes Risk CTC: Controllable CTC Alignment in Sequence-to-Sequence Tasks.
		Jiajin Li, Jianheng Tang, Lemin Kong, Huikang Liu, Jia Li, Anthony Man-Cho So, Jose H. Blanchet:
A Convergent Single-Loop Algorithm for Relaxation of Gromov-Wasserstein in Graph Data.
		Stoil Ganev, Laurence Aitchison:
Semi-supervised learning with a principled likelihood from a generative model of data curation.
		Yangtian Zhang, Huiyu Cai, Chence Shi, Jian Tang:
E3Bind: An End-to-End Equivariant Network for Protein-Ligand Docking.
		Sangwon Jung, Taeeon Park, Sanghyuk Chun, Taesup Moon:
Re-weighting Based Group Fairness Regularization via Classwise Robust Optimization.
		Haiteng Zhao, Shuming Ma, Dongdong Zhang, Zhi-Hong Deng, Furu Wei:
Are More Layers Beneficial to Graph Transformers?
		Thomas F. Burns, Tomoki Fukai:
Simplicial Hopfield networks.
		Zongyu Guo, Cuiling Lan, Zhizheng Zhang, Yan Lu, Zhibo Chen:
Versatile Neural Processes for Learning Implicit Neural Representations.
		Jonas Landman, Slimane Thabet, Constantin Dalyac, Hela Mhiri, Elham Kashefi:
Classically Approximating Variational Quantum Machine Learning with Random Fourier Features.
		Haiyan Yin, Shuicheng Yan, Zhongwen Xu:
Distributional Meta-Gradient Reinforcement Learning.
		Yazheng Liu, Xi Zhang, Sihong Xie:
A Differential Geometric View and Explainability of GNN on Evolving Graphs.
		Zeyu Zhu, Fanrong Li, Zitao Mo, Qinghao Hu, Gang Li, Zejian Liu, Xiaoyao Liang, Jian Cheng:
$\rm A^2Q$: Aggregation-Aware Quantization for Graph Neural Networks.
		Eduard Gorbunov, Samuel Horváth, Peter Richtárik, Gauthier Gidel:
Variance Reduction is an Antidote to Byzantines: Better Rates, Weaker Assumptions and Communication Compression as a Cherry on the Top.
		Zhen Wang, Rameswar Panda, Leonid Karlinsky, Rogério Feris, Huan Sun, Yoon Kim:
Multitask Prompt Tuning Enables Parameter-Efficient Transfer Learning.
		Daiqing Qi, Handong Zhao, Sheng Li:
Better Generative Replay for Continual Federated Learning.
		Severi Rissanen, Markus Heinonen, Arno Solin:
Generative Modelling with Inverse Heat Dissipation.
		Tianyu Hua, Yonglong Tian, Sucheng Ren, Michalis Raptis, Hang Zhao, Leonid Sigal:
Self-supervision through Random Segments with Autoregressive Coding (RandSAC).
		Zeyu Huang, Yikang Shen, Xiaofeng Zhang, Jie Zhou, Wenge Rong, Zhang Xiong:
Transformer-Patcher: One Mistake Worth One Neuron.
		Shi Fu, Yunwen Lei, Qiong Cao, Xinmei Tian, Dacheng Tao:
Sharper Bounds for Uniformly Stable Algorithms with Stationary Mixing Process.
		Kaiyue Wen, Jiaye Teng, Jingzhao Zhang:
Benign Overfitting in Classification: Provably Counter Label Noise with Larger Models.
		Jiaye Teng, Chuan Wen, Dinghuai Zhang, Yoshua Bengio, Yang Gao, Yang Yuan:
Predictive Inference with Feature Conformal Prediction.
		Guangyuan Shi, Qimai Li, Wenlong Zhang, Jiaxin Chen, Xiao-Ming Wu:
Recon: Reducing Conflicting Gradients From the Root For Multi-Task Learning.
		Jiashuo Liu, Jiayun Wu, Renjie Pi, Renzhe Xu, Xingxuan Zhang, Bo Li, Peng Cui:
Measure the Predictive Heterogeneity.
		Arthur Aubret, Markus Roland Ernst, Céline Teulière, Jochen Triesch:
Time to augment self-supervised visual representation learning.
		Xu Zhang, Yuan Zhao, Ziang Cui, Liqun Li, Shilin He, Qingwei Lin, Yingnong Dang, Saravan Rajmohan, Dongmei Zhang:
Towards Lightweight, Model-Agnostic and Diversity-Aware Active Anomaly Detection.
		Wei Hung, Bo-Kai Huang, Ping-Chun Hsieh, Xi Liu:
Q-Pensieve: Boosting Sample Efficiency of Multi-Objective RL Through Memory Sharing of Q-Snapshots.
		Yan Dai, Ruosong Wang, Simon Shaolei Du:
Variance-Aware Sparse Linear Bandits.
		Huan Lei, Ruitao Leng, Liang Zheng, Hongdong Li:
CircNet: Meshing 3D Point Clouds with Circumcenter Detection.
		Hongchang Zhang, Yixiu Mao, Boyuan Wang, Shuncheng He, Yi Xu, Xiangyang Ji:
In-sample Actor Critic for Offline Reinforcement Learning.
		Daehee Park, Hobin Ryu, Yunseo Yang, Jegyeong Cho, Jiwon Kim, Kuk-Jin Yoon:
Leveraging Future Relationship Reasoning for Vehicle Trajectory Prediction.
		Qiang Zhou, Yuang Liu, Chaohui Yu, Jingliang Li, Zhibin Wang, Fan Wang:
LMSeg: Language-guided Multi-dataset Segmentation.
		Sangwoo Mo, Jong-Chyi Su, Chih-Yao Ma, Mido Assran, Ishan Misra, Licheng Yu, Sean Bell:
RoPAWS: Robust Semi-supervised Representation Learning from Uncurated Data.
		Lovish Madaan, Srinadh Bhojanapalli, Himanshu Jain, Prateek Jain:
Treeformer: Dense Gradient Trees for Efficient Attention Computation.
		Chenyang Zhao, Antoni B. Chan:
ODAM: Gradient-based Instance-Specific Visual Explanations for Object Detection.
		Hongqiu Wu, Yongxiang Liu, Hanwen Shi, Hai Zhao, Min Zhang:
Toward Adversarial Training on Contextualized Language Representation.
		Nao Nakagawa, Ren Togo, Takahiro Ogawa, Miki Haseyama:
Gromov-Wasserstein Autoencoders.
		Jianxin Wang, José Bento:
Optimal Activation Functions for the Random Features Regression Model.
		Baoxiong Jia, Yu Liu, Siyuan Huang:
Improving Object-centric Learning with Query Optimization.
		Sravanti Addepalli, Anshul Nasery, Venkatesh Babu Radhakrishnan, Praneeth Netrapalli, Prateek Jain:
Feature Reconstruction From Outputs Can Mitigate Simplicity Bias in Neural Networks.
		Yifu Yuan, Jianye Hao, Fei Ni, Yao Mu, Yan Zheng, Yujing Hu, Jinyi Liu, Yingfeng Chen, Changjie Fan:
EUCLID: Towards Efficient Unsupervised Reinforcement Learning with Multi-choice Dynamics Model.
		Junyan Wang, Zhenhong Sun, Yichen Qian, Dong Gong, Xiuyu Sun, Ming C. Lin, Maurice Pagnucco, Yang Song:
Maximizing Spatio-Temporal Entropy of Deep 3D CNNs for Efficient Video Recognition.
		Yun Young Choi, Sun Woo Park, Youngho Woo, U Jin Choi:
Cycle to Clique (Cy2C) Graph Neural Network: A Sight to See beyond Neighborhood Aggregation.
		Dinghuai Zhang, Aaron C. Courville, Yoshua Bengio, Qinqing Zheng, Amy Zhang, Ricky T. Q. Chen:
Latent State Marginalization as a Low-cost Approach for Improving Exploration.
		Weiyang Liu, Longhui Yu, Adrian Weller, Bernhard Schölkopf:
Generalizing and Decoupling Neural Collapse via Hyperspherical Uniformity Gap.
		Chao Liao, Jianchao Tan, Jiyuan Jia, Yi Guo, Chengru Song:
MaskFusion: Feature Augmentation for Click-Through Rate Prediction via Input-adaptive Mask Fusion.
		Hongsuk Choi, Hyeongjin Nam, Taeryung Lee, Gyeongsik Moon, Kyoung Mu Lee:
Rethinking Self-Supervised Visual Representation Learning in Pre-training for 3D Human Pose and Shape Estimation.
		Daoyuan Chen, Wuchao Li, Yaliang Li, Bolin Ding, Kai Zeng, Defu Lian, Jingren Zhou:
Learned Index with Dynamic $\epsilon$.
		Jianye Hao, Xiaotian Hao, Hangyu Mao, Weixun Wang, Yaodong Yang, Dong Li, Yan Zheng, Zhen Wang:
Boosting Multiagent Reinforcement Learning via Permutation Invariant and Permutation Equivariant Networks.
		Adhiraj Banerjee, Vipul Arora:
wav2tok: Deep Sequence Tokenizer for Audio Retrieval.
		Eric Zhongcong Xu, Jianfeng Zhang, Jun Hao Liew, Wenqing Zhang, Song Bai, Jiashi Feng, Mike Zheng Shou:
PV3D: A 3D Generative Model for Portrait Video Generation.
		Zizhang Chen, Peizhao Li, Hongfu Liu, Pengyu Hong:
Characterizing the Influence of Graph Elements.
		Marco Bornstein, Tahseen Rabbani, Evan Wang, Amrit S. Bedi, Furong Huang:
SWIFT: Rapid Decentralized Federated Learning via Wait-Free Model Communication.
		Khai Nguyen, Tongzheng Ren, Huy Nguyen, Litu Rout, Tan Minh Nguyen, Nhat Ho:
Hierarchical Sliced Wasserstein Distance.
		Zhixiong Han, Yaru Hao, Li Dong, Yutao Sun, Furu Wei:
Prototypical Calibration for Few-shot Learning of Language Models.
		Heewon Kim, Kyoung Mu Lee:
NERDS: A General Framework to Train Camera Denoisers from Raw-RGB Noisy Image Pairs.
		Limei Wang, Haoran Liu, Yi Liu, Jerry Kurtin, Shuiwang Ji:
Learning Hierarchical Protein Representations via Complete 3D Graph Networks.
		Shancong Mou, Xiaoyi Gu, Meng Cao, Haoping Bai, Ping Huang, Jiulong Shan, Jianjun Shi:
RGI: robust GAN-inversion for mask-free image inpainting and unsupervised pixel-wise anomaly detection.
		Haizhong Zheng, Rui Liu, Fan Lai, Atul Prakash:
Coverage-centric Coreset Selection for High Pruning Rates.
		Chiu Wai Yan, Tsz-Him Cheung, Dit-Yan Yeung:
ILA-DA: Improving Transferability of Intermediate Level Attack with Data Augmentation.
		Zaid Khan, Yun Fu:
Contrastive Alignment of Vision to Language Through Parameter-Efficient Transfer Learning.
		Fu-Yun Wang, Da-Wei Zhou, Liu Liu, Han-Jia Ye, Yatao Bian, De-Chuan Zhan, Peilin Zhao:
BEEF: Bi-Compatible Class-Incremental Learning via Energy-Based Expansion and Fusion.
		Wang Lu, Jindong Wang, Xinwei Sun, Yiqiang Chen, Xing Xie:
Out-of-distribution Representation Learning for Time Series Classification.
		Haofei Zhang, Mengqi Xue, Xiaokang Liu, Kaixuan Chen, Jie Song, Mingli Song:
Schema Inference for Interpretable Image Classification.
		Tianyang Hu, Zhili Liu, Fengwei Zhou, Wenjia Wang, Weiran Huang:
Your Contrastive Learning Is Secretly Doing Stochastic Neighbor Embedding.
		Zhang-Wei Hong, Pulkit Agrawal, Remi Tachet des Combes, Romain Laroche:
Harnessing Mixed Offline Reinforcement Learning Datasets via Trajectory Weighting.
		Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc V. Le, Ed H. Chi, Sharan Narang, Aakanksha Chowdhery, Denny Zhou:
Self-Consistency Improves Chain of Thought Reasoning in Language Models.
		Changze Lv, Jianhan Xu, Xiaoqing Zheng:
Spiking Convolutional Neural Networks for Text Classification.
		Duy Nguyen, Ngoc Bui, Viet Anh Nguyen:
Distributionally Robust Recourse Action.
		Shizhe Diao, Wangchunshu Zhou, Xinsong Zhang, Jiawei Wang:
Write and Paint: Generative Vision-Language Models are Unified Modal Learners.
		Chunwei Ma, Zhanghexuan Ji, Ziyun Huang, Yan Shen, Mingchen Gao, Jinhui Xu:
Progressive Voronoi Diagram Subdivision Enables Accurate Data-free Class-Incremental Learning.
		Nohyun Ki, Hoyong Choi, Hye Won Chung:
Data Valuation Without Training of a Model.
		Tianlong Chen, Chengyue Gong, Daniel Jesus Diaz, Xuxi Chen, Jordan Tyler Wells, Qiang Liu, Zhangyang Wang, Andrew D. Ellington, Alex Dimakis, Adam R. Klivans:
HotProtein: A Novel Framework for Protein Thermostability Prediction and Editing.
		Wei Qiu, Xiao Ma, Bo An, Svetlana Obraztsova, Shuicheng Yan, Zhongwen Xu:
RPM: Generalizable Multi-Agent Policies for Multi-Agent Reinforcement Learning.
		Hongyu Zang, Xin Li, Jie Yu, Chen Liu, Riashat Islam, Remi Tachet des Combes, Romain Laroche:
Behavior Prior Representation learning for Offline Reinforcement Learning.
		Junfeng Guo, Yiming Li, Xun Chen, Hanqing Guo, Lichao Sun, Cong Liu:
SCALE-UP: An Efficient Black-box Input-level Backdoor Detection via Analyzing Scaled Prediction Consistency.
		Ravi Mangal, Zifan Wang, Chi Zhang, Klas Leino, Corina S. Pasareanu, Matt Fredrikson:
On the Perils of Cascading Robust Classifiers.
		Ansong Ni, Jeevana Priya Inala, Chenglong Wang, Alex Polozov, Christopher Meek, Dragomir Radev, Jianfeng Gao:
Learning Math Reasoning from Self-Sampled Correct and Partially-Correct Solutions.
		Hitesh Sapkota, Qi Yu:
Adaptive Robust Evidential Optimization For Open Set Detection from Imbalanced Data.
		Xuan Su, Jiaming Song, Chenlin Meng, Stefano Ermon:
Dual Diffusion Implicit Bridges for Image-to-Image Translation.
		Satoshi Hara, Yuichi Yoshida:
Average Sensitivity of Decision Tree Learning.
		Yilun Xu, Shangyuan Tong, Tommi S. Jaakkola:
Stable Target Field for Reduced Variance Score Estimation in Diffusion Models.
		Dan Berrebbi, Ronan Collobert, Samy Bengio, Navdeep Jaitly, Tatiana Likhomanenko:
Continuous pseudo-labeling from the start.
		Jiali Cheng, George Dasoulas, Huan He, Chirag Agarwal, Marinka Zitnik:
GNNDelete: A General Strategy for Unlearning in Graph Neural Networks.
		Keegan Harris, Ioannis Anagnostides, Gabriele Farina, Mikhail Khodak, Steven Wu, Tuomas Sandholm:
Meta-Learning in Games.
		Gabriele Corso, Hannes Stärk, Bowen Jing, Regina Barzilay, Tommi S. Jaakkola:
DiffDock: Diffusion Steps, Twists, and Turns for Molecular Docking.
		Gleb V. Ryzhakov, Ivan V. Oseledets:
Constructive TT-representation of the tensors given as index interaction functions with applications.
		Patrick Lutz, Ludovic Arnould, Claire Boyer, Erwan Scornet:
Sparse tree-based Initialization for Neural Networks.
		Angtian Wang, Peng Wang, Jian Sun, Adam Kortylewski, Alan L. Yuille:
VoGE: A Differentiable Volume Renderer using Gaussian Ellipsoids for Analysis-by-Synthesis.
		Zonglin Li, Chong You, Srinadh Bhojanapalli, Daliang Li, Ankit Singh Rawat, Sashank J. Reddi, Ke Ye, Felix Chern, Felix X. Yu, Ruiqi Guo, Sanjiv Kumar:
The Lazy Neuron Phenomenon: On Emergence of Activation Sparsity in Transformers.
		Kedar Karhadkar, Pradeep Kr. Banerjee, Guido Montúfar:
FoSR: First-order spectral rewiring for addressing oversquashing in GNNs.
		Benedikt Boecking, Nicholas Carl Roberts, Willie Neiswanger, Stefano Ermon, Frederic Sala, Artur Dubrawski:
Generative Modeling Helps Weak Supervision (and Vice Versa).
		Junghwan Kim, Michelle Kim, Barzan Mozafari:
Provable Memorization Capacity of Transformers.
		Qi Wang, Marco Federici, Herke van Hoof:
Bridge the Inference Gaps of Neural Processes via Expectation Maximization.
		Gukyeong Kwon, Zhaowei Cai, Avinash Ravichandran, Erhan Bas, Rahul Bhotika, Stefano Soatto:
Masked Vision and Language Modeling for Multi-modal Representation Learning.
		Karolis Martinkus, Pál András Papp, Benedikt Schesch, Roger Wattenhofer:
Agent-based Graph Neural Networks.
		Haoxing Tian, Ioannis Ch. Paschalidis, Alex Olshevsky:
On the Performance of Temporal Difference Learning With Neural Networks.
		Maksym Yatsura, Kaspar Sakmann, N. Grace Hua, Matthias Hein, Jan Hendrik Metzen:
Certified Defences Against Adversarial Patch Attacks on Semantic Segmentation.
		Yuntian Deng, Noriyuki Kojima, Alexander M. Rush:
Markup-to-Image Diffusion Models with Scheduled Sampling.
		Yutong Xie, Ziqiao Xu, Jiaqi Ma, Qiaozhu Mei:
How Much Space Has Been Explored? Measuring the Chemical Space Covered by Databases and Machine-Generated Molecules.
		Subha Maity, Mikhail Yurochkin, Moulinath Banerjee, Yuekai Sun:
Understanding new tasks through the lens of training data via exponential tilting.
		Yao Zhao, Misha Khalman, Rishabh Joshi, Shashi Narayan, Mohammad Saleh, Peter J. Liu:
Calibrating Sequence likelihood Improves Conditional Language Generation.
		Geoffrey Négiar, Michael W. Mahoney, Aditi S. Krishnapriyan:
Learning differentiable solvers for systems with hard constraints.
		Aoxiao Zhong, Hao He, Zhaolin Ren, Na Li, Quanzheng Li:
FedDAR: Federated Domain-Aware Representation Learning.
		Ziyi Wu, Nikita Dvornik, Klaus Greff, Thomas Kipf, Animesh Garg:
SlotFormer: Unsupervised Visual Dynamics Simulation with Object-Centric Models.
		Raj Ghugare, Homanga Bharadhwaj, Benjamin Eysenbach, Sergey Levine, Russ Salakhutdinov:
Simplifying Model-based RL: Learning Representations, Latent-space Models, and Policies with One Objective.
		Samuel Holt, Zhaozhi Qian, Mihaela van der Schaar:
Deep Generative Symbolic Regression.
		Ido Galil, Mohammed Dabbah, Ran El-Yaniv:
What Can we Learn From The Selective Prediction And Uncertainty Estimation Performance Of 523 Imagenet Classifiers?
		Subha Maity, Debarghya Mukherjee, Moulinath Banerjee, Yuekai Sun:
Predictor-corrector algorithms for stochastic optimization under gradual distribution shift.
		Taojiannan Yang, Yi Zhu, Yusheng Xie, Aston Zhang, Chen Chen, Mu Li:
AIM: Adapting Image Models for Efficient Video Action Recognition.
		Aaron Walsman, Muru Zhang, Sanjiban Choudhury, Dieter Fox, Ali Farhadi:
Impossibly Good Experts and How to Follow Them.
		Jiaheng Wei, Harikrishna Narasimhan, Ehsan Amid, Wen-Sheng Chu, Yang Liu, Abhishek Kumar:
Distributionally Robust Post-hoc Classifiers under Prior Shifts.
		Ruchi Guo, Shuhao Cao, Long Chen:
Transformer Meets Boundary Value Inverse Problems.
		Xiang An, Jiankang Deng, Kaicheng Yang, Jaiwei Li, Ziyong Feng, Jia Guo, Jing Yang, Tongliang Liu:
Unicom: Universal and Compact Representation Learning for Image Retrieval.
		Peiye Zhuang, Samira Abnar, Jiatao Gu, Alexander G. Schwing, Joshua M. Susskind, Miguel Ángel Bautista:
Diffusion Probabilistic Fields.
		Alexandre Perez-Lebel, Marine Le Morvan, Gaël Varoquaux:
Beyond calibration: estimating the grouping loss of modern neural networks.
		Yuda Song, Yifei Zhou, Ayush Sekhari, Drew Bagnell, Akshay Krishnamurthy, Wen Sun:
Hybrid RL: Using both offline and online data can make RL efficient.
		Xiangyu Peng, Chen Xing, Prafulla Kumar Choubey, Chien-Sheng Wu, Caiming Xiong:
Model ensemble instead of prompt fusion: a sample-specific knowledge transfer method for few-shot prompt tuning.
		Junlong Li, Guangyi Chen, Yansong Tang, Jinan Bao, Kun Zhang, Jie Zhou, Jiwen Lu:
GAIN: On the Generalization of Instructional Action Understanding.
		Chaoqi Yang, M. Brandon Westover, Jimeng Sun:
ManyDG: Many-domain Generalization for Healthcare Applications.
		Donghan Yu, Sheng Zhang, Patrick Ng, Henghui Zhu, Alexander Hanbo Li, Jun Wang, Yiqun Hu, William Yang Wang, Zhiguo Wang, Bing Xiang:
DecAF: Joint Decoding of Answers and Logical Forms for Question Answering over Knowledge Bases.
		Hyeong-Seok Choi, Jinhyeok Yang, Juheon Lee, Hyeongju Kim:
NANSY++: Unified Voice Synthesis with Neural Analysis and Synthesis.
		Ruyang Liu, Jingjia Huang, Thomas H. Li, Ge Li:
Causality Compensated Attention for Contextual Biased Visual Recognition.
		Haoye Lu, Daniel Herman, Yaoliang Yu:
Multi-Objective Reinforcement Learning: Convexity, Stationarity and Pareto Optimality.
		Gabriel Laberge, Ulrich Aïvodji, Satoshi Hara, Mario Marchand, Foutse Khomh:
Fooling SHAP with Stealthily Biased Sampling.
		Ruicheng Ao, Shicong Cen, Yuejie Chi:
Asynchronous Gradient Play in Zero-Sum Multi-agent Games.
		Daniel Watson, William Chan, Ricardo Martin-Brualla, Jonathan Ho, Andrea Tagliasacchi, Mohammad Norouzi:
Novel View Synthesis with Diffusion Models.
		Bing Wang, Lu Chen, Bo Yang:
DM-NeRF: 3D Scene Geometry Decomposition and Manipulation from 2D Images.
		Tim Z. Xiao, Robert Bamler:
Trading Information between Latents in Hierarchical Variational Autoencoders.
		Felix Petersen, Tobias Sutter, Christian Borgelt, Dongsung Huh, Hilde Kuehne, Yuekai Sun, Oliver Deussen:
ISAAC Newton: Input-based Approximate Curvature for Newton's Method.
		Han Liu, Yizhou Tian, Chacha Chen, Shi Feng, Yuxin Chen, Chenhao Tan:
Learning Human-Compatible Representations for Case-Based Decision Support.
		Thomas Laurent, James von Brecht, Xavier Bresson:
Long-Tailed Learning Requires Feature Learning.
		Yifei Ming, Yiyou Sun, Ousmane Dia, Yixuan Li:
How to Exploit Hyperspherical Embeddings for Out-of-Distribution Detection?
		Omprakash Chakraborty, Aadarsh Sahoo, Rameswar Panda, Abir Das:
AnyDA: Anytime Domain Adaptation.
		Shihao Zhang, Linlin Yang, Michael Bi Mi, Xiaoxu Zheng, Angela Yao:
Improving Deep Regression with Ordinal Entropy.
		Minghui Hu, Chuanxia Zheng, Zuopeng Yang, Tat-Jen Cham, Heliang Zheng, Chaoyue Wang, Dacheng Tao, Ponnuthurai N. Suganthan:
Unified Discrete Diffusion for Simultaneous Vision-Language Generation.
		Benjamin Bergner, Christoph Lippert, Aravindh Mahendran:
Iterative Patch Selection for High-Resolution Image Recognition.
		Zhengrui Ma, Chenze Shao, Shangtong Gui, Min Zhang, Yang Feng:
Fuzzy Alignments in Directed Acyclic Graph for Non-Autoregressive Machine Translation.
		Zeyu Zhou, Sheikh Shams Azam, Christopher G. Brinton, David I. Inouye:
Efficient Federated Domain Translation.
		Zhennan Wu, Yang Li, Yifei Huang, Lin Gu, Tatsuya Harada, Hiroyuki Sato:
3D Segmenter: 3D Transformer based Semantic Segmentation via 2D Panoramic Distillation.
		Johannes Brandstetter, Rianne van den Berg, Max Welling, Jayesh K. Gupta:
Clifford Neural Layers for PDE Modeling.
		Haiwen Huang, Andreas Geiger, Dan Zhang:
GOOD: Exploring geometric cues for detecting objects in an open world.
		Jintai Chen, Kuanlun Liao, Yanwen Fang, Danny Z. Chen, Jian Wu:
TabCaps: A Capsule Neural Network for Tabular Data Classification with BoW Routing.
		Amit Daniely, Elad Granot:
An Exact Poly-Time Membership-Queries Algorithm for Extracting a Three-Layer ReLU Network.
		Yujun Shi, Jian Liang, Wenqing Zhang, Vincent Y. F. Tan, Song Bai:
Towards Understanding and Mitigating Dimensional Collapse in Heterogeneous Federated Learning.
		Shuzhou Sun, Shuaifeng Zhi, Janne Heikkilä, Li Liu:
Evidential Uncertainty and Diversity Guided Active Learning for Scene Graph Generation.
		Moritz Thürlemann, Sereina Riniker:
Anisotropic Message Passing: Graph Neural Networks with Directional and Long-Range Interactions.
		Jingdong Zhang, Qunxi Zhu, Wei Yang, Wei Lin:
SYNC: Safety-Aware Neural Control for Stabilizing Stochastic Delay-Differential Equations.
		Adeel Pervez, Phillip Lippe, Efstratios Gavves:
Differentiable Mathematical Programming for Object-Centric Representation Learning.
		Adeel Pervez, Phillip Lippe, Efstratios Gavves:
Scalable Subset Sampling with Neural Conditional Poisson Networks.
		Huang Fang, Xiaoyun Li, Chenglin Fan, Ping Li:
Improved Convergence of Differential Private SGD with Gradient Clipping.
		Erik Franz, Barbara Solenthaler, Nils Thuerey:
Learning to Estimate Single-View Volumetric Flow Motions without 3D Supervision.
		Xuyang Zhao, Tianqi Du, Yisen Wang, Jun Yao, Weiran Huang:
ArCL: Enhancing Contrastive Learning with Augmentation-Robust Representations.
		Anna Kukleva, Moritz Böhle, Bernt Schiele, Hilde Kuehne, Christian Rupprecht:
Temperature Schedules for self-supervised contrastive methods on long-tail data.
		Luca De Luigi, Adriano Cardace, Riccardo Spezialetti, Pierluigi Zama Ramirez, Samuele Salti, Luigi Di Stefano:
Deep Learning on Implicit Neural Representations of Shapes.
		Minheng Ni, Zitong Huang, Kailai Feng, Wangmeng Zuo:
ImaginaryNet: Learning Object Detectors without Real Images and Annotations.
		Virginie Do, Elvis Dohmatob, Matteo Pirotta, Alessandro Lazaric, Nicolas Usunier:
Contextual bandits with concave rewards, and an application to fair ranking.
		Aleksei Ustimenko, Artem Beliakov, Liudmila Prokhorenkova:
Gradient Boosting Performs Gaussian Process Inference.
		Chao Yu, Jiaxuan Gao, Weilin Liu, Botian Xu, Hao Tang, Jiaqi Yang, Yu Wang, Yi Wu:
Learning Zero-Shot Cooperation with Humans, Assuming Humans Are Biased.
		David M. Knigge, David W. Romero, Albert Gu, Efstratios Gavves, Erik J. Bekkers, Jakub Mikolaj Tomczak, Mark Hoogendoorn, Jan-Jakob Sonke:
Modelling Long Range Dependencies in $N$D: From Task-Specific to a General Purpose CNN.
		Simone Zini, Alex Gomez-Villa, Marco Buzzelli, Bartlomiej Twardowski, Andrew D. Bagdanov, Joost van de Weijer:
Planckian Jitter: countering the color-crippling effects of color jitter on self-supervised training.
		Mohit Vaishnav, Thomas Serre:
GAMR: A Guided Attention Model for (visual) Reasoning.
		Abdullah Hamdi, Silvio Giancola, Bernard Ghanem:
Voint Cloud: Multi-View Point Cloud Representation for 3D Understanding.
		Noam Touitou, Nissim Halabi:
Approximate Nearest Neighbor Search through Modern Error-Correcting Codes.
		Alihan Hüyük, Zhaozhi Qian, Mihaela van der Schaar:
When to Make and Break Commitments?
		Heng Li, Xiaodong Gu, Weihao Yuan, Luwei Yang, Zilong Dong, Ping Tan:
Dense RGB Slam with Neural Implicit Maps.
		Weihao Yuan, Xiaodong Gu, Heng Li, Zilong Dong, Siyu Zhu:
Monocular Scene Reconstruction with 3D SDF Transformers.
		Seungwoong Ha, Hawoong Jeong:
Learning Heterogeneous Interaction Strengths by Trajectory Prediction with Graph Neural Network.
		Sebastian Damrich, Jan Niklas Böhm, Fred A. Hamprecht, Dmitry Kobak:
From $t$-SNE to UMAP with contrastive learning.
		Chi-Chang Lee, Yu Tsao, Hsin-Min Wang, Chu-Song Chen:
D4AM: A General Denoising Framework for Downstream Acoustic Models.
		Qingru Zhang, Minshuo Chen, Alexander Bukharin, Pengcheng He, Yu Cheng, Weizhu Chen, Tuo Zhao:
Adaptive Budget Allocation for Parameter-Efficient Fine-Tuning.
		Qingchun Hou, Jingwei Yang, Yiqiang Su, Xiaoqing Wang, Yuming Deng:
Generalize Learned Heuristics to Solve Large-scale Vehicle Routing Problems in Real-time.
		Weiran Huang, Mingyang Yi, Xuyang Zhao, Zihao Jiang:
Towards the Generalization of Contrastive Self-Supervised Learning.
		Runjian Chen, Yao Mu, Runsen Xu, Wenqi Shao, Chenhan Jiang, Hang Xu, Yu Qiao, Zhenguo Li, Ping Luo:
CO3: Cooperative Unsupervised 3D Representation Learning for Autonomous Driving.
		Yi Ren, Chen Zhang, Shuicheng Yan:
Bag of Tricks for Unsupervised Text-to-Speech.
		Yan Sun, Li Shen, Tiansheng Huang, Liang Ding, Dacheng Tao:
FedSpeed: Larger Local Interval, Less Communication Round, and Higher Generalization Accuracy.
		Hong-Yu Zhou, Chenyu Lian, Liansheng Wang, Yizhou Yu:
Advancing Radiograph Representation Learning with Masked Record Modeling.
		Kailang Ma, Yu Sun, Jian Cui, Dawei Li, Zhenyu Guan, Jianwei Liu:
Instance-wise Batch Label Restoration via Gradients in Federated Learning.
		Xiaohan Ding, Honghao Chen, Xiangyu Zhang, Kaiqi Huang, Jungong Han, Guiguang Ding:
Re-parameterizing Your Optimizers rather than Architectures.
		Hong-Yu Zhou, Yunxiang Fu, Zhicheng Zhang, Cheng Bian, Yizhou Yu:
Protein Representation Learning via Knowledge Enhanced Primary Structure Reasoning.
		Hao Hu, Yiqin Yang, Qianchuan Zhao, Chongjie Zhang:
The Provable Benefit of Unsupervised Data Sharing for Offline Reinforcement Learning.
		Shunyu Zhang, Yaobo Liang, Ming Gong, Daxin Jiang, Nan Duan:
Modeling Sequential Sentence Relation to Improve Cross-lingual Dense Retrieval.
		Minjae Kim, Sangyoon Yu, Suhyun Kim, Soo-Mook Moon:
DepthFL : Depthwise Federated Learning for Heterogeneous Clients.
		Kun Yi, Yixiao Ge, Xiaotong Li, Shusheng Yang, Dian Li, Jianping Wu, Ying Shan, Xiaohu Qie:
Masked Image Modeling with Denoising Contrast.
		Ming Zhang, Shenghan Zhang, Zhenjie Yang, Lekai Chen, Jinliang Zheng, Chao Yang, Chuming Li, Hang Zhou, Yazhe Niu, Yu Liu:
GoBigger: A Scalable Platform for Cooperative-Competitive Multi-Agent Interactive Simulation.
		Junnan Li, Silvio Savarese, Steven C. H. Hoi:
Masked Unsupervised Self-training for Label-free Image Classification.
		Zhenhui Ye, Ziyue Jiang, Yi Ren, Jinglin Liu, Jinzheng He, Zhou Zhao:
GeneFace: Generalized and High-Fidelity Audio-Driven 3D Talking Face Synthesis.
		Hao Zhang, Feng Li, Shilong Liu, Lei Zhang, Hang Su, Jun Zhu, Lionel M. Ni, Heung-Yeung Shum:
DINO: DETR with Improved DeNoising Anchor Boxes for End-to-End Object Detection.
		Kuan Li, Yang Liu, Xiang Ao, Qing He:
Revisiting Graph Adversarial Attack and Defense From a Data Distribution Perspective.
		Jiachen Hu, Han Zhong, Chi Jin, Liwei Wang:
Provable Sim-to-real Transfer in Continuous Domain with Partial Observations.
		Tolga Ergen, Halil Ibrahim Gulluk, Jonathan Lacotte, Mert Pilanci:
Globally Optimal Training of Neural Networks with Threshold Activation Functions.
		Zaixi Zhang, Yaosen Min, Shuxin Zheng, Qi Liu:
Molecule Generation For Target Protein Binding with Structural Motifs.
		Yi Zeng, Zhouxing Shi, Ming Jin, Feiyang Kang, Lingjuan Lyu, Cho-Jui Hsieh, Ruoxi Jia:
Towards Robustness Certification Against Universal Perturbations.
		Yong Zhong, Hongtao Liu, Xiaodong Liu, Fan Bao, Weiran Shen, Chongxuan Li:
Deep Generative Modeling on Limited Data with Regularization by Nontransferable Pre-trained Models.
		Bin Xia, Yulun Zhang, Yitong Wang, Yapeng Tian, Wenming Yang, Radu Timofte, Luc Van Gool:
Basic Binary Convolution Unit for Binarized Image Restoration Network.
		Qiying Yu, Yang Liu, Yimu Wang, Ke Xu, Jingjing Liu:
Multimodal Federated Learning via Contrastive Representation Ensemble.
		Lin Zhang, Shaohuai Shi, Bo Li:
Eva: Practical Second-order Optimization with Kronecker-vectorized Approximation.
		Zeyu Wang, Yutong Bai, Yuyin Zhou, Cihang Xie:
Can CNNs Be More Robust Than Transformers?
		Thanh Lam, Arun Verma, Bryan Kian Hsiang Low, Patrick Jaillet:
Risk-Aware Reinforcement Learning with Coherent Risk Measures and Non-linear Function Approximation.
		Zhongkai Hao, Chengyang Ying, Hang Su, Jun Zhu, Jian Song, Ze Cheng:
Bi-level Physics-Informed Neural Networks for PDE Constrained Optimization using Broyden's Hypergradients.
		Yicheng Li, Haobo Zhang, Qian Lin:
On the Saturation Effect of Kernel Ridge Regression.
		Zuobai Zhang, Minghao Xu, Arian Rokkum Jamasb, Vijil Chenthamarakshan, Aurélie C. Lozano, Payel Das, Jian Tang:
Protein Representation Learning by Geometric Structure Pretraining.
		Tao Li, Zhehao Huang, Qinghua Tao, Yingwen Wu, Xiaolin Huang:
Trainable Weight Averaging: Efficient Training by Optimizing Historical Solutions.
		Ming Xu, Sourav Garg, Michael Milford, Stephen Gould:
Deep Declarative Dynamic Time Warping for End-to-End Learning of Alignment Paths.
		Ting Chen, Ruixiang Zhang, Geoffrey E. Hinton:
Analog Bits: Generating Discrete Data using Diffusion Models with Self-Conditioning.
		Xingyu Zhu, Zixuan Wang, Xiang Wang, Mo Zhou, Rong Ge:
Understanding Edge-of-Stability Training Dynamics with a Minimalist Example.
		Lingxiao Li, Noam Aigerman, Vladimir G. Kim, Jiajin Li, Kristjan H. Greenewald, Mikhail Yurochkin, Justin Solomon:
Learning Proximal Operators to Discover Multiple Optima.
		Nadim Saad, Gaurav Gupta, Shima Alizadeh, Danielle C. Maddix:
Guiding continuous operator learning through Physics-based boundary constraints.
		Matthew Wallingford, Aditya Kusupati, Alex Fang, Vivek Ramanujan, Aniruddha Kembhavi, Roozbeh Mottaghi, Ali Farhadi:
Neural Radiance Field Codebooks.
		Yujia Zheng, Ignavier Ng, Yewen Fan, Kun Zhang:
Generalized Precision Matrix for Scalable Estimation of Nonparametric Markov Networks.
		Aliaksandra Shysheya, John Bronskill, Massimiliano Patacchiola, Sebastian Nowozin, Richard E. Turner:
FiT: Parameter Efficient Few-shot Transfer Learning for Personalized and Federated Image Classification.
		Ye Zhu, Yu Wu, Kyle Olszewski, Jian Ren, Sergey Tulyakov, Yan Yan:
Discrete Contrastive Diffusion for Cross-Modal Music and Image Generation.
		Brian L. Trippe, Jason Yim, Doug Tischer, David Baker, Tamara Broderick, Regina Barzilay, Tommi S. Jaakkola:
Diffusion Probabilistic Modeling of Protein Backbones in 3D for the motif-scaffolding problem.
		Zhiwen Fan, Peihao Wang, Yifan Jiang, Xinyu Gong, Dejia Xu, Zhangyang Wang:
NeRF-SOS: Any-View Self-supervised Object Segmentation on Complex Scenes.
		Bo Hui, Da Yan, Xiaolong Ma, Wei-Shinn Ku:
Rethinking Graph Lottery Tickets: Graph Sparsity Matters.
		Andrew Lowy, Meisam Razaviyayn:
Private Federated Learning Without a Trusted Server: Optimal Algorithms for Convex Losses.
		Yat Long Lo, Christian Schröder de Witt, Samuel Sokota, Jakob Nicolaus Foerster, Shimon Whiteson:
Cheap Talk Discovery and Utilization in Multi-Agent Reinforcement Learning.
		Yuxuan Cai, Yizhuang Zhou, Qi Han, Jianjian Sun, Xiangwen Kong, Jun Li, Xiangyu Zhang:
Reversible Column Networks.
		Zhitong Gao, Yucong Chen, Chuyu Zhang, Xuming He:
Modeling Multimodal Aleatoric Uncertainty in Segmentation with Mixture of Stochastic Experts.
		Zuxin Liu, Zijian Guo, Zhepeng Cen, Huan Zhang, Jie Tan, Bo Li, Ding Zhao:
On the Robustness of Safe Reinforcement Learning under Observational Perturbations.
		Jianhao Ma, Lingjun Guo, Salar Fattahi:
Behind the Scenes of Gradient Descent: A Trajectory Analysis via Basis Function Decomposition.
		Yihua Zhang, Pranay Sharma, Parikshit Ram, Mingyi Hong, Kush R. Varshney, Sijia Liu:
What Is Missing in IRM Training and Evaluation? Challenges and Solutions.
		Mingxuan Ju, Tong Zhao, Qianlong Wen, Wenhao Yu, Neil Shah, Yanfang Ye, Chuxu Zhang:
Multi-task Self-supervised Graph Neural Networks Enable Stronger Task Generalization.
		Ryuichi Kanoh, Mahito Sugiyama:
Analyzing Tree Architectures in Ensembles via Neural Tangent Kernel.
		Youngwan Lee, Jeffrey Ryan Willette, Jonghee Kim, Juho Lee, Sung Ju Hwang:
Exploring The Role of Mean Teachers in Self-supervised Masked Auto-Encoders.
		Noam Wies, Yoav Levine, Amnon Shashua:
Sub-Task Decomposition Enables Learning in Sequence to Sequence Tasks.
		Jurgis Pasukonis, Timothy P. Lillicrap, Danijar Hafner:
Evaluating Long-Term Memory in 3D Mazes.
		Hai Ci, Mickel Liu, Xuehai Pan, Fangwei Zhong, Yizhou Wang:
Proactive Multi-Camera Collaboration for 3D Human Pose Estimation.
		Weirui Ye, Yunsheng Zhang, Pieter Abbeel, Yang Gao:
Become a Proficient Player with Limited Data through Watching Pure Videos.
		Hongyu Liu, Xintong Han, Chenbin Jin, Lihui Qian, Huawei Wei, Zhe Lin, Faqiang Wang, Haoye Dong, Yibing Song, Jia Xu, Qifeng Chen:
Human MotionFormer: Transferring Human Motions with Vision Transformers.
		Han-Dong Lim, Donghwan Lee:
Backstepping Temporal Difference Learning.
		Hui Wu, Min Wang, Wengang Zhou, Houqiang Li:
A General Rank Preserving Framework for Asymmetric Image Retrieval.
		Xuezhe Ma, Chunting Zhou, Xiang Kong, Junxian He, Liangke Gui, Graham Neubig, Jonathan May, Luke Zettlemoyer:
Mega: Moving Average Equipped Gated Attention.
		Yifei Wang, Tolga Ergen, Mert Pilanci:
Parallel Deep Neural Networks Have Zero Duality Gap.
		Ziqiao Wang, Yongyi Mao:
Information-Theoretic Analysis of Unsupervised Domain Adaptation.
		Miao Lu, Yifei Min, Zhaoran Wang, Zhuoran Yang:
Pessimism in the Face of Confounders: Provably Efficient Offline Reinforcement Learning in Partially Observable Markov Decision Processes.
		Chengzhi Mao, Scott Geng, Junfeng Yang, Xin Wang, Carl Vondrick:
Understanding Zero-shot Adversarial Robustness for Large-Scale Models.
		Jie Ren, Zhanpeng Zhou, Qirui Chen, Quanshi Zhang:
Can We Faithfully Represent Absence States to Compute Shapley Values on a DNN?
		Xisen Jin, Xiang Ren, Daniel Preotiuc-Pietro, Pengxiang Cheng:
Dataless Knowledge Fusion by Merging Weights of Language Models.
		Zhenghao Liu, Chenyan Xiong, Yuanhuiyi Lv, Zhiyuan Liu, Ge Yu:
Universal Vision-Language Dense Retrieval: Learning A Unified Representation Space for Multi-Modal Retrieval.
		Byung-Ki Kwon, Nam Hyeon-Woo, Ji-Yun Kim, Tae-Hyun Oh:
DFlow: Learning to Synthesize Better Optical Flow Datasets via a Differentiable Pipeline.
		Berivan Isik, Francesco Pase, Deniz Gündüz, Tsachy Weissman, Michele Zorzi:
Sparse Random Networks for Communication-Efficient Federated Learning.
		Damien Ferbach, Christos Tsirigotis, Gauthier Gidel, Avishek Joey Bose:
A General Framework For Proving The Equivariant Strong Lottery Ticket Hypothesis.
		Anshuman Chhabra, Peizhao Li, Prasant Mohapatra, Hongfu Liu:
Robust Fair Clustering: A Novel Fairness Attack and Defense Framework.
		Shangqian Gao, Burak Uzkent, Yilin Shen, Heng Huang, Hongxia Jin:
Learning to Jointly Share and Prune Weights for Grounding Based Vision and Language Models.
		Yuanqing Wang, John D. Chodera:
Spatial Attention Kinetic Networks with E(n)-Equivariance.
		Yuning You, Tianlong Chen, Zhangyang Wang, Yang Shen:
Graph Domain Adaptation via Theory-Grounded Spectral Regularization.
		Sheng Yue, Guanbo Wang, Wei Shao, Zhaofeng Zhang, Sen Lin, Ju Ren, Junshan Zhang:
CLARE: Conservative Model-Based Reward Learning for Offline Inverse Reinforcement Learning.
		Clare Elizabeth Heinbaugh, Emilio Luz-Ricca, Huajie Shao:
Data-Free One-Shot Federated Learning Under Very High Statistical Heterogeneity.
		Zhengyang Zhou, Qihe Huang, Gengyu Lin, Yang Kuo, Lei Bai, Yang Wang:
GReTo: Remedying dynamic graph topology-task discordance via target homophily.
		Zheng Yu, Yikuan Li, Joseph C. Kim, Kaixuan Huang, Yuan Luo, Mengdi Wang:
Deep Reinforcement Learning for Cost-Effective Medical Diagnosis.
		Steven D. Morad, Ryan Kortvelesy, Matteo Bettini, Stephan Liwicki, Amanda Prorok:
POPGym: Benchmarking Partially Observable Reinforcement Learning.
		Xudong Han, Timothy Baldwin, Trevor Cohn:
Everybody Needs Good Neighbours: An Unsupervised Locality-based Method for Bias Mitigation.
		Hanze Dong, Xi Wang, Yong Lin, Tong Zhang:
Particle-based Variational Inference with Preconditioned Functional Gradient Flow.
		Han Wu, Haochen Tan, Mingjie Zhan, Gangming Zhao, Shaoqing Lu, Ding Liang, Linqi Song:
Learning Locality and Isotropy in Dialogue Modeling.
		Jianing Zhu, Jiangchao Yao, Tongliang Liu, Quanming Yao, Jianliang Xu, Bo Han:
Combating Exacerbated Heterogeneity for Robust Models in Federated Learning.
		Qi Fan, Mattia Segù, Yu-Wing Tai, Fisher Yu, Chi-Keung Tang, Bernt Schiele, Dengxin Dai:
Towards Robust Object Detection Invariant to Real-World Domain Shifts.
		Jing Yang, Hanyuan Xiao, Wenbin Teng, Yunxuan Cai, Yajie Zhao:
Light Sampling Field and BRDF Representation for Physically-based Neural Rendering.
		Penghao Wu, Li Chen, Hongyang Li, Xiaosong Jia, Junchi Yan, Yu Qiao:
Policy Pre-training for Autonomous Driving via Self-supervised Geometric Modeling.
		Haixu Wu, Tengge Hu, Yong Liu, Hang Zhou, Jianmin Wang, Mingsheng Long:
TimesNet: Temporal 2D-Variation Modeling for General Time Series Analysis.
		Myeongho Jeon, Hyoje Lee, Yedarm Seong, Myungjoo Kang:
Learning without Prejudices: Continual Unbiased Learning via Benign and Malignant Forgetting.
		Takashi Matsubara, Takaharu Yaguchi:
FINDE: Neural Differential Equations for Finding and Preserving Invariant Quantities.
		Elias Samuel Wirth, Hiroshi Kera, Sebastian Pokutta:
Approximate Vanishing Ideal Computations at Scale.
		Hongjin Su, Jungo Kasai, Chen Henry Wu, Weijia Shi, Tianlu Wang, Jiayi Xin, Rui Zhang, Mari Ostendorf, Luke Zettlemoyer, Noah A. Smith, Tao Yu:
Selective Annotation Makes Language Models Better Few-Shot Learners.
		Zhenxing Mi, Dan Xu:
Switch-NeRF: Learning Scene Decomposition with Mixture of Experts for Large-scale Neural Radiance Fields.
		Xiaolong Liu, Lujun Li, Chao Li, Anbang Yao:
NORM: Knowledge Distillation via N-to-One Representation Matching.
		Vasileios Lioutas, Jonathan Wilder Lavington, Justice Sefas, Matthew Niedoba, Yunpeng Liu, Berend Zwartsenberg, Setareh Dabiri, Frank Wood, Adam Scibior:
Critic Sequential Monte Carlo.
		Runpei Dong, Zekun Qi, Linfeng Zhang, Junbo Zhang, Jianjian Sun, Zheng Ge, Li Yi, Kaisheng Ma:
Autoencoders as Cross-Modal Teachers: Can Pretrained 2D Image Transformers Help 3D Representation Learning?
		Kaiqi Zhang, Yu-Xiang Wang:
Deep Learning meets Nonparametric Regression: Are Weight-Decayed DNNs Locally Adaptive?
		Heejun Lee, Minki Kang, Youngwan Lee, Sung Ju Hwang:
Sparse Token Transformer with Attention Back Tracking.
		Cenk Baykal, Khoa Trinh, Fotis Iliopoulos, Gaurav Menghani, Erik Vee:
Robust Active Distillation.
		Alexander Korotin, Daniil Selikhanovych, Evgeny Burnaev:
Kernel Neural Optimal Transport.
		Qiang Wan, Zilong Huang, Jiachen Lu, Gang Yu, Li Zhang:
SeaFormer: Squeeze-enhanced Axial Transformer for Mobile Semantic Segmentation.
		Shuai Zhang, Meng Wang, Pin-Yu Chen, Sijia Liu, Songtao Lu, Miao Liu:
Joint Edge-Model Sparse Learning is Provably Efficient for Graph Neural Networks.
		Stamatios Lefkimmiatis, Iaroslav Koshelev:
Learning Sparse and Low-Rank Priors for Image Recovery via Iterative Reweighted Least Squares Minimization.
		Clément Bonet, Paul Berg, Nicolas Courty, François Septier, Lucas Drumetz, Minh-Tan Pham:
Spherical Sliced-Wasserstein.
		Zhuoran Yu, Yin Li, Yong Jae Lee:
InPL: Pseudo-labeling the Inliers First for Imbalanced Semi-supervised Learning.
		Yucheng Lu, Conglong Li, Minjia Zhang, Christopher De Sa, Yuxiong He:
Maximizing Communication Efficiency for Large-scale Training via 0/1 Adam.
		Shohei Ohsawa:
Truthful Self-Play.
		Itay Eilat, Ben Finkelshtein, Chaim Baskin, Nir Rosenfeld:
Strategic Classification with Graph Neural Networks.
		Lukas Hedegaard, Arian Bakhtiarnia, Alexandros Iosifidis:
Continual Transformers: Redundancy-Free Attention for Online Inference.
		Hongzhi Shi, Jingtao Ding, Yufan Cao, Quanming Yao, Li Liu, Yong Li:
Learning Symbolic Models for Graph-structured Physical Mechanism.
		Sasha Salter, Kristian Hartikainen, Walter Goodwin, Ingmar Posner:
Priors, Hierarchy, and Information Asymmetry for Skill Transfer in Reinforcement Learning.
		Dong Bok Lee, Seanie Lee, Kenji Kawaguchi, Yunji Kim, Jihwan Bang, Jung-Woo Ha, Sung Ju Hwang:
Self-Supervised Set Representation Learning for Unsupervised Meta-Learning.
		Phillip Lippe, Sara Magliacane, Sindy Löwe, Yuki M. Asano, Taco Cohen, Efstratios Gavves:
Causal Representation Learning for Instantaneous and Temporal Effects in Interactive Systems.
		Minghuan Liu, Tairan He, Weinan Zhang, Shuicheng Yan, Zhongwen Xu:
Visual Imitation Learning with Patch Rewards.
		Bei Chen, Fengji Zhang, Anh Nguyen, Daoguang Zan, Zeqi Lin, Jian-Guang Lou, Weizhu Chen:
CodeT: Code Generation with Generated Tests.
		Yuan Sun, Andreas T. Ernst, Xiaodong Li, Jake Weiner:
Learning to Generate Columns with Application to Vertex Coloring.
		Guo-Hua Wang, Jiahao Li, Bin Li, Yan Lu:
EVC: Towards Real-Time Neural Image Compression with Mask Decay.
		Yulun Wu, Robert A. Barton, Zichen Wang, Vassilis N. Ioannidis, Carlo De Donno, Layne C. Price, Luis F. Voloch, George Karypis:
Predicting Cellular Responses with Variational Causal Inference and Refined Relational Information.
		Wanqi Xue, Qingpeng Cai, Ruohan Zhan, Dong Zheng, Peng Jiang, Kun Gai, Bo An:
ResAct: Reinforcing Long-term Engagement in Sequential Recommendation with Residual Actor.
		Shuo Yang, Zeke Xie, Hanyu Peng, Min Xu, Mingming Sun, Ping Li:
Dataset Pruning: Reducing Training Data by Examining Generalization Influence.
		Yuechen Yu, Yulin Li, Chengquan Zhang, Xiaoqiang Zhang, Zengyuan Guo, Xiameng Qin, Kun Yao, Junyu Han, Errui Ding, Jingdong Wang:
StrucTexTv2: Masked Visual-Textual Prediction for Document Image Pre-training.
		Xiang Wang, Annie N. Wang, Mo Zhou, Rong Ge:
Plateau in Monotonic Linear Interpolation - A "Biased" View of Loss Landscape for Deep Networks.
		Xue Yang, Yue Zhou, Gefan Zhang, Jirui Yang, Wentao Wang, Junchi Yan, Xiaopeng Zhang, Qi Tian:
The KFIoU Loss for Rotated Object Detection.
		Christopher Wang, Vighnesh Subramaniam, Adam Uri Yaari, Gabriel Kreiman, Boris Katz, Ignacio Cases, Andrei Barbu:
BrainBERT: Self-supervised representation learning for intracranial recordings.
		Fangneng Zhan, Lingjie Liu, Adam Kortylewski, Christian Theobalt:
General Neural Gauge Fields.
		Wenhao Yu, Dan Iter, Shuohang Wang, Yichong Xu, Mingxuan Ju, Soumya Sanyal, Chenguang Zhu, Michael Zeng, Meng Jiang:
Generate rather than Retrieve: Large Language Models are Strong Context Generators.
		Chang Liu, Kunpeng Li, Michael Stopa, Jun Amano, Yun Fu:
Discovering Informative and Robust Positives for Video Domain Adaptation.
		Runtian Zhai, Chen Dan, J. Zico Kolter, Pradeep Kumar Ravikumar:
Understanding Why Generalized Reweighting Does Not Improve Over ERM.
		Jeevesh Juneja, Rachit Bansal, Kyunghyun Cho, João Sedoc, Naomi Saphra:
Linear Connectivity Reveals Generalization Strategies.
		Meng Liu, Haoran Liu, Shuiwang Ji:
Gradient-Guided Importance Sampling for Learning Binary Energy-Based Models.
		Shuang Li, Yilun Du, Joshua B. Tenenbaum, Antonio Torralba, Igor Mordatch:
Composing Ensembles of Pre-trained Models via Iterative Consensus.
		Youzhi Luo, Michael McThrow, Wing Yee Au, Tao Komikado, Kanji Uchino, Koji Maruhashi, Shuiwang Ji:
Automated Data Augmentations for Graph Classification.
		Christopher Scarvelis, Justin Solomon:
Riemannian Metric Learning via Optimal Transport.
		MohammadReza Davari, Stefan Horoi, Amine Natik, Guillaume Lajoie, Guy Wolf, Eugene Belilovsky:
Reliability of CKA as a Similarity Measure in Deep Learning.
		Dongliang Guo, Zhixuan Chu, Sheng Li:
Fair Attribute Completion on Graph with Missing Attributes.
		Abdus Salam Khazi, Sebastian Pineda-Arango, Josif Grabocka:
Deep Ranking Ensembles for Hyperparameter Optimization.
		Xi Wang, Laurence Aitchison:
Robustness to corruption in pre-trained Bayesian neural networks.
		Bo Wan, Yongfei Liu, Desen Zhou, Tinne Tuytelaars, Xuming He:
Weakly-supervised HOI Detection via Prior-guided Bi-level Representation Learning.
		Wenlin Chen, Austin Tripp, José Miguel Hernández-Lobato:
Meta-learning Adaptive Deep Kernel Gaussian Processes for Molecular Property Prediction.
		Jianye Hao, Pengyi Li, Hongyao Tang, Yan Zheng, Xian Fu, Zhaopeng Meng:
ERL-Re$^2$: Efficient Evolutionary Reinforcement Learning with Shared State Representation and Individual Policy Representation.
		Denny Zhou, Nathanael Schärli, Le Hou, Jason Wei, Nathan Scales, Xuezhi Wang, Dale Schuurmans, Claire Cui, Olivier Bousquet, Quoc V. Le, Ed H. Chi:
Least-to-Most Prompting Enables Complex Reasoning in Large Language Models.
		Steven J. Krieg, William C. Burgis, Patrick M. Soga, Nitesh V. Chawla:
Deep Ensembles for Graphs with Higher-order Dependencies.
		Jiachun Pan, Pan Zhou, Shuicheng Yan:
Towards Understanding Why Mask Reconstruction Pretraining Helps in Downstream Tasks.
		Xueyi Liu, Ji Zhang, Ruizhen Hu, Haibin Huang, He Wang, Li Yi:
Self-Supervised Category-Level Articulated Object Pose Estimation with Part-Level SE(3) Equivariance.
		Ali Hummos:
Thalamus: a brain-inspired algorithm for biologically-plausible continual learning and disentangled representations.
		Luis A. Ortega, Simón Rodríguez Santana, Daniel Hernández-Lobato:
Deep Variational Implicit Processes.
		Quanlin Wu, Hang Ye, Yuntian Gu, Huishuai Zhang, Liwei Wang, Di He:
Denoising Masked Autoencoders Help Robust Classification.
		Dennis Frauen, Stefan Feuerriegel:
Estimating individual treatment effects under unobserved confounding using binary instruments.
		Tobias Pielok, Bernd Bischl, David Rügamer:
Approximate Bayesian Inference with Stein Functional Variational Gradient Descent.
		Zhiyuan Zeng, Deyi Xiong:
SCoMoE: Efficient Mixtures of Experts with Structured Communication.
		Vy Vo, Van Nguyen, Trung Le, Quan Hung Tran, Reza Haf, Seyit Camtepe, Dinh Phung:
An Additive Instance-Wise Approach to Multi-class Model Interpretation.
		Xinjie Zhang, Jiawei Shao, Jun Zhang:
LDMIC: Learning-based Distributed Multi-view Image Coding.
		Václav Vorácek, Matthias Hein:
Sound Randomized Smoothing in Floating-Point Arithmetic.
		Yihan Du, Wei Chen, Yuko Kuroki, Longbo Huang:
Collaborative Pure Exploration in Kernel Bandit.
		Yihan Du, Siwei Wang, Longbo Huang:
Provably Efficient Risk-Sensitive Reinforcement Learning: Iterated CVaR and Worst Path.
		Liangze Jiang, Tao Lin:
Test-Time Robust Personalization for Federated Learning.
		Souvik Kundu, Shunlin Lu, Yuke Zhang, Jacqueline Tiffany Liu, Peter A. Beerel:
Learning to Linearize Deep Neural Networks for Secure and Efficient Private Inference.
		Ping Liu, Xin Yu, Joey Tianyi Zhou:
Meta Knowledge Condensation for Federated Learning.
		Jiahao Xie, Wei Li, Xiaohang Zhan, Ziwei Liu, Yew-Soon Ong, Chen Change Loy:
Masked Frequency Modeling for Self-Supervised Visual Pre-Training.
		Pan Lu, Liang Qiu, Kai-Wei Chang, Ying Nian Wu, Song-Chun Zhu, Tanmay Rajpurohit, Peter Clark, Ashwin Kalyan:
Dynamic Prompt Learning via Policy Gradient for Semi-structured Mathematical Reasoning.
		Chuang Lin, Peize Sun, Yi Jiang, Ping Luo, Lizhen Qu, Gholamreza Haffari, Zehuan Yuan, Jianfei Cai:
Learning Object-Language Alignments for Open-Vocabulary Object Detection.
		Jiashun Jin, Zheng Tracy Ke, Paxton Turner, Anru Zhang:
Phase transition for detecting a small community in a large network.
		Ryo Ueda, Taiga Ishii, Yusuke Miyao:
On the Word Boundaries of Emergent Languages Based on Harris's Articulation Scheme.
		Yuncong Yang, Jiawei Ma, Shiyuan Huang, Long Chen, Xudong Lin, Guangxing Han, Shih-Fu Chang:
TempCLR: Temporal Alignment Representation with Contrastive Learning.
		Borui Zhang, Wenzhao Zheng, Jie Zhou, Jiwen Lu:
Bort: Towards Explainable Neural Networks with Bounded Orthogonal Constraint.
		Mingyang Liu, Asuman E. Ozdaglar, Tiancheng Yu, Kaiqing Zhang:
The Power of Regularization in Solving Extensive-Form Games.
		Xiaotian Han, Tong Zhao, Yozen Liu, Xia Hu, Neil Shah:
MLPInit: Embarrassingly Simple GNN Training Acceleration with MLP Initialization.
		Jin Li, Yaoming Wang, Xiaopeng Zhang, Yabo Chen, Dongsheng Jiang, Wenrui Dai, Chenglin Li, Hongkai Xiong, Qi Tian:
Progressively Compressed Auto-Encoder for Self-supervised Representation Learning.
		Ziyang Xie, Junge Zhang, Wenye Li, Feihu Zhang, Li Zhang:
S-NeRF: Neural Radiance Fields for Street Views.
		Haiyang Yang, Xiaotong Li, Shixiang Tang, Feng Zhu, Yizhou Wang, Meilin Chen, Lei Bai, Rui Zhao, Wanli Ouyang:
Cycle-consistent Masked AutoEncoder for Unsupervised Domain Generalization.
		Yinchuan Li, Shuang Luo, Haozhi Wang, Jianye Hao:
CFlowNets: Continuous Control with Generative Flow Networks.
		Dongzhuo Li:
Differentiable Gaussianization Layers for Inverse Problems Regularized by Deep Generative Models.
		Jinrong Yang, Lin Song, Songtao Liu, Weixin Mao, Zeming Li, Xiaoping Li, Hongbin Sun, Jian Sun, Nanning Zheng:
DBQ-SSD: Dynamic Ball Query for Efficient 3D Object Detection.
		Jinxi Xiang, Jun Zhang:
Exploring Low-Rank Property in Multiple Instance Learning for Whole Slide Image Classification.
		Xinyi Wang, Michael Saxon, Jiachen Li, Hongyang Zhang, Kun Zhang, William Yang Wang:
Causal Balancing for Domain Generalization.
		Yiqun Diao, Qinbin Li, Bingsheng He:
Towards Addressing Label Skews in One-Shot Federated Learning.
		Mingyang Yi, Ruoyu Wang, Jiacheng Sun, Zhenguo Li, Zhi-Ming Ma:
Breaking Correlation Shift via Conditional Invariant Regularizer.
		Runzhong Wang, Li Shen, Yiting Chen, Xiaokang Yang, Dacheng Tao, Junchi Yan:
Towards One-shot Neural Combinatorial Solvers: Theoretical and Empirical Notes on the Cardinality-Constrained Case.
		Yun-Chen Lo, Tse-Kuang Lee, Ren-Shuo Liu:
Block and Subword-Scaling Floating-Point (BSFP) : An Efficient Non-Uniform Quantization For Low Precision Inference.
		Rundong Luo, Yifei Wang, Yisen Wang:
Rethinking the Effect of Data Augmentation in Adversarial Contrastive Learning.
		Yicong Jiang, Tracy Ke:
Semi-supervised Community Detection via Structural Similarity Metrics.
		Tiange Xiang, Mahmut Yurt, Ali B. Syed, Kawin Setsompop, Akshay Chaudhari:
DDM2: Self-Supervised Diffusion MRI Denoising with Generative Diffusion Models.
		Shuai Liu, Xiucheng Li, Gao Cong, Yile Chen, Yue Jiang:
Multivariate Time-series Imputation with Disentangled Temporal Representations.
		Zonghan Yang, Xiaoyuan Yi, Peng Li, Yang Liu, Xing Xie:
Unified Detoxifying and Debiasing in Language Generation via Inference-time Adaptive Optimization.
		Philip Sun, Ruiqi Guo, Sanjiv Kumar:
Automating Nearest Neighbor Search Configuration with Constrained Optimization.
		Huangjie Zheng, Pengcheng He, Weizhu Chen, Mingyuan Zhou:
Truncated Diffusion Probabilistic Models and Diffusion-based Adversarial Auto-Encoders.
		Yite Wang, Dawei Li, Ruoyu Sun:
NTK-SAP: Improving neural network pruning by aligning training dynamics.
		Fuwen Tan, Fatemeh Sadat Saleh, Brais Martínez:
Effective Self-supervised Pre-training on Low-compute Networks without Distillation.
		Yu-Neng Chuang, Guanchu Wang, Fan Yang, Quan Zhou, Pushkar Tripathi, Xuanting Cai, Xia Ben Hu:
CoRTX: Contrastive Framework for Real-time Explanation.
		Tianyi Chen, Luming Liang, Tianyu Ding, Zhihui Zhu, Ilya Zharkov:
OTOv2: Automatic, Generic, User-Friendly.
		Haoyue Cheng, Zhaoyang Liu, Wayne Wu, Limin Wang:
Filter-Recovery Network for Multi-Speaker Audio-Visual Speech Separation.
		Nathanaël Carraz Rakotonirina, Roberto Dessì, Fabio Petroni, Sebastian Riedel, Marco Baroni:
Can discrete information extraction prompts generalize across language models?
		Maksim Velikanov, Denis Kuznedelev, Dmitry Yarotsky:
A view of mini-batch SGD via generating functions: conditions of convergence, phase transitions, benefit from negative momenta.
		Zecheng Hao, Jianhao Ding, Tong Bu, Tiejun Huang, Zhaofei Yu:
Bridging the Gap between ANNs and SNNs by Calibrating Offset Spikes.
		Hee Suk Yoon, Joshua Tian Jin Tee, Eunseop Yoon, Sunjae Yoon, Gwangsu Kim, Yingzhen Li, Chang D. Yoo:
ESD: Expected Squared Difference as a Tuning-Free Trainable Calibration Measure.
		Jeya Maria Jose Valanarasu, He Zhang, Jianming Zhang, Yilin Wang, Zhe Lin, Jose Echevarria, Yinglan Ma, Zijun Wei, Kalyan Sunkavalli, Vishal Patel:
Interactive Portrait Harmonization.
		Seanie Lee, Minki Kang, Juho Lee, Sung Ju Hwang, Kenji Kawaguchi:
Self-Distillation for Further Pre-training of Transformers.
		Shuxian Liang, Xu Shen, Tongliang Liu, Xian-Sheng Hua:
Contextual Convolutional Networks.
		Luofeng Liao, Yuan Gao, Christian Kroer:
Statistical Inference for Fisher Market Equilibrium.
		Haitian Sun, William W. Cohen, Ruslan Salakhutdinov:
Scenario-based Question Answering with Interacting Contextual Properties.
		Kareem Amin, Matthew Joseph, Mónica Ribero, Sergei Vassilvitskii:
Easy Differentially Private Linear Regression.
		Bowen Dong, Pan Zhou, Shuicheng Yan, Wangmeng Zuo:
LPT: Long-tailed Prompt Tuning for Image Classification.
		Yang Liu, Jiankang Deng, Fei Wang, Lei Shang, Xuansong Xie, Baigui Sun:
DamoFD: Digging into Backbone Design on Face Detection.
		Qihang Zhang, Ceyuan Yang, Yujun Shen, Yinghao Xu, Bolei Zhou:
Towards Smooth Video Composition.
		Jiawei Ren, Cunjun Yu, Siwei Chen, Xiao Ma, Liang Pan, Ziwei Liu:
DiffMimic: Efficient Motion Mimicking with Differentiable Physics.
		Michael Hagmann, Philipp Meier, Stefan Riezler:
Towards Inferential Reproducibility of Machine Learning Research.
		Bin Xia, Yulun Zhang, Yitong Wang, Yapeng Tian, Wenming Yang, Radu Timofte, Luc Van Gool:
Knowledge Distillation based Degradation Estimation for Blind Super-Resolution.
		Xiaohu Huang, Hao Zhou, Jian Wang, Haocheng Feng, Junyu Han, Errui Ding, Jingdong Wang, Xinggang Wang, Wenyu Liu, Bin Feng:
Graph Contrastive Learning for Skeleton-based Action Recognition.
		Jie Yang, Ailing Zeng, Shilong Liu, Feng Li, Ruimao Zhang, Lei Zhang:
Explicit Box Detection Unifies End-to-End Multi-Person Pose Estimation.
		Zhaokun Zhou, Yuesheng Zhu, Chao He, Yaowei Wang, Shuicheng Yan, Yonghong Tian, Li Yuan:
Spikformer: When Spiking Neural Network Meets Transformer.
		Ningyu Zhang, Lei Li, Xiang Chen, Xiaozhuan Liang, Shumin Deng, Huajun Chen:
Multimodal Analogical Reasoning over Knowledge Graphs.
		Junyuan Hong, Lingjuan Lyu, Jiayu Zhou, Michael Spranger:
MECTA: Memory-Economic Continual Test-Time Model Adaptation.
		Kieran A. Murphy, Danielle S. Bassett:
Interpretability with full complexity by constraining feature information.
		Ziyin Liu, Ekdeep Singh Lubana, Masahito Ueda, Hidenori Tanaka:
What shapes the loss landscape of self supervised learning?
		Rui Yuan, Simon Shaolei Du, Robert M. Gower, Alessandro Lazaric, Lin Xiao:
Linear Convergence of Natural Policy Gradient Methods with Log-Linear Policies.
		Wei Xiong, Han Zhong, Chengshuai Shi, Cong Shen, Liwei Wang, Tong Zhang:
Nearly Minimax Optimal Offline Reinforcement Learning with Linear Function Approximation: Single-Agent MDP and Markov Game.
		Xiangxiang Chu, Zhi Tian, Bo Zhang, Xinlong Wang, Chunhua Shen:
Conditional Positional Encodings for Vision Transformers.
		Jiayuan Gu, Fanbo Xiang, Xuanlin Li, Zhan Ling, Xiqiang Liu, Tongzhou Mu, Yihe Tang, Stone Tao, Xinyue Wei, Yunchao Yao, Xiaodi Yuan, Pengwei Xie, Zhiao Huang, Rui Chen, Hao Su:
ManiSkill2: A Unified Benchmark for Generalizable Manipulation Skills.
		Chenxi Liu, Lixu Wang, Lingjuan Lyu, Chen Sun, Xiao Wang, Qi Zhu:
Deja Vu: Continual Model Generalization for Unseen Domains.
		Kiarash Jamali, Dari Kimanius, Sjors H. W. Scheres:
A Graph Neural Network Approach to Automated Model Building in Cryo-EM Maps.
		Hanxun Huang, Xingjun Ma, Sarah Monazam Erfani, James Bailey:
Distilling Cognitive Backdoor Patterns within an Image.
		Chang Liu, Zetian Jiang, Runzhong Wang, Lingxiao Huang, Pinyan Lu, Junchi Yan:
Revocable Deep Reinforcement Learning with Affinity Regularization for Outlier-Robust Graph Matching.
		Shengjie Luo, Tianlang Chen, Yixian Xu, Shuxin Zheng, Tie-Yan Liu, Liwei Wang, Di He:
One Transformer Can Understand Both 2D & 3D Molecular Data.
		Jianxiong Li, Xiao Hu, Haoran Xu, Jingjing Liu, Xianyuan Zhan, Qing-Shan Jia, Ya-Qin Zhang:
Mind the Gap: Offline Policy Optimization for Imperfect Rewards.
		Nihal V. Nayak, Peilin Yu, Stephen H. Bach:
Learning to Compose Soft Prompts for Compositional Zero-Shot Learning.
		Xiaojian Ma, Silong Yong, Zilong Zheng, Qing Li, Yitao Liang, Song-Chun Zhu, Siyuan Huang:
SQA3D: Situated Question Answering in 3D Scenes.
		Zikai Sun, Thierry Blu:
Empowering Networks With Scale and Rotation Equivariance Using A Similarity Convolution.
		Ruixiang Zhang, Tong Che, Boris Ivanovic, Renhao Wang, Marco Pavone, Yoshua Bengio, Liam Paull:
Robust and Controllable Object-Centric Learning through Energy-based Models.
		Fengchun Qiao, Xi Peng:
Topology-aware Robust Optimization for Out-of-Distribution Generalization.
		Steeven Janny, Aurélien Béneteau, Madiha Nadri, Julie Digne, Nicolas Thome, Christian Wolf:
EAGLE: Large-scale Learning of Turbulent Fluid Dynamics with Mesh Transformers.
		Christian Koke:
Limitless Stability for Graph Convolutional Networks.
		Zijie Geng, Shufang Xie, Yingce Xia, Lijun Wu, Tao Qin, Jie Wang, Yongdong Zhang, Feng Wu, Tie-Yan Liu:
De Novo Molecular Generation via Connection-aware Motif Mining.
		Oscar Chang, Dongseong Hwang, Olivier Siohan:
Revisiting the Entropy Semiring for Neural Speech Recognition.
		Dengsheng Chen, Jie Hu, Wenwen Qiang, Xiaoming Wei, Enhua Wu:
Rethinking skip connection model as a learnable Markov chain.
		Miguel Monteiro, Fabio De Sousa Ribeiro, Nick Pawlowski, Daniel C. Castro, Ben Glocker:
Measuring axiomatic soundness of counterfactual image models.
		Haixiang Sun, Ye Shi, Jingya Wang, Hoang Duong Tuan, H. Vincent Poor, Dacheng Tao:
Alternating Differentiation for Optimization Layers.
		Qizhou Wang, Junjie Ye, Feng Liu, Quanyu Dai, Marcus Kalander, Tongliang Liu, Jianye Hao, Bo Han:
Out-of-distribution Detection with Implicit Outlier Transformation.
		Guanlin Li, Guowen Xu, Shangwei Guo, Han Qiu, Jiwei Li, Tianwei Zhang:
Extracting Robust Models with Uncertain Examples.
		Prafull Sharma, Ayush Tewari, Yilun Du, Sergey Zakharov, Rares Andrei Ambrus, Adrien Gaidon, William T. Freeman, Frédo Durand, Joshua B. Tenenbaum, Vincent Sitzmann:
Neural Groundplans: Persistent Neural Scene Representations from a Single Image.
		Jie Zhu, Huabin Huang, Banghuai Li, Leye Wang:
E-CRF: Embedded Conditional Random Field for Boundary-caused Class Weights Confusion in Semantic Segmentation.
		Xiang Ji, Minshuo Chen, Mengdi Wang, Tuo Zhao:
Sample Complexity of Nonparametric Off-Policy Evaluation on Low-Dimensional Manifolds using Deep Networks.
		Andrew Lowy, Devansh Gupta, Meisam Razaviyayn:
Stochastic Differentially Private and Fair Learning.
		Zhijie Nie, Richong Zhang, Yongyi Mao:
On The Inadequacy of Optimizing Alignment and Uniformity in Contrastive Learning of Sentence Representations.
		Na Lei, Dongsheng An, Min Zhang, Xiaoyin Xu, Xianfeng David Gu:
Volumetric Optimal Transportation by Fast Fourier Transform.
		Nikolay Malkin, Salem Lahlou, Tristan Deleu, Xu Ji, Edward J. Hu, Katie Everett, Dinghuai Zhang, Yoshua Bengio:
GFlowNets and variational inference.
		Han Wu, Jie Yin, Bala Rajaratnam, Jianyuan Guo:
Hierarchical Relational Learning for Few-Shot Knowledge Graph Completion.
		Dongyang Liu, Meina Kan, Shiguang Shan, Xilin Chen:
Function-Consistent Feature Distillation.
		Jun Cen, Di Luan, Shiwei Zhang, Yixuan Pei, Yingya Zhang, Deli Zhao, Shaojie Shen, Qifeng Chen:
The Devil is in the Wrongly-classified Samples: Towards Unified Open-set Recognition.
		Hang Qiu, Krishna Chintalapudi, Ramesh Govindan:
MCAL: Minimum Cost Human-Machine Active Labeling.
		Cheng Zhang:
Learnable Topological Features For Phylogenetic Inference via Graph Neural Networks.
		Fengda Zhang, Kun Kuang, Long Chen, Yuxuan Liu, Chao Wu, Jun Xiao:
Fairness-aware Contrastive Learning with Partially Annotated Sensitive Attributes.
		Shitong Luo, Yufeng Su, Zuofan Wu, Chenpeng Su, Jian Peng, Jianzhu Ma:
Rotamer Density Estimator is an Unsupervised Learner of the Effect of Mutations on Protein-Protein Interaction.
		Ismail Khalfaoui Hassani, Thomas Pellegrini, Timothée Masquelier:
Dilated convolution with learnable spacings.
		Qinrou Wen, Jirui Yang, Xue Yang, Kewei Liang:
PatchDCT: Patch Refinement for High Quality Instance Segmentation.
		Ayan Das, Yongxin Yang, Timothy M. Hospedales, Tao Xiang, Yi-Zhe Song:
ChiroDiff: Modelling chirographic data with Diffusion Models.
		Yuxin Zhang, Mingbao Lin, Xunchao Li, Han Liu, Guozhi Wang, Fei Chao, Shuai Ren, Yafei Wen, Xiaoxin Chen, Rongrong Ji:
Real-Time Image Demoiréing on Mobile Devices.
		Hao Zheng, Runqi Wang, Jianzhuang Liu, Asako Kanezaki:
Cross-Level Distillation and Feature Denoising for Cross-Domain Few-Shot Classification.
		Bowen Zhao, Chen Chen, Shu-Tao Xia:
Delta: Degradation-Free Fully Test-Time Adaptation.
		Yusuke Sekikawa, Shingo Yashima:
Bit-Pruning: A Sparse Multiplication-Less Dot-Product.
		Shelly Sheynin, Oron Ashual, Adam Polyak, Uriel Singer, Oran Gafni, Eliya Nachmani, Yaniv Taigman:
kNN-Diffusion: Image Generation via Large-Scale Retrieval.
		Guangrui Li, Yifan Sun, Zongxin Yang, Yi Yang:
Decompose to Generalize: Species-Generalized Animal Pose Estimation.
		Jie Zhang, Chen Chen, Lingjuan Lyu:
IDEAL: Query-Efficient Data-Free Learning from Black-Box Models.
		Huan Wang, Yun Fu:
Trainability Preserving Neural Pruning.
		Yuhui Zhang, Jeff Z. HaoChen, Shih-Cheng Huang, Kuan-Chieh Wang, James Zou, Serena Yeung:
Diagnosing and Rectifying Vision Models using Language.
		Zhuo Huang, Xiaobo Xia, Li Shen, Bo Han, Mingming Gong, Chen Gong, Tongliang Liu:
Harnessing Out-Of-Distribution Examples via Augmenting Content and Style.
		Joya Chen, Kai Xu, Yuhui Wang, Yifei Cheng, Angela Yao:
DropIT: Dropping Intermediate Tensors for Memory-Efficient DNN Training.
		Yanqi Chen, Zhengyu Ma, Wei Fang, Xiawu Zheng, Zhaofei Yu, Yonghong Tian:
A Unified Framework for Soft Threshold Pruning.
		Hanrong Ye, Dan Xu:
TaskPrompter: Spatial-Channel Multi-Task Prompting for Dense Scene Understanding.
		Chu-ran Wang, Jing Li, Xinwei Sun, Fandong Zhang, Yizhou Yu, Yizhou Wang:
Learning Domain-Agnostic Representation for Disease Diagnosis.
		Chi Han, Qizheng He, Charles Yu, Xinya Du, Hanghang Tong, Heng Ji:
Logical Entity Representation in Knowledge-Graphs for Differentiable Rule Learning.
		Zehui Chen, Zhenyu Li, Shiquan Zhang, Liangji Fang, Qinhong Jiang, Feng Zhao:
BEVDistill: Cross-Modal BEV Distillation for Multi-View 3D Object Detection.
		Xiang Hu, Xinyu Kong, Kewei Tu:
A Multi-Grained Self-Interpretable Symbolic-Neural Model For Single/Multi-Labeled Text Classification.
		Zhengdong Hu, Yifan Sun, Yi Yang:
Suppressing the Heterogeneity: A Strong Feature Extractor for Few-shot Segmentation.
		Yongqiang Cai:
Achieve the Minimum Width of Neural Networks for Universal Approximation.
		Xue Yang, Gefan Zhang, Wentong Li, Yue Zhou, Xuehui Wang, Junchi Yan:
H2RBox: Horizontal Box Annotation is All You Need for Oriented Object Detection.
		Guoyang Xie, Jinbao Wang, Jiaqi Liu, Yaochu Jin, Feng Zheng:
Pushing the Limits of Fewshot Anomaly Detection in Industry Vision: Graphcore.
		Chengzhuo Ni, Yuda Song, Xuezhou Zhang, Zihan Ding, Chi Jin, Mengdi Wang:
Representation Learning for Low-rank General-sum Markov Games.
		Yoonho Lee, Annie S. Chen, Fahim Tajwar, Ananya Kumar, Huaxiu Yao, Percy Liang, Chelsea Finn:
Surgical Fine-Tuning Improves Adaptation to Distribution Shifts.
		Yoonho Lee, Huaxiu Yao, Chelsea Finn:
Diversify and Disambiguate: Out-of-Distribution Robustness via Disagreement.
		Brandon Amos:
On amortizing convex conjugates for optimal transport.
		Yan Zhao, Ruihai Wu, Zhehuan Chen, Yourong Zhang, Qingnan Fan, Kaichun Mo, Hao Dong:
DualAfford: Learning Collaborative Visual Affordance for Dual-gripper Manipulation.
		Shengchao Liu, Hongyu Guo, Jian Tang:
Molecular Geometry Pretraining with SE(3)-Invariant Denoising Distance Matching.
		Ziyue Li, Kan Ren, Xinyang Jiang, Yifei Shen, Haipeng Zhang, Dongsheng Li:
SIMPLE: Specialized Model-Sample Matching for Domain Generalization.
		Yuki M. Asano, Aaqib Saeed:
The Augmented Image Prior: Distilling 1000 Classes by Extrapolating from a Single Image.
		Yanbiao Ma, Licheng Jiao, Fang Liu, Yuxin Li, Shuyuan Yang, Xu Liu:
Delving into Semantic Scale Imbalance.
		Wenqian Li, Yinchuan Li, Zhigang Li, Jianye Hao, Yan Pang:
DAG Matters! GFlowNets Enhanced Explainer for Graph Neural Networks.
		Shaofeng Zhang, Feng Zhu, Rui Zhao, Junchi Yan:
Contextual Image Masking Modeling via Synergized Contrasting without View Augmentation for Faster and Better Visual Pretraining.
		Shaofeng Zhang, Feng Zhu, Rui Zhao, Junchi Yan:
Patch-Level Contrasting without Patch Correspondence for Accurate and Dense Contrastive Representation Learning.
		Hehe Fan, Zhangyang Wang, Yi Yang, Mohan S. Kankanhalli:
Continuous-Discrete Convolution for Geometry-Sequence Modeling in Proteins.